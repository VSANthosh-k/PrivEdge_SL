{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "waECmNJKoSJ-"
      },
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DF-czaxWx8ii"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import pathlib\n",
        "import socket, struct\n",
        "import imblearn\n",
        "from imblearn.under_sampling import RandomUnderSampler\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from collections import Counter\n",
        "from imblearn.over_sampling import SMOTE\n",
        "from imblearn.pipeline import make_pipeline\n",
        "from imblearn.under_sampling import NearMiss\n",
        "from sklearn.preprocessing import OneHotEncoder\n",
        "from sklearn.feature_selection import RFE\n",
        "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.preprocessing import LabelEncoder, StandardScaler, PowerTransformer\n",
        "from sklearn.decomposition import PCA"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iyvarGgDIG2L"
      },
      "outputs": [],
      "source": [
        "import socket\n",
        "import threading\n",
        "import pickle\n",
        "import numpy as np\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Conv1D, Flatten, Input\n",
        "from keras.optimizers import Adam\n",
        "import tensorflow as tf"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ufn6sytvYTKA"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QvSRXl8dy-st",
        "outputId": "4045aa8a-4661-47c1-a224-eaa62ff29e45"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vLi0wjCSy-vr"
      },
      "outputs": [],
      "source": [
        "benign = pathlib.Path(\"/content/drive/MyDrive/scopus/N-BaIoT dataset/1.benign.csv\")\n",
        "g_c=pathlib.Path(\"/content/drive/MyDrive/scopus/N-BaIoT dataset/1.gafgyt.combo.csv\")\n",
        "g_j=pathlib.Path(\"/content/drive/MyDrive/scopus/N-BaIoT dataset/1.gafgyt.junk.csv\")\n",
        "g_s=pathlib.Path(\"/content/drive/MyDrive/scopus/N-BaIoT dataset/1.gafgyt.scan.csv\")\n",
        "g_t=pathlib.Path(\"/content/drive/MyDrive/scopus/N-BaIoT dataset/1.gafgyt.tcp.csv\")\n",
        "g_u=pathlib.Path(\"/content/drive/MyDrive/scopus/N-BaIoT dataset/1.gafgyt.udp.csv\")\n",
        "m_a=pathlib.Path(\"/content/drive/MyDrive/scopus/N-BaIoT dataset/1.mirai.ack.csv\")\n",
        "m_sc=pathlib.Path(\"/content/drive/MyDrive/scopus/N-BaIoT dataset/1.mirai.scan.csv\")\n",
        "m_sy=pathlib.Path(\"/content/drive/MyDrive/scopus/N-BaIoT dataset/1.mirai.syn.csv\")\n",
        "m_u=pathlib.Path(\"/content/drive/MyDrive/scopus/N-BaIoT dataset/1.mirai.udp.csv\")\n",
        "m_u_p=pathlib.Path(\"/content/drive/MyDrive/scopus/N-BaIoT dataset/1.mirai.udpplain.csv\")\n",
        "\n",
        "benign9 = pathlib.Path(\"/content/drive/MyDrive/scopus/N-BaIoT dataset/9.benign.csv\")\n",
        "g_c9=pathlib.Path(\"/content/drive/MyDrive/scopus/N-BaIoT dataset/9.gafgyt.combo.csv\")\n",
        "g_j9=pathlib.Path(\"/content/drive/MyDrive/scopus/N-BaIoT dataset/9.gafgyt.junk.csv\")\n",
        "g_s9=pathlib.Path(\"/content/drive/MyDrive/scopus/N-BaIoT dataset/9.gafgyt.scan.csv\")\n",
        "g_t9=pathlib.Path(\"/content/drive/MyDrive/scopus/N-BaIoT dataset/9.gafgyt.tcp.csv\")\n",
        "g_u9=pathlib.Path(\"/content/drive/MyDrive/scopus/N-BaIoT dataset/9.gafgyt.udp.csv\")\n",
        "m_a9=pathlib.Path(\"/content/drive/MyDrive/scopus/N-BaIoT dataset/9.mirai.ack.csv\")\n",
        "m_sc9=pathlib.Path(\"/content/drive/MyDrive/scopus/N-BaIoT dataset/9.mirai.scan.csv\")\n",
        "m_sy9=pathlib.Path(\"/content/drive/MyDrive/scopus/N-BaIoT dataset/9.mirai.syn.csv\")\n",
        "m_u9=pathlib.Path(\"/content/drive/MyDrive/scopus/N-BaIoT dataset/9.mirai.udp.csv\")\n",
        "m_u_p9=pathlib.Path(\"/content/drive/MyDrive/scopus/N-BaIoT dataset/9.mirai.udpplain.csv\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Onow6NoZETOu"
      },
      "outputs": [],
      "source": [
        "# Load your data\n",
        "benign = pd.read_csv(benign)\n",
        "g_c=pd.read_csv(g_c)\n",
        "g_j=pd.read_csv(g_j)\n",
        "g_s=pd.read_csv(g_s)\n",
        "g_t=pd.read_csv(g_t)\n",
        "g_u=pd.read_csv(g_u)\n",
        "m_a=pd.read_csv(m_a)\n",
        "m_sc=pd.read_csv(m_sc)\n",
        "m_sy=pd.read_csv(m_sy)\n",
        "m_u=pd.read_csv(m_u)\n",
        "m_u_p=pd.read_csv(m_u_p)\n",
        "\n",
        "benign9 = pd.read_csv(benign9)\n",
        "g_c9=pd.read_csv(g_c9)\n",
        "g_j9=pd.read_csv(g_j9)\n",
        "g_s9=pd.read_csv(g_s9)\n",
        "g_t9=pd.read_csv(g_t9)\n",
        "g_u9=pd.read_csv(g_u9)\n",
        "m_a9=pd.read_csv(m_a9)\n",
        "m_sc9=pd.read_csv(m_sc9)\n",
        "m_sy9=pd.read_csv(m_sy9)\n",
        "m_u9=pd.read_csv(m_u9)\n",
        "m_u_p9=pd.read_csv(m_u_p9)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "q8gtsdZRy-yy"
      },
      "outputs": [],
      "source": [
        "benign=benign.sample(frac=0.35,replace=False)\n",
        "g_c=g_c.sample(frac=0.25,replace=False)\n",
        "g_j=g_j.sample(frac=0.5,replace=False)\n",
        "g_s=g_s.sample(frac=0.5,replace=False)\n",
        "g_t=g_t.sample(frac=0.15,replace=False)\n",
        "g_u=g_u.sample(frac=0.15,replace=False)\n",
        "m_a=m_a.sample(frac=0.15,replace=False)\n",
        "m_sc=m_sc.sample(frac=0.15,replace=False)\n",
        "m_sy=m_sy.sample(frac=0.15,replace=False)\n",
        "m_u=m_u.sample(frac=0.08,replace=False)\n",
        "m_u_p=m_u_p.sample(frac=0.17,replace=False)\n",
        "\n",
        "benign9=benign9.sample(frac=0.35,replace=False)\n",
        "g_c9=g_c9.sample(frac=0.25,replace=False)\n",
        "g_j9=g_j9.sample(frac=0.5,replace=False)\n",
        "g_s9=g_s9.sample(frac=0.5,replace=False)\n",
        "g_t9=g_t9.sample(frac=0.15,replace=False)\n",
        "g_u9=g_u9.sample(frac=0.15,replace=False)\n",
        "m_a9=m_a9.sample(frac=0.15,replace=False)\n",
        "m_sc9=m_sc9.sample(frac=0.15,replace=False)\n",
        "m_sy9=m_sy9.sample(frac=0.15,replace=False)\n",
        "m_u9=m_u9.sample(frac=0.08,replace=False)\n",
        "m_u_p9=m_u_p9.sample(frac=0.17,replace=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0duD_tGsGoR7"
      },
      "outputs": [],
      "source": [
        "benign['type']='benign'\n",
        "m_u['type']='mirai_udp'\n",
        "g_c['type']='gafgyt_combo'\n",
        "g_j['type']='gafgyt_junk'\n",
        "g_s['type']='gafgyt_scan'\n",
        "g_t['type']='gafgyt_tcp'\n",
        "g_u['type']='gafgyt_udp'\n",
        "m_a['type']='mirai_ack'\n",
        "m_sc['type']='mirai_scan'\n",
        "m_sy['type']='mirai_syn'\n",
        "m_u_p['type']='mirai_udpplain'\n",
        "\n",
        "benign9['type']='benign'\n",
        "m_u9['type']='mirai_udp'\n",
        "g_c9['type']='gafgyt_combo'\n",
        "g_j9['type']='gafgyt_junk'\n",
        "g_s9['type']='gafgyt_scan'\n",
        "g_t9['type']='gafgyt_tcp'\n",
        "g_u9['type']='gafgyt_udp'\n",
        "m_a9['type']='mirai_ack'\n",
        "m_sc9['type']='mirai_scan'\n",
        "m_sy9['type']='mirai_syn'\n",
        "m_u_p9['type']='mirai_udpplain'\n",
        "\n",
        "data=pd.concat([benign,m_u,g_c,g_j,g_s,g_t,g_u,m_a,m_sc,m_sy,m_u_p,benign9,m_u9,g_c9,g_j9,g_s9,g_t9,g_u9,m_a9,m_sc9,m_sy9,m_u_p9],\n",
        "               axis=0, sort=False, ignore_index=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ftUFFIMQQ-5H",
        "outputId": "f5fb2188-8f82-4456-cfb8-c843ae01763f"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(322007, 116)"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ],
      "source": [
        "data.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pbuYEnWapEBj",
        "outputId": "3d68be6b-bfd5-41ee-dc55-694ec4d8d02f"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array(['benign', 'mirai_udp', 'gafgyt_combo', 'gafgyt_junk',\n",
              "       'gafgyt_scan', 'gafgyt_tcp', 'gafgyt_udp', 'mirai_ack',\n",
              "       'mirai_scan', 'mirai_syn', 'mirai_udpplain'], dtype=object)"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ],
      "source": [
        "data.type.unique()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 460
        },
        "id": "vROqjqRoGoU-",
        "outputId": "5e731802-026d-4226-f968-2d322771efd8"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "type\n",
              "benign            24177\n",
              "gafgyt_combo      29780\n",
              "gafgyt_junk       28240\n",
              "gafgyt_scan       29210\n",
              "gafgyt_tcp        28532\n",
              "gafgyt_udp        31328\n",
              "mirai_ack         31407\n",
              "mirai_scan        22704\n",
              "mirai_syn         36758\n",
              "mirai_udp         31580\n",
              "mirai_udpplain    28291\n",
              "Name: type, dtype: int64"
            ],
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>type</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>type</th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>benign</th>\n",
              "      <td>24177</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>gafgyt_combo</th>\n",
              "      <td>29780</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>gafgyt_junk</th>\n",
              "      <td>28240</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>gafgyt_scan</th>\n",
              "      <td>29210</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>gafgyt_tcp</th>\n",
              "      <td>28532</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>gafgyt_udp</th>\n",
              "      <td>31328</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>mirai_ack</th>\n",
              "      <td>31407</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>mirai_scan</th>\n",
              "      <td>22704</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>mirai_syn</th>\n",
              "      <td>36758</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>mirai_udp</th>\n",
              "      <td>31580</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>mirai_udpplain</th>\n",
              "      <td>28291</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div><br><label><b>dtype:</b> int64</label>"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ],
      "source": [
        "#how many instances of each class\n",
        "data.groupby('type')['type'].count()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 256
        },
        "id": "mIlf1rtfGodT",
        "outputId": "a95f1d67-2ac1-49a2-a619-1125e0f3b145"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "        MI_dir_L5_weight  MI_dir_L5_mean  MI_dir_L5_variance  \\\n",
              "152608        117.522186       71.477471           28.993132   \n",
              "92586           1.000000       60.000000            0.000000   \n",
              "45617         150.948689       81.631268         4512.842091   \n",
              "210722        175.064384       74.030988            0.742760   \n",
              "27737         104.561981      502.892895        22634.952677   \n",
              "\n",
              "        MI_dir_L3_weight  MI_dir_L3_mean  MI_dir_L3_variance  \\\n",
              "152608        208.923071       70.476367           36.951138   \n",
              "92586           1.000000       60.000000            0.000000   \n",
              "45617         248.464129       81.979615         5438.547797   \n",
              "210722        284.711691       74.038486            0.922184   \n",
              "27737         188.629431      462.041639        36970.631789   \n",
              "\n",
              "        MI_dir_L1_weight  MI_dir_L1_mean  MI_dir_L1_variance  \\\n",
              "152608        665.669226       69.668129           41.899178   \n",
              "92586           1.000000       60.000000            0.000000   \n",
              "45617         769.310221       79.023258         3752.221894   \n",
              "210722        839.588503       74.042024            1.279972   \n",
              "27737         615.649871      410.622629        50265.752941   \n",
              "\n",
              "        MI_dir_L0.1_weight  ...  HpHp_L0.1_covariance  HpHp_L0.1_pcc  \\\n",
              "152608         6701.016815  ...                   0.0            0.0   \n",
              "92586             1.000000  ...                   0.0            0.0   \n",
              "45617          6361.660822  ...                   0.0            0.0   \n",
              "210722         5358.725479  ...                   0.0            0.0   \n",
              "27737          5149.677953  ...                   0.0            0.0   \n",
              "\n",
              "        HpHp_L0.01_weight  HpHp_L0.01_mean  HpHp_L0.01_std  \\\n",
              "152608                1.0             74.0             0.0   \n",
              "92586                 1.0             60.0             0.0   \n",
              "45617                 1.0             74.0             0.0   \n",
              "210722                1.0             74.0             0.0   \n",
              "27737                 1.0            554.0             0.0   \n",
              "\n",
              "        HpHp_L0.01_magnitude  HpHp_L0.01_radius  HpHp_L0.01_covariance  \\\n",
              "152608                  74.0                0.0                    0.0   \n",
              "92586                   60.0                0.0                    0.0   \n",
              "45617                   74.0                0.0                    0.0   \n",
              "210722                  74.0                0.0                    0.0   \n",
              "27737                  554.0                0.0                    0.0   \n",
              "\n",
              "        HpHp_L0.01_pcc          type  \n",
              "152608             0.0     mirai_syn  \n",
              "92586              0.0    gafgyt_tcp  \n",
              "45617              0.0  gafgyt_combo  \n",
              "210722             0.0   gafgyt_junk  \n",
              "27737              0.0     mirai_udp  \n",
              "\n",
              "[5 rows x 116 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-016ee3a0-7df5-4545-8b1d-985c245069dd\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>MI_dir_L5_weight</th>\n",
              "      <th>MI_dir_L5_mean</th>\n",
              "      <th>MI_dir_L5_variance</th>\n",
              "      <th>MI_dir_L3_weight</th>\n",
              "      <th>MI_dir_L3_mean</th>\n",
              "      <th>MI_dir_L3_variance</th>\n",
              "      <th>MI_dir_L1_weight</th>\n",
              "      <th>MI_dir_L1_mean</th>\n",
              "      <th>MI_dir_L1_variance</th>\n",
              "      <th>MI_dir_L0.1_weight</th>\n",
              "      <th>...</th>\n",
              "      <th>HpHp_L0.1_covariance</th>\n",
              "      <th>HpHp_L0.1_pcc</th>\n",
              "      <th>HpHp_L0.01_weight</th>\n",
              "      <th>HpHp_L0.01_mean</th>\n",
              "      <th>HpHp_L0.01_std</th>\n",
              "      <th>HpHp_L0.01_magnitude</th>\n",
              "      <th>HpHp_L0.01_radius</th>\n",
              "      <th>HpHp_L0.01_covariance</th>\n",
              "      <th>HpHp_L0.01_pcc</th>\n",
              "      <th>type</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>152608</th>\n",
              "      <td>117.522186</td>\n",
              "      <td>71.477471</td>\n",
              "      <td>28.993132</td>\n",
              "      <td>208.923071</td>\n",
              "      <td>70.476367</td>\n",
              "      <td>36.951138</td>\n",
              "      <td>665.669226</td>\n",
              "      <td>69.668129</td>\n",
              "      <td>41.899178</td>\n",
              "      <td>6701.016815</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>74.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>74.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>mirai_syn</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>92586</th>\n",
              "      <td>1.000000</td>\n",
              "      <td>60.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>60.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>60.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>60.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>60.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>gafgyt_tcp</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>45617</th>\n",
              "      <td>150.948689</td>\n",
              "      <td>81.631268</td>\n",
              "      <td>4512.842091</td>\n",
              "      <td>248.464129</td>\n",
              "      <td>81.979615</td>\n",
              "      <td>5438.547797</td>\n",
              "      <td>769.310221</td>\n",
              "      <td>79.023258</td>\n",
              "      <td>3752.221894</td>\n",
              "      <td>6361.660822</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>74.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>74.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>gafgyt_combo</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>210722</th>\n",
              "      <td>175.064384</td>\n",
              "      <td>74.030988</td>\n",
              "      <td>0.742760</td>\n",
              "      <td>284.711691</td>\n",
              "      <td>74.038486</td>\n",
              "      <td>0.922184</td>\n",
              "      <td>839.588503</td>\n",
              "      <td>74.042024</td>\n",
              "      <td>1.279972</td>\n",
              "      <td>5358.725479</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>74.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>74.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>gafgyt_junk</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>27737</th>\n",
              "      <td>104.561981</td>\n",
              "      <td>502.892895</td>\n",
              "      <td>22634.952677</td>\n",
              "      <td>188.629431</td>\n",
              "      <td>462.041639</td>\n",
              "      <td>36970.631789</td>\n",
              "      <td>615.649871</td>\n",
              "      <td>410.622629</td>\n",
              "      <td>50265.752941</td>\n",
              "      <td>5149.677953</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>554.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>554.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>mirai_udp</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5 rows × 116 columns</p>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-016ee3a0-7df5-4545-8b1d-985c245069dd')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-016ee3a0-7df5-4545-8b1d-985c245069dd button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-016ee3a0-7df5-4545-8b1d-985c245069dd');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "    <div id=\"df-5f667880-bb13-4b0d-8820-afc315ff72ea\">\n",
              "      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-5f667880-bb13-4b0d-8820-afc315ff72ea')\"\n",
              "                title=\"Suggest charts\"\n",
              "                style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "      </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "      <script>\n",
              "        async function quickchart(key) {\n",
              "          const quickchartButtonEl =\n",
              "            document.querySelector('#' + key + ' button');\n",
              "          quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "          quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "          try {\n",
              "            const charts = await google.colab.kernel.invokeFunction(\n",
              "                'suggestCharts', [key], {});\n",
              "          } catch (error) {\n",
              "            console.error('Error during call to suggestCharts:', error);\n",
              "          }\n",
              "          quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "          quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "        }\n",
              "        (() => {\n",
              "          let quickchartButtonEl =\n",
              "            document.querySelector('#df-5f667880-bb13-4b0d-8820-afc315ff72ea button');\n",
              "          quickchartButtonEl.style.display =\n",
              "            google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "        })();\n",
              "      </script>\n",
              "    </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "data"
            }
          },
          "metadata": {},
          "execution_count": 12
        }
      ],
      "source": [
        "#shuffle rows of dataframe\n",
        "sampler=np.random.permutation(len(data))\n",
        "data=data.take(sampler)\n",
        "data.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vxRacyPkwgfH"
      },
      "outputs": [],
      "source": [
        "Y=data['type']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 256
        },
        "id": "UBhpnzcKImL4",
        "outputId": "176d3bde-c668-474c-8cb9-e9d7ea1d441e"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "        MI_dir_L5_weight  MI_dir_L5_mean  MI_dir_L5_variance  \\\n",
              "152608        117.522186       71.477471           28.993132   \n",
              "92586           1.000000       60.000000            0.000000   \n",
              "45617         150.948689       81.631268         4512.842091   \n",
              "210722        175.064384       74.030988            0.742760   \n",
              "27737         104.561981      502.892895        22634.952677   \n",
              "\n",
              "        MI_dir_L3_weight  MI_dir_L3_mean  MI_dir_L3_variance  \\\n",
              "152608        208.923071       70.476367           36.951138   \n",
              "92586           1.000000       60.000000            0.000000   \n",
              "45617         248.464129       81.979615         5438.547797   \n",
              "210722        284.711691       74.038486            0.922184   \n",
              "27737         188.629431      462.041639        36970.631789   \n",
              "\n",
              "        MI_dir_L1_weight  MI_dir_L1_mean  MI_dir_L1_variance  \\\n",
              "152608        665.669226       69.668129           41.899178   \n",
              "92586           1.000000       60.000000            0.000000   \n",
              "45617         769.310221       79.023258         3752.221894   \n",
              "210722        839.588503       74.042024            1.279972   \n",
              "27737         615.649871      410.622629        50265.752941   \n",
              "\n",
              "        MI_dir_L0.1_weight  ...  HpHp_L0.1_radius  HpHp_L0.1_covariance  \\\n",
              "152608         6701.016815  ...               0.0                   0.0   \n",
              "92586             1.000000  ...               0.0                   0.0   \n",
              "45617          6361.660822  ...               0.0                   0.0   \n",
              "210722         5358.725479  ...               0.0                   0.0   \n",
              "27737          5149.677953  ...               0.0                   0.0   \n",
              "\n",
              "        HpHp_L0.1_pcc  HpHp_L0.01_weight  HpHp_L0.01_mean  HpHp_L0.01_std  \\\n",
              "152608            0.0                1.0             74.0             0.0   \n",
              "92586             0.0                1.0             60.0             0.0   \n",
              "45617             0.0                1.0             74.0             0.0   \n",
              "210722            0.0                1.0             74.0             0.0   \n",
              "27737             0.0                1.0            554.0             0.0   \n",
              "\n",
              "        HpHp_L0.01_magnitude  HpHp_L0.01_radius  HpHp_L0.01_covariance  \\\n",
              "152608                  74.0                0.0                    0.0   \n",
              "92586                   60.0                0.0                    0.0   \n",
              "45617                   74.0                0.0                    0.0   \n",
              "210722                  74.0                0.0                    0.0   \n",
              "27737                  554.0                0.0                    0.0   \n",
              "\n",
              "        HpHp_L0.01_pcc  \n",
              "152608             0.0  \n",
              "92586              0.0  \n",
              "45617              0.0  \n",
              "210722             0.0  \n",
              "27737              0.0  \n",
              "\n",
              "[5 rows x 115 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-a18dcb7e-7d98-4ea6-8441-606079c9baa7\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>MI_dir_L5_weight</th>\n",
              "      <th>MI_dir_L5_mean</th>\n",
              "      <th>MI_dir_L5_variance</th>\n",
              "      <th>MI_dir_L3_weight</th>\n",
              "      <th>MI_dir_L3_mean</th>\n",
              "      <th>MI_dir_L3_variance</th>\n",
              "      <th>MI_dir_L1_weight</th>\n",
              "      <th>MI_dir_L1_mean</th>\n",
              "      <th>MI_dir_L1_variance</th>\n",
              "      <th>MI_dir_L0.1_weight</th>\n",
              "      <th>...</th>\n",
              "      <th>HpHp_L0.1_radius</th>\n",
              "      <th>HpHp_L0.1_covariance</th>\n",
              "      <th>HpHp_L0.1_pcc</th>\n",
              "      <th>HpHp_L0.01_weight</th>\n",
              "      <th>HpHp_L0.01_mean</th>\n",
              "      <th>HpHp_L0.01_std</th>\n",
              "      <th>HpHp_L0.01_magnitude</th>\n",
              "      <th>HpHp_L0.01_radius</th>\n",
              "      <th>HpHp_L0.01_covariance</th>\n",
              "      <th>HpHp_L0.01_pcc</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>152608</th>\n",
              "      <td>117.522186</td>\n",
              "      <td>71.477471</td>\n",
              "      <td>28.993132</td>\n",
              "      <td>208.923071</td>\n",
              "      <td>70.476367</td>\n",
              "      <td>36.951138</td>\n",
              "      <td>665.669226</td>\n",
              "      <td>69.668129</td>\n",
              "      <td>41.899178</td>\n",
              "      <td>6701.016815</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>74.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>74.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>92586</th>\n",
              "      <td>1.000000</td>\n",
              "      <td>60.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>60.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>60.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>60.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>60.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>45617</th>\n",
              "      <td>150.948689</td>\n",
              "      <td>81.631268</td>\n",
              "      <td>4512.842091</td>\n",
              "      <td>248.464129</td>\n",
              "      <td>81.979615</td>\n",
              "      <td>5438.547797</td>\n",
              "      <td>769.310221</td>\n",
              "      <td>79.023258</td>\n",
              "      <td>3752.221894</td>\n",
              "      <td>6361.660822</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>74.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>74.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>210722</th>\n",
              "      <td>175.064384</td>\n",
              "      <td>74.030988</td>\n",
              "      <td>0.742760</td>\n",
              "      <td>284.711691</td>\n",
              "      <td>74.038486</td>\n",
              "      <td>0.922184</td>\n",
              "      <td>839.588503</td>\n",
              "      <td>74.042024</td>\n",
              "      <td>1.279972</td>\n",
              "      <td>5358.725479</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>74.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>74.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>27737</th>\n",
              "      <td>104.561981</td>\n",
              "      <td>502.892895</td>\n",
              "      <td>22634.952677</td>\n",
              "      <td>188.629431</td>\n",
              "      <td>462.041639</td>\n",
              "      <td>36970.631789</td>\n",
              "      <td>615.649871</td>\n",
              "      <td>410.622629</td>\n",
              "      <td>50265.752941</td>\n",
              "      <td>5149.677953</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>554.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>554.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5 rows × 115 columns</p>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-a18dcb7e-7d98-4ea6-8441-606079c9baa7')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-a18dcb7e-7d98-4ea6-8441-606079c9baa7 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-a18dcb7e-7d98-4ea6-8441-606079c9baa7');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "    <div id=\"df-4897d069-49ea-4f91-8cc2-c02a1c9d2f95\">\n",
              "      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-4897d069-49ea-4f91-8cc2-c02a1c9d2f95')\"\n",
              "                title=\"Suggest charts\"\n",
              "                style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "      </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "      <script>\n",
              "        async function quickchart(key) {\n",
              "          const quickchartButtonEl =\n",
              "            document.querySelector('#' + key + ' button');\n",
              "          quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "          quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "          try {\n",
              "            const charts = await google.colab.kernel.invokeFunction(\n",
              "                'suggestCharts', [key], {});\n",
              "          } catch (error) {\n",
              "            console.error('Error during call to suggestCharts:', error);\n",
              "          }\n",
              "          quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "          quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "        }\n",
              "        (() => {\n",
              "          let quickchartButtonEl =\n",
              "            document.querySelector('#df-4897d069-49ea-4f91-8cc2-c02a1c9d2f95 button');\n",
              "          quickchartButtonEl.style.display =\n",
              "            google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "        })();\n",
              "      </script>\n",
              "    </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "X"
            }
          },
          "metadata": {},
          "execution_count": 14
        }
      ],
      "source": [
        "#drop labels from training dataset\n",
        "X=data.drop(columns='type')\n",
        "X.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rlkwKK7Ep6vF",
        "outputId": "ded3f2bc-0427-40d4-d2fe-b91a9da553ee"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(322007, 115)"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ],
      "source": [
        "X.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CC1qGJ54xDkQ",
        "outputId": "6884f80a-a30f-4573-82ab-38aeb8240b27"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(322007,)"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ],
      "source": [
        "Y.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 241
        },
        "id": "tUkMfaaVdC9U",
        "outputId": "41809db8-cb64-4420-f8c8-54170139611e"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "152608       mirai_syn\n",
              "92586       gafgyt_tcp\n",
              "45617     gafgyt_combo\n",
              "210722     gafgyt_junk\n",
              "27737        mirai_udp\n",
              "Name: type, dtype: object"
            ],
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>type</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>152608</th>\n",
              "      <td>mirai_syn</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>92586</th>\n",
              "      <td>gafgyt_tcp</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>45617</th>\n",
              "      <td>gafgyt_combo</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>210722</th>\n",
              "      <td>gafgyt_junk</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>27737</th>\n",
              "      <td>mirai_udp</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div><br><label><b>dtype:</b> object</label>"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ],
      "source": [
        "Y.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zMLhU6IhVNF3"
      },
      "source": [
        "**ANOVA Feature selection method**\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qk0Tw7enPECp"
      },
      "outputs": [],
      "source": [
        "from sklearn.feature_selection import SelectKBest, SelectPercentile, chi2, f_classif, mutual_info_classif\n",
        "from sklearn.feature_selection import VarianceThreshold\n",
        "from sklearn.preprocessing import StandardScaler, LabelEncoder"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mQCn63skWI6r"
      },
      "outputs": [],
      "source": [
        "# Apply SelectKBest with the ANOVA F-test\n",
        "k = 40  # Define the number of top features to select\n",
        "selector = SelectKBest(score_func=f_classif, k=k)\n",
        "X_selected_A = selector.fit_transform(X,Y)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5eCGcXp8VLNS"
      },
      "outputs": [],
      "source": [
        "# Get selected feature indices and scores\n",
        "selected_indices = selector.get_support(indices=True)\n",
        "selected_feature_names = X.columns[selected_indices]\n",
        "selected_scores = selector.scores_[selected_indices]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "csi2pbRsVLRD",
        "outputId": "a0a4b529-edd3-485d-9e72-51d37c237be3"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Selected top-k features based on ANOVA F-test:\n",
            "Feature: MI_dir_L5_weight, Score: 168338.93272887467\n",
            "Feature: MI_dir_L5_mean, Score: 186724.37601253967\n",
            "Feature: MI_dir_L5_variance, Score: 131342.74967932398\n",
            "Feature: MI_dir_L3_weight, Score: 284384.3489466965\n",
            "Feature: MI_dir_L3_mean, Score: 310941.36149062286\n",
            "Feature: MI_dir_L3_variance, Score: 285072.0067426502\n",
            "Feature: MI_dir_L1_weight, Score: 588950.6277224141\n",
            "Feature: MI_dir_L1_mean, Score: 655567.8101788332\n",
            "Feature: MI_dir_L1_variance, Score: 1027001.8627276478\n",
            "Feature: MI_dir_L0.1_weight, Score: 482357.39148207\n",
            "Feature: MI_dir_L0.1_mean, Score: 1130264.0510009397\n",
            "Feature: MI_dir_L0.1_variance, Score: 1820799.5052792858\n",
            "Feature: MI_dir_L0.01_weight, Score: 93230.71027722489\n",
            "Feature: MI_dir_L0.01_mean, Score: 1480982.9325627752\n",
            "Feature: MI_dir_L0.01_variance, Score: 1788071.5839490716\n",
            "Feature: H_L5_weight, Score: 168338.93272887246\n",
            "Feature: H_L5_mean, Score: 186724.37601264502\n",
            "Feature: H_L5_variance, Score: 131342.74967932352\n",
            "Feature: H_L3_weight, Score: 284384.3489439551\n",
            "Feature: H_L3_mean, Score: 310941.3617611152\n",
            "Feature: H_L3_variance, Score: 285072.00674179074\n",
            "Feature: H_L1_weight, Score: 588950.625817548\n",
            "Feature: H_L1_mean, Score: 655568.9960800189\n",
            "Feature: H_L1_variance, Score: 1027001.8636339938\n",
            "Feature: H_L0.1_weight, Score: 482357.3806415589\n",
            "Feature: H_L0.1_mean, Score: 1131143.7727987564\n",
            "Feature: H_L0.1_variance, Score: 1820798.078470978\n",
            "Feature: H_L0.01_weight, Score: 93230.70868062855\n",
            "Feature: H_L0.01_mean, Score: 1486490.7145014314\n",
            "Feature: H_L0.01_variance, Score: 1788021.3736222524\n",
            "Feature: HH_L5_weight, Score: 108551.7601059172\n",
            "Feature: HH_L3_weight, Score: 116593.58826768216\n",
            "Feature: HH_L1_weight, Score: 122024.75646981636\n",
            "Feature: HH_L0.1_weight, Score: 86555.6064020959\n",
            "Feature: HH_jit_L5_weight, Score: 108551.76010591694\n",
            "Feature: HH_jit_L3_weight, Score: 116593.58826768238\n",
            "Feature: HH_jit_L1_weight, Score: 122024.7564698159\n",
            "Feature: HH_jit_L0.1_weight, Score: 86555.60640209638\n",
            "Feature: HH_jit_L0.01_mean, Score: 47501.41889517921\n",
            "Feature: HH_jit_L0.01_variance, Score: 46670.95607529165\n"
          ]
        }
      ],
      "source": [
        "# Display selected features and their ANOVA F-scores\n",
        "print(\"Selected top-k features based on ANOVA F-test:\")\n",
        "for feature, score in zip(selected_feature_names, selected_scores):\n",
        "    print(f\"Feature: {feature}, Score: {score}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NEQki2ybVLUc"
      },
      "outputs": [],
      "source": [
        "# Create a DataFrame with selected features\n",
        "X_selected_dfA = pd.DataFrame(X_selected_A, columns=selected_feature_names)\n",
        "\n",
        "selected_data_A = pd.concat([X_selected_dfA, Y.reset_index(drop=True)], axis=1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 290
        },
        "id": "7ePcJnDMVLX1",
        "outputId": "9a3b6b32-06da-4cb6-98a1-e4936e121037"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "DataFrame with selected features and target label:\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "   MI_dir_L5_weight  MI_dir_L5_mean  MI_dir_L5_variance  MI_dir_L3_weight  \\\n",
              "0        117.522186       71.477471           28.993132        208.923071   \n",
              "1          1.000000       60.000000            0.000000          1.000000   \n",
              "2        150.948689       81.631268         4512.842091        248.464129   \n",
              "3        175.064384       74.030988            0.742760        284.711691   \n",
              "4        104.561981      502.892895        22634.952677        188.629431   \n",
              "\n",
              "   MI_dir_L3_mean  MI_dir_L3_variance  MI_dir_L1_weight  MI_dir_L1_mean  \\\n",
              "0       70.476367           36.951138        665.669226       69.668129   \n",
              "1       60.000000            0.000000          1.000000       60.000000   \n",
              "2       81.979615         5438.547797        769.310221       79.023258   \n",
              "3       74.038486            0.922184        839.588503       74.042024   \n",
              "4      462.041639        36970.631789        615.649871      410.622629   \n",
              "\n",
              "   MI_dir_L1_variance  MI_dir_L0.1_weight  ...  HH_L3_weight  HH_L1_weight  \\\n",
              "0           41.899178         6701.016815  ...    155.798467    458.829215   \n",
              "1            0.000000            1.000000  ...      1.000000      1.000000   \n",
              "2         3752.221894         6361.660822  ...    244.256425    761.786643   \n",
              "3            1.279972         5358.725479  ...    284.255133    838.133685   \n",
              "4        50265.752941         5149.677953  ...    153.515570    436.949505   \n",
              "\n",
              "   HH_L0.1_weight  HH_jit_L5_weight  HH_jit_L3_weight  HH_jit_L1_weight  \\\n",
              "0     4517.635928         96.003774        155.798467        458.829215   \n",
              "1        1.000000          1.000000          1.000000          1.000000   \n",
              "2     6333.819080        148.026309        244.256425        761.786643   \n",
              "3     5346.683154        174.838344        284.255133        838.133685   \n",
              "4     3396.559490         93.744441        153.515570        436.949505   \n",
              "\n",
              "   HH_jit_L0.1_weight  HH_jit_L0.01_mean  HH_jit_L0.01_variance          type  \n",
              "0         4517.635928       4.209805e+04           6.346764e+13     mirai_syn  \n",
              "1            1.000000       1.505914e+09           0.000000e+00    gafgyt_tcp  \n",
              "2         6333.819080       8.415063e+04           1.267165e+14  gafgyt_combo  \n",
              "3         5346.683154       1.709032e+05           2.573363e+14   gafgyt_junk  \n",
              "4         3396.559490       2.007616e+05           3.026391e+14     mirai_udp  \n",
              "\n",
              "[5 rows x 41 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-f6b75039-3192-430d-af61-e4b76f9692ac\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>MI_dir_L5_weight</th>\n",
              "      <th>MI_dir_L5_mean</th>\n",
              "      <th>MI_dir_L5_variance</th>\n",
              "      <th>MI_dir_L3_weight</th>\n",
              "      <th>MI_dir_L3_mean</th>\n",
              "      <th>MI_dir_L3_variance</th>\n",
              "      <th>MI_dir_L1_weight</th>\n",
              "      <th>MI_dir_L1_mean</th>\n",
              "      <th>MI_dir_L1_variance</th>\n",
              "      <th>MI_dir_L0.1_weight</th>\n",
              "      <th>...</th>\n",
              "      <th>HH_L3_weight</th>\n",
              "      <th>HH_L1_weight</th>\n",
              "      <th>HH_L0.1_weight</th>\n",
              "      <th>HH_jit_L5_weight</th>\n",
              "      <th>HH_jit_L3_weight</th>\n",
              "      <th>HH_jit_L1_weight</th>\n",
              "      <th>HH_jit_L0.1_weight</th>\n",
              "      <th>HH_jit_L0.01_mean</th>\n",
              "      <th>HH_jit_L0.01_variance</th>\n",
              "      <th>type</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>117.522186</td>\n",
              "      <td>71.477471</td>\n",
              "      <td>28.993132</td>\n",
              "      <td>208.923071</td>\n",
              "      <td>70.476367</td>\n",
              "      <td>36.951138</td>\n",
              "      <td>665.669226</td>\n",
              "      <td>69.668129</td>\n",
              "      <td>41.899178</td>\n",
              "      <td>6701.016815</td>\n",
              "      <td>...</td>\n",
              "      <td>155.798467</td>\n",
              "      <td>458.829215</td>\n",
              "      <td>4517.635928</td>\n",
              "      <td>96.003774</td>\n",
              "      <td>155.798467</td>\n",
              "      <td>458.829215</td>\n",
              "      <td>4517.635928</td>\n",
              "      <td>4.209805e+04</td>\n",
              "      <td>6.346764e+13</td>\n",
              "      <td>mirai_syn</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1.000000</td>\n",
              "      <td>60.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>60.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>60.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>...</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.505914e+09</td>\n",
              "      <td>0.000000e+00</td>\n",
              "      <td>gafgyt_tcp</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>150.948689</td>\n",
              "      <td>81.631268</td>\n",
              "      <td>4512.842091</td>\n",
              "      <td>248.464129</td>\n",
              "      <td>81.979615</td>\n",
              "      <td>5438.547797</td>\n",
              "      <td>769.310221</td>\n",
              "      <td>79.023258</td>\n",
              "      <td>3752.221894</td>\n",
              "      <td>6361.660822</td>\n",
              "      <td>...</td>\n",
              "      <td>244.256425</td>\n",
              "      <td>761.786643</td>\n",
              "      <td>6333.819080</td>\n",
              "      <td>148.026309</td>\n",
              "      <td>244.256425</td>\n",
              "      <td>761.786643</td>\n",
              "      <td>6333.819080</td>\n",
              "      <td>8.415063e+04</td>\n",
              "      <td>1.267165e+14</td>\n",
              "      <td>gafgyt_combo</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>175.064384</td>\n",
              "      <td>74.030988</td>\n",
              "      <td>0.742760</td>\n",
              "      <td>284.711691</td>\n",
              "      <td>74.038486</td>\n",
              "      <td>0.922184</td>\n",
              "      <td>839.588503</td>\n",
              "      <td>74.042024</td>\n",
              "      <td>1.279972</td>\n",
              "      <td>5358.725479</td>\n",
              "      <td>...</td>\n",
              "      <td>284.255133</td>\n",
              "      <td>838.133685</td>\n",
              "      <td>5346.683154</td>\n",
              "      <td>174.838344</td>\n",
              "      <td>284.255133</td>\n",
              "      <td>838.133685</td>\n",
              "      <td>5346.683154</td>\n",
              "      <td>1.709032e+05</td>\n",
              "      <td>2.573363e+14</td>\n",
              "      <td>gafgyt_junk</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>104.561981</td>\n",
              "      <td>502.892895</td>\n",
              "      <td>22634.952677</td>\n",
              "      <td>188.629431</td>\n",
              "      <td>462.041639</td>\n",
              "      <td>36970.631789</td>\n",
              "      <td>615.649871</td>\n",
              "      <td>410.622629</td>\n",
              "      <td>50265.752941</td>\n",
              "      <td>5149.677953</td>\n",
              "      <td>...</td>\n",
              "      <td>153.515570</td>\n",
              "      <td>436.949505</td>\n",
              "      <td>3396.559490</td>\n",
              "      <td>93.744441</td>\n",
              "      <td>153.515570</td>\n",
              "      <td>436.949505</td>\n",
              "      <td>3396.559490</td>\n",
              "      <td>2.007616e+05</td>\n",
              "      <td>3.026391e+14</td>\n",
              "      <td>mirai_udp</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5 rows × 41 columns</p>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-f6b75039-3192-430d-af61-e4b76f9692ac')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-f6b75039-3192-430d-af61-e4b76f9692ac button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-f6b75039-3192-430d-af61-e4b76f9692ac');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "    <div id=\"df-db2f5720-e43e-45a9-8fe2-ca026a0395e3\">\n",
              "      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-db2f5720-e43e-45a9-8fe2-ca026a0395e3')\"\n",
              "                title=\"Suggest charts\"\n",
              "                style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "      </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "      <script>\n",
              "        async function quickchart(key) {\n",
              "          const quickchartButtonEl =\n",
              "            document.querySelector('#' + key + ' button');\n",
              "          quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "          quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "          try {\n",
              "            const charts = await google.colab.kernel.invokeFunction(\n",
              "                'suggestCharts', [key], {});\n",
              "          } catch (error) {\n",
              "            console.error('Error during call to suggestCharts:', error);\n",
              "          }\n",
              "          quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "          quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "        }\n",
              "        (() => {\n",
              "          let quickchartButtonEl =\n",
              "            document.querySelector('#df-db2f5720-e43e-45a9-8fe2-ca026a0395e3 button');\n",
              "          quickchartButtonEl.style.display =\n",
              "            google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "        })();\n",
              "      </script>\n",
              "    </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "selected_data_A"
            }
          },
          "metadata": {},
          "execution_count": 23
        }
      ],
      "source": [
        "print(\"\\nDataFrame with selected features and target label:\")\n",
        "selected_data_A.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VPJEX-D1nILU"
      },
      "source": [
        "**Split learning Model using pearson ANOVA-F based feature selection**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "D4234ejIzk5V"
      },
      "outputs": [],
      "source": [
        "# Convert application names to numbers\n",
        "encoder = LabelEncoder()\n",
        "encoder.fit(Y)\n",
        "encoded_Y = encoder.transform(Y)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ODxE56TI0iWa",
        "outputId": "a079e072-95bc-459d-9c90-b55ec63ed5cc"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[('benign', 24177), ('gafgyt_combo', 29780), ('gafgyt_junk', 28240), ('gafgyt_scan', 29210), ('gafgyt_tcp', 28532), ('gafgyt_udp', 31328), ('mirai_ack', 31407), ('mirai_scan', 22704), ('mirai_syn', 36758), ('mirai_udp', 31580), ('mirai_udpplain', 28291)]\n"
          ]
        }
      ],
      "source": [
        "print(sorted(Counter(Y).items()))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hjLsV6E4zmLx"
      },
      "outputs": [],
      "source": [
        "smote = SMOTE(sampling_strategy='auto', random_state=42)\n",
        "X_resampled, y_resampled = smote.fit_resample(X_selected_dfA, encoded_Y)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RrychZk2zmO5",
        "outputId": "8e719d03-a5ba-4380-872d-7b47aa6bc411"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[(np.int64(0), 24177), (np.int64(1), 29780), (np.int64(2), 28240), (np.int64(3), 29210), (np.int64(4), 28532), (np.int64(5), 31328), (np.int64(6), 31407), (np.int64(7), 22704), (np.int64(8), 36758), (np.int64(9), 31580), (np.int64(10), 28291)]\n"
          ]
        }
      ],
      "source": [
        "print(sorted(Counter(encoded_Y).items()))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gv3MHntt4qQz",
        "outputId": "ba7448f8-e403-4f5f-8d74-b13cf134ca9b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[(np.int64(0), 36758), (np.int64(1), 36758), (np.int64(2), 36758), (np.int64(3), 36758), (np.int64(4), 36758), (np.int64(5), 36758), (np.int64(6), 36758), (np.int64(7), 36758), (np.int64(8), 36758), (np.int64(9), 36758), (np.int64(10), 36758)]\n"
          ]
        }
      ],
      "source": [
        "print(sorted(Counter(y_resampled).items()))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Huxo1pYzzmR1",
        "outputId": "7755839c-a24c-40b8-9313-a4487ee91bee"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([4, 1, 2, 9, 6, 8, 4, 6, 7])"
            ]
          },
          "metadata": {},
          "execution_count": 30
        }
      ],
      "source": [
        "encoded_Y[1:10]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MfV6rXCI1f_F",
        "outputId": "a872a8d9-2caa-4134-d7d8-9e4e1d786ba1"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(404338, 40)"
            ]
          },
          "metadata": {},
          "execution_count": 31
        }
      ],
      "source": [
        "X_resampled.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Md3RPXLF1gCl",
        "outputId": "b26df6a2-5ece-4695-bd04-cf15bb0787a3"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(404338,)"
            ]
          },
          "metadata": {},
          "execution_count": 32
        }
      ],
      "source": [
        " y_resampled.shape\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8Ihfq5rEVLg7"
      },
      "outputs": [],
      "source": [
        "#split data\n",
        "from sklearn.model_selection import train_test_split\n",
        "X_train, X_test, y_train, y_test,= train_test_split(X_resampled, y_resampled, train_size = 0.70, random_state=100)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mTG_CfygstP1"
      },
      "outputs": [],
      "source": [
        "# Data Transformation to Reduce Skewness\n",
        "power_transformer = PowerTransformer(method='yeo-johnson')\n",
        "X_train_transformed = power_transformer.fit_transform(X_train)\n",
        "X_test_transformed = power_transformer.transform(X_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "X0aOdT1TstU4"
      },
      "outputs": [],
      "source": [
        "# Standard Scaling After Transformation\n",
        "scaler = StandardScaler()\n",
        "X_train_scaled = scaler.fit_transform(X_train_transformed)\n",
        "X_test_scaled = scaler.transform(X_test_transformed)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-ZgGNdmcbzaO"
      },
      "outputs": [],
      "source": [
        "y_train=tf.keras.utils.to_categorical(y_train, num_classes=11)\n",
        "y_test = tf.keras.utils.to_categorical(y_test, num_classes=11)  # One-hot encoding for test labels"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y_train[1:10]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XRYljQRZ03TG",
        "outputId": "27468b95-c089-420b-f1e6-fa35fe7046cc"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0.],\n",
              "       [0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
              "       [0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0.],\n",
              "       [0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0.],\n",
              "       [0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0.],\n",
              "       [0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
              "       [0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0.],\n",
              "       [0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0.],\n",
              "       [0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0.]])"
            ]
          },
          "metadata": {},
          "execution_count": 38
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5KQZ8U8I7cCn",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "fa9a365a-b240-44c7-cd6d-7a3434f43e83"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/61.0 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m61.0/61.0 kB\u001b[0m \u001b[31m4.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m242.5/242.5 kB\u001b[0m \u001b[31m8.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m18.3/18.3 MB\u001b[0m \u001b[31m105.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "thinc 8.3.6 requires numpy<3.0.0,>=2.0.0, but you have numpy 1.26.4 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0m"
          ]
        }
      ],
      "source": [
        "! pip install -q tensorflow-model-optimization"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "***Dt:23/04/25***\n"
      ],
      "metadata": {
        "id": "obnaaCBj2QMx"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "E4ig60K1HPjd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "UrmGwz6fJ4sa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gG2zHtgtdW_I"
      },
      "outputs": [],
      "source": [
        "import socket\n",
        "import pickle\n",
        "import zlib\n",
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "from tensorflow.keras import Sequential\n",
        "from tensorflow.keras.layers import MaxPooling1D, Flatten, Dense, BatchNormalization\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "import threading\n",
        "from sklearn.metrics import precision_score, recall_score, f1_score\n",
        "from tensorflow.keras.layers import Dropout\n",
        "\n",
        "# Server-side model\n",
        "def create_server_model():\n",
        "    model = Sequential([\n",
        "        MaxPooling1D(pool_size=2,input_shape=(20, 64)),\n",
        "        Conv1D(128, kernel_size=3, activation='relu',padding='same'),\n",
        "        BatchNormalization(),\n",
        "        Conv1D(128, kernel_size=3, activation='relu',padding='same'),\n",
        "        BatchNormalization(),\n",
        "        MaxPooling1D(pool_size=2),\n",
        "        Conv1D(256, kernel_size=3, activation='relu',padding='same'),\n",
        "        BatchNormalization(),\n",
        "        Conv1D(256, kernel_size=3, activation='relu',padding='same'),\n",
        "        BatchNormalization(),\n",
        "        MaxPooling1D(pool_size=2),\n",
        "        Flatten(),\n",
        "        Dense(256, activation='relu'),\n",
        "        Dropout(0.3),\n",
        "        Dense(128, activation='relu'),\n",
        "        Dropout(0.2),\n",
        "        Dense(11, activation='softmax')\n",
        "    ])\n",
        "    model.compile(optimizer=Adam(learning_rate=0.001),\n",
        "                  loss='categorical_crossentropy',\n",
        "                  metrics=['accuracy'])\n",
        "    return model\n",
        "\n",
        "# Deserialize and decompress data\n",
        "def deserialize_data(data):\n",
        "    return pickle.loads(zlib.decompress(data))\n",
        "\n",
        "# Server function\n",
        "def start_server(host='127.0.0.1', port=65438):\n",
        "    server_model = create_server_model()\n",
        "    server_socket = socket.socket(socket.AF_INET, socket.SOCK_STREAM)\n",
        "    server_socket.bind((host, port))\n",
        "    server_socket.listen(1)\n",
        "    print(\"Server waiting for connection...\")\n",
        "    conn, addr = server_socket.accept()\n",
        "    print(f\"Connected to client: {addr}\")\n",
        "    lr_schedule = tf.keras.optimizers.schedules.ExponentialDecay(\n",
        "    initial_learning_rate=0.001,\n",
        "    decay_steps=10000,\n",
        "    decay_rate=0.9\n",
        "    )\n",
        "    optimizer = tf.keras.optimizers.Adam(learning_rate=lr_schedule)\n",
        "\n",
        "    all_true_labels = []\n",
        "    all_pred_labels = []\n",
        "\n",
        "\n",
        "    while True:\n",
        "        try:\n",
        "            # Receive header indicating batch size\n",
        "            header = conn.recv(8)\n",
        "            if not header:\n",
        "                break\n",
        "            data_size = int(header.decode('utf-8').strip())\n",
        "\n",
        "\n",
        "            # If a special flag (e.g., -1) is sent, switch to evaluation\n",
        "            if data_size == -1:\n",
        "              print(\"Switching to evaluation phase...\")\n",
        "              break\n",
        "\n",
        "            # Receive the batch data\n",
        "            data = b\"\"\n",
        "            while len(data) < data_size:\n",
        "                packet = conn.recv(4096)\n",
        "                if not packet:\n",
        "                    break\n",
        "                data += packet\n",
        "\n",
        "            # Deserialize the data\n",
        "            intermediate_output, labels = deserialize_data(data)\n",
        "\n",
        "            # Perform forward pass and backpropagation on batch\n",
        "            with tf.GradientTape() as tape:\n",
        "                logits = server_model(np.array(intermediate_output), training=True)\n",
        "                loss = tf.reduce_mean(\n",
        "                    tf.keras.losses.categorical_crossentropy(np.array(labels), logits)\n",
        "                )\n",
        "            gradients = tape.gradient(loss, server_model.trainable_variables)\n",
        "            optimizer.apply_gradients(zip(gradients, server_model.trainable_variables))\n",
        "\n",
        "            pred_classes = np.argmax(logits.numpy(), axis=1)\n",
        "            true_classes = np.argmax(labels, axis=1)\n",
        "\n",
        "            all_pred_labels.extend(pred_classes)\n",
        "            all_true_labels.extend(true_classes)\n",
        "\n",
        "            correct_predictions = int(np.sum(\n",
        "                np.argmax(logits.numpy(), axis=1) == np.argmax(labels, axis=1)\n",
        "            ))\n",
        "            response = f\"{loss.numpy():.4f},{correct_predictions}\"\n",
        "            conn.sendall(f\"{len(response):08}\".encode('utf-8'))\n",
        "            conn.sendall(response.encode('utf-8'))\n",
        "\n",
        "        except Exception as e:\n",
        "            print(f\"Error: {e}\")\n",
        "            break\n",
        "\n",
        "    # At the end of training\n",
        "    precision = precision_score(all_true_labels, all_pred_labels, average='macro')\n",
        "    recall = recall_score(all_true_labels, all_pred_labels, average='macro')\n",
        "    f1 = f1_score(all_true_labels, all_pred_labels, average='macro')\n",
        "    print(f\"\\nTraining Metrics → Precision: {precision:.4f}, Recall: {recall:.4f}, F1 Score: {f1:.4f}\")\n",
        "\n",
        "    # Handle test evaluation\n",
        "    print(\"Evaluating test data...\")\n",
        "\n",
        "    all_test_true = []\n",
        "    all_test_pred = []\n",
        "\n",
        "    while True:\n",
        "        header = conn.recv(8)\n",
        "        if not header:\n",
        "            break\n",
        "        test_data_size = int(header.decode('utf-8').strip())\n",
        "        test_data = b\"\"\n",
        "        while len(test_data) < test_data_size:\n",
        "            packet = conn.recv(4096)\n",
        "            if not packet:\n",
        "                break\n",
        "            test_data += packet\n",
        "\n",
        "        test_intermediate, test_labels = deserialize_data(test_data)\n",
        "        logits = server_model(np.array(test_intermediate), training=False)\n",
        "\n",
        "        test_intermediate = np.array(test_intermediate)\n",
        "        test_labels = np.array(test_labels)\n",
        "\n",
        "        logits = server_model(test_intermediate, training=False)\n",
        "        pred_classes = np.argmax(logits.numpy(), axis=1)\n",
        "        true_classes = np.argmax(test_labels, axis=1)\n",
        "\n",
        "        all_test_pred.extend(pred_classes)\n",
        "        all_test_true.extend(true_classes)\n",
        "\n",
        "        correct_predictions = int(np.sum(\n",
        "            np.argmax(logits.numpy(), axis=1) == np.argmax(test_labels, axis=1)\n",
        "        ))\n",
        "        response = f\"{correct_predictions}\"\n",
        "        conn.sendall(f\"{len(response):08}\".encode('utf-8'))\n",
        "        conn.sendall(response.encode('utf-8'))\n",
        "\n",
        "    # Final test metrics\n",
        "    precision = precision_score(all_test_true, all_test_pred, average='macro')\n",
        "    recall = recall_score(all_test_true, all_test_pred, average='macro')\n",
        "    f1 = f1_score(all_test_true, all_test_pred, average='macro')\n",
        "    print(f\"\\nTesting Metrics → Precision: {precision:.4f}, Recall: {recall:.4f}, F1 Score: {f1:.4f}\")\n",
        "\n",
        "\n",
        "    conn.close()\n",
        "    server_socket.close()\n",
        "    print(\"Server connection closed.\")\n",
        "\n",
        "server_thread = threading.Thread(target=start_server)\n",
        "server_thread.start()\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "GAjSknDvJ4xo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0d40ae6b-2419-4a02-c127-c8ef569642f1",
        "id": "3UjmKGLpda-M"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Connected to server!Connected to client: ('127.0.0.1', 53536)\n",
            "\n",
            "\n",
            "Starting Training...\n",
            "\n",
            "Epoch 1/15\n",
            "Batch 553/553 - Progress: 100.00% - Loss: 0.1736\n",
            "Epoch 1 completed: Avg Loss = 0.2384, Training Accuracy = 0.8651\n",
            "\n",
            "Epoch 2/15\n",
            "Batch 553/553 - Progress: 100.00% - Loss: 0.2064\n",
            "Epoch 2 completed: Avg Loss = 0.1568, Training Accuracy = 0.8990\n",
            "\n",
            "Epoch 3/15\n",
            "Batch 553/553 - Progress: 100.00% - Loss: 0.1391\n",
            "Epoch 3 completed: Avg Loss = 0.1462, Training Accuracy = 0.9024\n",
            "\n",
            "Epoch 4/15\n",
            "Batch 553/553 - Progress: 100.00% - Loss: 0.1337\n",
            "Epoch 4 completed: Avg Loss = 0.1434, Training Accuracy = 0.9032\n",
            "\n",
            "Epoch 5/15\n",
            "Batch 553/553 - Progress: 100.00% - Loss: 0.1416\n",
            "Epoch 5 completed: Avg Loss = 0.1420, Training Accuracy = 0.9040\n",
            "\n",
            "Epoch 6/15\n",
            "Batch 553/553 - Progress: 100.00% - Loss: 0.1266\n",
            "Epoch 6 completed: Avg Loss = 0.1377, Training Accuracy = 0.9050\n",
            "\n",
            "Epoch 7/15\n",
            "Batch 553/553 - Progress: 100.00% - Loss: 0.1213\n",
            "Epoch 7 completed: Avg Loss = 0.1366, Training Accuracy = 0.9056\n",
            "\n",
            "Epoch 8/15\n",
            "Batch 553/553 - Progress: 100.00% - Loss: 0.1206\n",
            "Epoch 8 completed: Avg Loss = 0.1350, Training Accuracy = 0.9066\n",
            "\n",
            "Epoch 9/15\n",
            "Batch 553/553 - Progress: 100.00% - Loss: 0.1255\n",
            "Epoch 9 completed: Avg Loss = 0.1353, Training Accuracy = 0.9066\n",
            "\n",
            "Epoch 10/15\n",
            "Batch 553/553 - Progress: 100.00% - Loss: 0.1251\n",
            "Epoch 10 completed: Avg Loss = 0.1350, Training Accuracy = 0.9063\n",
            "\n",
            "Epoch 11/15\n",
            "Batch 553/553 - Progress: 100.00% - Loss: 0.1289\n",
            "Epoch 11 completed: Avg Loss = 0.1339, Training Accuracy = 0.9064\n",
            "\n",
            "Epoch 12/15\n",
            "Batch 553/553 - Progress: 100.00% - Loss: 0.1208\n",
            "Epoch 12 completed: Avg Loss = 0.1346, Training Accuracy = 0.9066\n",
            "\n",
            "Epoch 13/15\n",
            "Batch 553/553 - Progress: 100.00% - Loss: 0.1227\n",
            "Epoch 13 completed: Avg Loss = 0.1337, Training Accuracy = 0.9071\n",
            "\n",
            "Epoch 14/15\n",
            "Batch 553/553 - Progress: 100.00% - Loss: 0.1223\n",
            "Epoch 14 completed: Avg Loss = 0.1311, Training Accuracy = 0.9082\n",
            "\n",
            "Epoch 15/15\n",
            "Batch 553/553 - Progress: 100.00% - Loss: 0.1231\n",
            "Epoch 15 completed: Avg Loss = 0.1344, Training Accuracy = 0.9072\n",
            "\n",
            "Training completed in 8136.38 seconds.\n",
            "Switching to evaluation phase...\n",
            "Training complete. Signaled server to start evaluation.\n",
            "\n",
            "Evaluating on test data...\n",
            "\n",
            "Training Metrics → Precision: 0.9027, Recall: 0.9027, F1 Score: 0.9026\n",
            "Evaluating test data...\n",
            "\n",
            "Testing completed: Testing Accuracy = 0.8923\n",
            "\n",
            "Client connection closed.\n"
          ]
        }
      ],
      "source": [
        "import socket\n",
        "import pickle\n",
        "import zlib\n",
        "import time\n",
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "from tensorflow.keras import Sequential\n",
        "from tensorflow.keras.layers import Conv1D, MaxPooling1D, BatchNormalization\n",
        "from sklearn.model_selection import train_test_split\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "\n",
        "# Client-side model\n",
        "def create_client_model():\n",
        "    model = Sequential([\n",
        "        Conv1D(16, kernel_size=3, activation='relu', input_shape=(40, 1),padding='same'),\n",
        "        BatchNormalization(),\n",
        "        Conv1D(32, kernel_size=3, activation='relu',padding='same'),\n",
        "        BatchNormalization(),\n",
        "        #MaxPooling1D(pool_size=2),\n",
        "        Conv1D(32, kernel_size=3, activation='relu',padding='same'),\n",
        "        BatchNormalization(),\n",
        "        #MaxPooling1D(pool_size=2),\n",
        "        Conv1D(64, kernel_size=3, activation='relu',padding='same'),\n",
        "        BatchNormalization(),\n",
        "        Conv1D(64, kernel_size=3, activation='relu',padding='same'),\n",
        "        BatchNormalization(),\n",
        "        MaxPooling1D(pool_size=2),\n",
        "\n",
        "    ])\n",
        "    return model\n",
        "\n",
        "# Serialize and compress data using pickle\n",
        "def serialize_data(data):\n",
        "    return zlib.compress(pickle.dumps(data))\n",
        "\n",
        "# Client function\n",
        "def start_client(host='127.0.0.1', port=65438):\n",
        "    client_model = create_client_model()\n",
        "    client_socket = socket.socket(socket.AF_INET, socket.SOCK_STREAM)\n",
        "    client_socket.connect((host, port))\n",
        "    print(\"Connected to server!\")\n",
        "\n",
        "    batch_size = 512\n",
        "    epochs =  15\n",
        "    total_batches = int(np.ceil(X_train_scaled.shape[0] / batch_size))\n",
        "\n",
        "    print(\"\\nStarting Training...\")\n",
        "    start_time = time.time()\n",
        "\n",
        "    for epoch in range(epochs):\n",
        "        print(f\"\\nEpoch {epoch + 1}/{epochs}\")\n",
        "        epoch_loss = 0\n",
        "        correct_predictions = 0\n",
        "        total_samples = 0\n",
        "\n",
        "        for batch_index, i in enumerate(range(0, X_train_scaled.shape[0], batch_size), start=1):\n",
        "            x_batch = X_train_scaled[i:min(i + batch_size, X_train_scaled.shape[0])]\n",
        "            y_batch = y_train[i:min(i + batch_size, y_train.shape[0])]\n",
        "\n",
        "            # Forward pass to get intermediate activations\n",
        "            intermediate_output = client_model(x_batch, training=True).numpy()\n",
        "\n",
        "            # Serialize and send data\n",
        "            data = serialize_data((intermediate_output.tolist(), y_batch.tolist()))\n",
        "            client_socket.sendall(f\"{len(data):08}\".encode('utf-8'))\n",
        "            client_socket.sendall(data)\n",
        "\n",
        "            # Receive server response\n",
        "            response_header = client_socket.recv(8)\n",
        "            response_size = int(response_header.decode('utf-8').strip())\n",
        "            response = client_socket.recv(response_size)\n",
        "            server_loss, batch_correct = map(float, response.decode('utf-8').split(','))\n",
        "\n",
        "            # Update statistics\n",
        "            epoch_loss += server_loss\n",
        "            correct_predictions += batch_correct\n",
        "            total_samples += x_batch.shape[0]\n",
        "\n",
        "            # Display batch progress\n",
        "            progress = (batch_index / total_batches) * 100\n",
        "            print(f\"\\rBatch {batch_index}/{total_batches} - Progress: {progress:.2f}% - Loss: {server_loss:.4f}\", end=\"\")\n",
        "\n",
        "        training_accuracy = correct_predictions / total_samples\n",
        "        print(f\"\\nEpoch {epoch + 1} completed: Avg Loss = {epoch_loss / total_batches:.4f}, \"\n",
        "              f\"Training Accuracy = {training_accuracy:.4f}\")\n",
        "\n",
        "    total_training_time = time.time() - start_time\n",
        "    print(f\"\\nTraining completed in {total_training_time:.2f} seconds.\")\n",
        "\n",
        "    # Signal the server to switch to evaluation mode\n",
        "    client_socket.sendall(f\"{-1:08}\".encode('utf-8'))\n",
        "    print(\"Training complete. Signaled server to start evaluation.\")\n",
        "\n",
        "    # Evaluate testing accuracy in batches\n",
        "    print(\"\\nEvaluating on test data...\")\n",
        "    test_batch_size = 512  # Larger batch size for efficient testing\n",
        "    total_test_batches = int(np.ceil(X_test_scaled.shape[0] / test_batch_size))\n",
        "    correct_predictions = 0\n",
        "    total_samples = 0\n",
        "\n",
        "    for i in range(0, X_test_scaled.shape[0], test_batch_size):\n",
        "        x_test_batch = X_test_scaled[i:min(i + test_batch_size, X_test_scaled.shape[0])]\n",
        "        y_test_batch = y_test[i:min(i + test_batch_size, y_test.shape[0])]\n",
        "\n",
        "        test_intermediate = client_model.predict(x_test_batch, verbose=0)\n",
        "        test_data = serialize_data((test_intermediate.tolist(), y_test_batch.tolist()))\n",
        "\n",
        "        client_socket.sendall(f\"{len(test_data):08}\".encode('utf-8'))\n",
        "        client_socket.sendall(test_data)\n",
        "\n",
        "        # Receive test batch accuracy\n",
        "        test_accuracy_response = client_socket.recv(8)\n",
        "        test_accuracy_size = int(test_accuracy_response.decode('utf-8').strip())\n",
        "        test_accuracy_data = client_socket.recv(test_accuracy_size)\n",
        "        batch_correct = int(test_accuracy_data.decode('utf-8'))\n",
        "\n",
        "        correct_predictions += batch_correct\n",
        "        total_samples += x_test_batch.shape[0]\n",
        "\n",
        "    test_accuracy = correct_predictions / total_samples\n",
        "    print(f\"\\nTesting completed: Testing Accuracy = {test_accuracy:.4f}\")\n",
        "\n",
        "    client_socket.close()\n",
        "    print(\"\\nClient connection closed.\")\n",
        "\n",
        "# Start the client\n",
        "start_client()\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "QHSiXMHxJ43H"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "***Pruned Server-client Models***"
      ],
      "metadata": {
        "id": "j07P-UcjfkO_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "! pip install -q tensorflow-model-optimization"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LflbwIJ3fa_M",
        "outputId": "b4808003-9d09-456a-8215-c78cb203db4a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/61.0 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m61.0/61.0 kB\u001b[0m \u001b[31m2.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m242.5/242.5 kB\u001b[0m \u001b[31m13.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m18.3/18.3 MB\u001b[0m \u001b[31m103.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "thinc 8.3.6 requires numpy<3.0.0,>=2.0.0, but you have numpy 1.26.4 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0m"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "import tensorflow_model_optimization as tfmot\n",
        "import tf_keras as keras\n",
        "\n",
        "%load_ext tensorboard\n",
        "\n",
        "import tempfile"
      ],
      "metadata": {
        "id": "RWuap7siiUc6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_gzipped_model_size(file):\n",
        "  # Returns size of gzipped model, in bytes.\n",
        "  import os\n",
        "  import zipfile\n",
        "\n",
        "  _, zipped_file = tempfile.mkstemp('.zip')\n",
        "  with zipfile.ZipFile(zipped_file, 'w', compression=zipfile.ZIP_DEFLATED) as f:\n",
        "    f.write(file)\n",
        "\n",
        "  return os.path.getsize(zipped_file)"
      ],
      "metadata": {
        "id": "H7ceYDqHh-de"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "pcXgC5jch-mC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "wfSZ9p9Wh-4x"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "V5oI1yZEhCXz",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ca152e91-2b9b-472c-aebf-0f2efdb9046b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Exception in thread Thread-10 (start_server):\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/lib/python3.11/threading.py\", line 1045, in _bootstrap_inner\n",
            "    self.run()\n",
            "  File \"/usr/lib/python3.11/threading.py\", line 982, in run\n"
          ]
        }
      ],
      "source": [
        "import socket\n",
        "import pickle\n",
        "import zlib\n",
        "import tensorflow as tf\n",
        "import tf_keras as keras\n",
        "import tensorflow_model_optimization as tfmot\n",
        "import numpy as np\n",
        "from tensorflow.keras import Sequential\n",
        "from tensorflow.keras.layers import MaxPooling1D, Flatten, Dense, BatchNormalization\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "import threading\n",
        "from sklearn.metrics import precision_score, recall_score, f1_score\n",
        "from tensorflow.keras.layers import Dropout\n",
        "# Apply pruning\n",
        "prune_low_magnitude = tfmot.sparsity.keras.prune_low_magnitude\n",
        "\n",
        "# Server-side model\n",
        "def create_server_model():\n",
        "    model = keras.Sequential([\n",
        "        keras.layers.MaxPooling1D(pool_size=2,input_shape=(20, 64)),\n",
        "        keras.layers.Conv1D(128, kernel_size=3, activation='relu',padding='same'),\n",
        "        keras.layers.BatchNormalization(),\n",
        "        keras.layers.Conv1D(128, kernel_size=3, activation='relu',padding='same'),\n",
        "        keras.layers.BatchNormalization(),\n",
        "        keras.layers.MaxPooling1D(pool_size=2),\n",
        "        keras.layers.Conv1D(256, kernel_size=3, activation='relu',padding='same'),\n",
        "        keras.layers.BatchNormalization(),\n",
        "        keras.layers.Conv1D(256, kernel_size=3, activation='relu',padding='same'),\n",
        "        keras.layers.BatchNormalization(),\n",
        "        keras.layers.MaxPooling1D(pool_size=2),\n",
        "        keras.layers.Flatten(),\n",
        "        keras.layers.Dense(256, activation='relu'),\n",
        "        keras.layers.Dropout(0.3),\n",
        "        keras.layers.Dense(128, activation='relu'),\n",
        "        keras.layers.Dropout(0.2),\n",
        "        keras.layers.Dense(11, activation='softmax')\n",
        "    ])\n",
        "    return model\n",
        "\n",
        "pruning_params = {\"pruning_schedule\": tfmot.sparsity.keras.PolynomialDecay(initial_sparsity=0.2, final_sparsity=0.6, begin_step=0, end_step=1000)}\n",
        "server_model = prune_low_magnitude(create_server_model(), **pruning_params)\n",
        "server_model.build(input_shape=(None, 20, 64))\n",
        "server_model.compile(optimizer='adam',loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "# Deserialize and decompress data\n",
        "def deserialize_data(data):\n",
        "    return pickle.loads(zlib.decompress(data))\n",
        "\n",
        "# Server function\n",
        "def start_server(host='127.0.0.1', port=65438):\n",
        "\n",
        "    pruned_server_model=server_model\n",
        "    pruning_callback = tfmot.sparsity.keras.UpdatePruningStep()\n",
        "    log_callback = tfmot.sparsity.keras.PruningSummaries(log_dir=\"logs\")\n",
        "\n",
        "\n",
        "    server_socket = socket.socket(socket.AF_INET, socket.SOCK_STREAM)\n",
        "    server_socket.bind((host, port))\n",
        "    server_socket.listen(1)\n",
        "    print(\"Server waiting for connection...\")\n",
        "    conn, addr = server_socket.accept()\n",
        "    print(f\"Connected to client: {addr}\")\n",
        "    lr_schedule = tf.keras.optimizers.schedules.ExponentialDecay(\n",
        "    initial_learning_rate=0.001,\n",
        "    decay_steps=10000,\n",
        "    decay_rate=0.9\n",
        "    )\n",
        "    optimizer = tf.keras.optimizers.Adam(learning_rate=lr_schedule)\n",
        "\n",
        "    total_comm_overhead = 0  # Track communication overhead\n",
        "    pruning_callback.set_model(pruned_server_model)\n",
        "    log_callback.set_model(pruned_server_model)\n",
        "    pruning_callback.on_train_begin()\n",
        "\n",
        "    all_true_labels = []\n",
        "    all_pred_labels = []\n",
        "\n",
        "    training_start_time = time.time()\n",
        "\n",
        "\n",
        "    while True:\n",
        "        try:\n",
        "            # Receive header indicating batch size\n",
        "            header = conn.recv(8)\n",
        "            if not header:\n",
        "                break\n",
        "            data_size = int(header.decode('utf-8').strip())\n",
        "\n",
        "\n",
        "            # If a special flag (e.g., -1) is sent, switch to evaluation\n",
        "            if data_size == -1:\n",
        "              print(\"Switching to evaluation phase...\")\n",
        "              break\n",
        "\n",
        "            # Receive the batch data\n",
        "            data = b\"\"\n",
        "            while len(data) < data_size:\n",
        "                packet = conn.recv(4096)\n",
        "                if not packet:\n",
        "                    break\n",
        "                data += packet\n",
        "            total_comm_overhead += len(data)  # Update comm overhead\n",
        "\n",
        "            # Deserialize the data\n",
        "            intermediate_output, labels = deserialize_data(data)\n",
        "            pruning_callback.on_train_batch_begin(batch=-1)\n",
        "\n",
        "            # Perform forward pass and backpropagation on batch\n",
        "            with tf.GradientTape() as tape:\n",
        "                logits = pruned_server_model(np.array(intermediate_output), training=True)\n",
        "                loss = tf.reduce_mean(\n",
        "                    tf.keras.losses.categorical_crossentropy(np.array(labels), logits)\n",
        "                )\n",
        "            gradients = tape.gradient(loss, pruned_server_model.trainable_variables)\n",
        "            optimizer.apply_gradients(zip(gradients, pruned_server_model.trainable_variables))\n",
        "            pruning_callback.on_epoch_end(batch=-1)\n",
        "\n",
        "            pred_classes = np.argmax(logits.numpy(), axis=1)\n",
        "            true_classes = np.argmax(labels, axis=1)\n",
        "\n",
        "            all_pred_labels.extend(pred_classes)\n",
        "            all_true_labels.extend(true_classes)\n",
        "\n",
        "            correct_predictions = int(np.sum(\n",
        "                np.argmax(logits.numpy(), axis=1) == np.argmax(labels, axis=1)\n",
        "            ))\n",
        "            response = f\"{loss.numpy():.4f},{correct_predictions}\"\n",
        "            conn.sendall(f\"{len(response):08}\".encode('utf-8'))\n",
        "            conn.sendall(response.encode('utf-8'))\n",
        "\n",
        "        except Exception as e:\n",
        "            print(f\"Error: {e}\")\n",
        "            break\n",
        "\n",
        "    training_end_time = time.time()\n",
        "    print(f\"Total Training Time: {training_end_time - training_start_time:.2f} sec\")\n",
        "    print(f\"Total Communication Overhead: {total_comm_overhead / 1024:.2f} KB\")\n",
        "\n",
        "\n",
        "    # At the end of training\n",
        "    precision = precision_score(all_true_labels, all_pred_labels, average='macro')\n",
        "    recall = recall_score(all_true_labels, all_pred_labels, average='macro')\n",
        "    f1 = f1_score(all_true_labels, all_pred_labels, average='macro')\n",
        "    print(f\"\\nTraining Metrics → Precision: {precision:.4f}, Recall: {recall:.4f}, F1 Score: {f1:.4f}\")\n",
        "\n",
        "    # Strip pruning and save the final model\n",
        "    pruned_server_model = tfmot.sparsity.keras.strip_pruning(pruned_server_model)\n",
        "    server_model.save(\"server_model_pruned.h5\")\n",
        "\n",
        "    converter = tf.lite.TFLiteConverter.from_keras_model(pruned_server_model)\n",
        "    tflite_model = converter.convert()\n",
        "    with open(\"server_model_pruned.tflite\", \"wb\") as f:\n",
        "        f.write(tflite_model)\n",
        "\n",
        "    print(\"Model saved in .h5 and .tflite formats.\")\n",
        "\n",
        "    # Handle test evaluation\n",
        "    print(\"Evaluating test data...\")\n",
        "\n",
        "    all_test_true = []\n",
        "    all_test_pred = []\n",
        "\n",
        "    while True:\n",
        "        header = conn.recv(8)\n",
        "        if not header:\n",
        "            break\n",
        "        test_data_size = int(header.decode('utf-8').strip())\n",
        "        test_data = b\"\"\n",
        "        while len(test_data) < test_data_size:\n",
        "            packet = conn.recv(4096)\n",
        "            if not packet:\n",
        "                break\n",
        "            test_data += packet\n",
        "\n",
        "        test_intermediate, test_labels = deserialize_data(test_data)\n",
        "        #logits = pruned_server_model(np.array(test_intermediate), training=False)\n",
        "\n",
        "        test_intermediate = np.array(test_intermediate)\n",
        "        test_labels = np.array(test_labels)\n",
        "\n",
        "        logits = pruned_server_model(test_intermediate, training=False)\n",
        "        pred_classes = np.argmax(logits.numpy(), axis=1)\n",
        "        true_classes = np.argmax(test_labels, axis=1)\n",
        "\n",
        "        all_test_pred.extend(pred_classes)\n",
        "        all_test_true.extend(true_classes)\n",
        "\n",
        "        correct_predictions = int(np.sum(\n",
        "            np.argmax(logits.numpy(), axis=1) == np.argmax(test_labels, axis=1)\n",
        "        ))\n",
        "        response = f\"{correct_predictions}\"\n",
        "        conn.sendall(f\"{len(response):08}\".encode('utf-8'))\n",
        "        conn.sendall(response.encode('utf-8'))\n",
        "\n",
        "        # Final test metrics\n",
        "        precision = precision_score(all_test_true, all_test_pred, average='macro')\n",
        "        recall = recall_score(all_test_true, all_test_pred, average='macro')\n",
        "        f1 = f1_score(all_test_true, all_test_pred, average='macro')\n",
        "        print(f\"\\nTesting Metrics → Precision: {precision:.4f}, Recall: {recall:.4f}, F1 Score: {f1:.4f}\")\n",
        "\n",
        "\n",
        "    conn.close()\n",
        "    server_socket.close()\n",
        "    print(\"Server connection closed.\")\n",
        "\n",
        "server_thread = threading.Thread(target=start_server)\n",
        "server_thread.start()\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "mBYj_V8q9sbv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ef6ca079-ee44-40ea-d6d5-1d023ebd0714",
        "id": "yjQx2FyPhHv9"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Connected to server!Connected to client: ('127.0.0.1', 40772)\n",
            "\n",
            "\n",
            "Starting Training...\n",
            "\n",
            "Epoch 1/10\n",
            "Batch 553/553 - Progress: 100.00% - Loss: 0.2483\n",
            "Epoch 1 completed: Avg Loss = 0.3479, Training Accuracy = 0.8188\n",
            "\n",
            "Epoch 2/10\n",
            "Batch 553/553 - Progress: 100.00% - Loss: 0.1789\n",
            "Epoch 2 completed: Avg Loss = 0.2505, Training Accuracy = 0.8550\n",
            "\n",
            "Epoch 3/10\n",
            "Batch 553/553 - Progress: 100.00% - Loss: 0.1523\n",
            "Epoch 3 completed: Avg Loss = 0.1748, Training Accuracy = 0.8903\n",
            "\n",
            "Epoch 4/10\n",
            "Batch 553/553 - Progress: 100.00% - Loss: 0.1281\n",
            "Epoch 4 completed: Avg Loss = 0.1482, Training Accuracy = 0.9015\n",
            "\n",
            "Epoch 5/10\n",
            "Batch 553/553 - Progress: 100.00% - Loss: 0.1243\n",
            "Epoch 5 completed: Avg Loss = 0.1432, Training Accuracy = 0.9028\n",
            "\n",
            "Epoch 6/10\n",
            "Batch 553/553 - Progress: 100.00% - Loss: 0.1237\n",
            "Epoch 6 completed: Avg Loss = 0.1381, Training Accuracy = 0.9049\n",
            "\n",
            "Epoch 7/10\n",
            "Batch 553/553 - Progress: 100.00% - Loss: 0.1229\n",
            "Epoch 7 completed: Avg Loss = 0.1358, Training Accuracy = 0.9060\n",
            "\n",
            "Epoch 8/10\n",
            "Batch 553/553 - Progress: 100.00% - Loss: 0.1243\n",
            "Epoch 8 completed: Avg Loss = 0.1357, Training Accuracy = 0.9053\n",
            "\n",
            "Epoch 9/10\n",
            "Batch 553/553 - Progress: 100.00% - Loss: 0.1210\n",
            "Epoch 9 completed: Avg Loss = 0.1328, Training Accuracy = 0.9060\n",
            "\n",
            "Epoch 10/10\n",
            "Batch 552/553 - Progress: 99.82% - Loss: 0.1323"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-43-248437b05133>:115: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native TF-Keras format, e.g. `model.save('my_model.keras')`.\n",
            "  keras.models.save_model(model_for_export, pruned_keras_file, include_optimizer=False)\n",
            "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\rBatch 553/553 - Progress: 100.00% - Loss: 0.1228\n",
            "Epoch 10 completed: Avg Loss = 0.1343, Training Accuracy = 0.9070\n",
            "\n",
            "Training completed in 5879.91 seconds.\n",
            "Total Communication Overhead: 12167440.65 KB\n",
            "Saved pruned Keras model to: /tmp/tmpqxyuq9lz.h5\n",
            "Size of gzipped pruned Keras model: 32499.00 bytes\n",
            "Saved pruned TFLite model to: /tmp/tmp21kdbiac.tflite\n",
            "Size of gzipped pruned TFlite model: 31115.00 bytes\n",
            "Training complete. Signaled server to start evaluation.\n",
            "\n",
            "Evaluating on test data...\n",
            "Switching to evaluation phase...\n",
            "Total Training Time: 5882.24 sec\n",
            "Total Communication Overhead: 12167440.65 KB\n",
            "\n",
            "Training Metrics → Precision: 0.8899, Recall: 0.8897, F1 Score: 0.8897\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/tf_keras/src/engine/training.py:3098: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native TF-Keras format, e.g. `model.save('my_model.keras')`.\n",
            "  saving_api.save_model(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model saved in .h5 and .tflite formats.\n",
            "Evaluating test data...\n",
            "\n",
            "Testing completed: Testing Accuracy = 0.8981\n",
            "\n",
            "Client connection closed.\n"
          ]
        }
      ],
      "source": [
        "import socket\n",
        "import pickle\n",
        "import zlib\n",
        "import time\n",
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "from tensorflow.keras import Sequential\n",
        "from tensorflow.keras.layers import Conv1D, MaxPooling1D, BatchNormalization\n",
        "from sklearn.model_selection import train_test_split\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "\n",
        "# Client-side model\n",
        "def create_client_model():\n",
        "    model =keras.Sequential([\n",
        "        keras.layers.InputLayer(input_shape=(40, 1)),\n",
        "        keras.layers.Conv1D(16, kernel_size=3, activation='relu',padding='same'),\n",
        "        keras.layers.BatchNormalization(),\n",
        "        keras.layers.Conv1D(32, kernel_size=3, activation='relu',padding='same'),\n",
        "        keras.layers.BatchNormalization(),\n",
        "        #MaxPooling1D(pool_size=2),\n",
        "        keras.layers.Conv1D(32, kernel_size=3, activation='relu',padding='same'),\n",
        "        keras.layers.BatchNormalization(),\n",
        "        #MaxPooling1D(pool_size=2),\n",
        "        keras.layers.Conv1D(64, kernel_size=3, activation='relu',padding='same'),\n",
        "        keras.layers.BatchNormalization(),\n",
        "        keras.layers.Conv1D(64, kernel_size=3, activation='relu',padding='same'),\n",
        "        keras.layers.BatchNormalization(),\n",
        "        keras.layers.MaxPooling1D(pool_size=2),\n",
        "\n",
        "    ])\n",
        "    return model\n",
        "\n",
        "    # Apply pruning\n",
        "pruning_params = {'pruning_schedule': tfmot.sparsity.keras.PolynomialDecay(initial_sparsity=0.50, final_sparsity=0.80, begin_step=0, end_step=1000)}\n",
        "pruned_client_model = prune_low_magnitude(create_client_model(), **pruning_params)\n",
        "pruned_client_model.build(input_shape=(None, 40, 1))\n",
        "#print(\"Size of gzipped baseline Keras model: %.2f bytes\" % (get_gzipped_model_size(pruned_client_model)))\n",
        "\n",
        "# Serialize and compress data using pickle\n",
        "def serialize_data(data):\n",
        "    return zlib.compress(pickle.dumps(data))\n",
        "\n",
        "# Client function\n",
        "def start_client(host='127.0.0.1', port=65438):\n",
        "    client_model = create_client_model()\n",
        "    client_socket = socket.socket(socket.AF_INET, socket.SOCK_STREAM)\n",
        "    client_socket.connect((host, port))\n",
        "    print(\"Connected to server!\")\n",
        "\n",
        "    pruning_callback = tfmot.sparsity.keras.UpdatePruningStep()\n",
        "    pruning_callback.set_model(pruned_client_model)\n",
        "    pruning_callback.on_train_begin()\n",
        "\n",
        "    batch_size = 512\n",
        "    epochs =  10\n",
        "    total_batches = int(np.ceil(X_train_scaled.shape[0] / batch_size))\n",
        "    total_comm_overhead = 0\n",
        "\n",
        "    print(\"\\nStarting Training...\")\n",
        "    start_time = time.time()\n",
        "\n",
        "    for epoch in range(epochs):\n",
        "        print(f\"\\nEpoch {epoch + 1}/{epochs}\")\n",
        "        epoch_loss = 0\n",
        "        correct_predictions = 0\n",
        "        total_samples = 0\n",
        "\n",
        "        for batch_index, i in enumerate(range(0, X_train_scaled.shape[0], batch_size), start=1):\n",
        "            x_batch = X_train_scaled[i:min(i + batch_size, X_train_scaled.shape[0])]\n",
        "            y_batch = y_train[i:min(i + batch_size, y_train.shape[0])]\n",
        "\n",
        "            pruning_callback.on_train_batch_begin(batch=-1)\n",
        "\n",
        "            # Forward pass to get intermediate activations\n",
        "            intermediate_output = pruned_client_model(x_batch, training=True).numpy()\n",
        "\n",
        "            # Serialize and send data\n",
        "            data = serialize_data((intermediate_output.tolist(), y_batch.tolist()))\n",
        "            data_size = len(data)\n",
        "\n",
        "            client_socket.sendall(f\"{len(data):08}\".encode('utf-8'))\n",
        "            client_socket.sendall(data)\n",
        "\n",
        "            total_comm_overhead += data_size\n",
        "\n",
        "            # Receive server response\n",
        "            response_header = client_socket.recv(8)\n",
        "            response_size = int(response_header.decode('utf-8').strip())\n",
        "            response = client_socket.recv(response_size)\n",
        "            server_loss, batch_correct = map(float, response.decode('utf-8').split(','))\n",
        "            pruning_callback.on_epoch_end(batch=-1)\n",
        "\n",
        "            # Update statistics\n",
        "            epoch_loss += server_loss\n",
        "            correct_predictions += batch_correct\n",
        "            total_samples += x_batch.shape[0]\n",
        "\n",
        "            # Display batch progress\n",
        "            progress = (batch_index / total_batches) * 100\n",
        "            print(f\"\\rBatch {batch_index}/{total_batches} - Progress: {progress:.2f}% - Loss: {server_loss:.4f}\", end=\"\")\n",
        "\n",
        "        training_accuracy = correct_predictions / total_samples\n",
        "        print(f\"\\nEpoch {epoch + 1} completed: Avg Loss = {epoch_loss / total_batches:.4f}, \"\n",
        "              f\"Training Accuracy = {training_accuracy:.4f}\")\n",
        "\n",
        "    total_training_time = time.time() - start_time\n",
        "    print(f\"\\nTraining completed in {total_training_time:.2f} seconds.\")\n",
        "    print(f\"Total Communication Overhead: {total_comm_overhead / 1024:.2f} KB\")\n",
        "\n",
        "    #client_model = tfmot.sparsity.keras.strip_pruning(pruned_client_model)\n",
        "    #client_model.save(\"client_model_pruned.h5\")\n",
        "    model_for_export = tfmot.sparsity.keras.strip_pruning(pruned_client_model)\n",
        "\n",
        "    _, pruned_keras_file = tempfile.mkstemp('.h5')\n",
        "    keras.models.save_model(model_for_export, pruned_keras_file, include_optimizer=False)\n",
        "    print('Saved pruned Keras model to:', pruned_keras_file)\n",
        "\n",
        "    print(\"Size of gzipped pruned Keras model: %.2f bytes\" % (get_gzipped_model_size(pruned_keras_file)))\n",
        "\n",
        "    #converter = tf.lite.TFLiteConverter.from_keras_model(pruned_client_model)\n",
        "    #tflite_model = converter.convert()\n",
        "    #with open(\"client_model_pruned.tflite\", \"wb\") as f:\n",
        "        #f.write(tflite_model)\n",
        "    converter = tf.lite.TFLiteConverter.from_keras_model(model_for_export)\n",
        "    pruned_tflite_model = converter.convert()\n",
        "\n",
        "    _, pruned_tflite_file = tempfile.mkstemp('.tflite')\n",
        "\n",
        "    with open(pruned_tflite_file, 'wb') as f:\n",
        "        f.write(pruned_tflite_model)\n",
        "\n",
        "    print('Saved pruned TFLite model to:', pruned_tflite_file)\n",
        "    print(\"Size of gzipped pruned TFlite model: %.2f bytes\" % (get_gzipped_model_size(pruned_tflite_file)))\n",
        "\n",
        "        #print(\"Client model saved in .h5 and .tflite formats.\")\n",
        "    # Signal the server to switch to evaluation mode\n",
        "    client_socket.sendall(f\"{-1:08}\".encode('utf-8'))\n",
        "    print(\"Training complete. Signaled server to start evaluation.\")\n",
        "\n",
        "    # Evaluate testing accuracy in batches\n",
        "    print(\"\\nEvaluating on test data...\")\n",
        "    test_batch_size = 512  # Larger batch size for efficient testing\n",
        "    total_test_batches = int(np.ceil(X_test_scaled.shape[0] / test_batch_size))\n",
        "    correct_predictions = 0\n",
        "    total_samples = 0\n",
        "\n",
        "    for i in range(0, X_test_scaled.shape[0], test_batch_size):\n",
        "        x_test_batch = X_test_scaled[i:min(i + test_batch_size, X_test_scaled.shape[0])]\n",
        "        y_test_batch = y_test[i:min(i + test_batch_size, y_test.shape[0])]\n",
        "\n",
        "        test_intermediate = pruned_client_model.predict(x_test_batch, verbose=0)\n",
        "        test_data = serialize_data((test_intermediate.tolist(), y_test_batch.tolist()))\n",
        "\n",
        "        client_socket.sendall(f\"{len(test_data):08}\".encode('utf-8'))\n",
        "        client_socket.sendall(test_data)\n",
        "\n",
        "        # Receive test batch accuracy\n",
        "        test_accuracy_response = client_socket.recv(8)\n",
        "        test_accuracy_size = int(test_accuracy_response.decode('utf-8').strip())\n",
        "        test_accuracy_data = client_socket.recv(test_accuracy_size)\n",
        "        batch_correct = int(test_accuracy_data.decode('utf-8'))\n",
        "\n",
        "        correct_predictions += batch_correct\n",
        "        total_samples += x_test_batch.shape[0]\n",
        "\n",
        "    test_accuracy = correct_predictions / total_samples\n",
        "    print(f\"\\nTesting completed: Testing Accuracy = {test_accuracy:.4f}\")\n",
        "\n",
        "    client_socket.close()\n",
        "    print(\"\\nClient connection closed.\")\n",
        "\n",
        "# Start the client\n",
        "start_client()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "***With Optimized Pruning Parameters***"
      ],
      "metadata": {
        "id": "T-LvCGvsIVOl"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "B-r3hIPxfbFP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "z1ZERugiInyM"
      },
      "outputs": [],
      "source": [
        "import socket\n",
        "import pickle\n",
        "import zlib\n",
        "import tensorflow as tf\n",
        "import tf_keras as keras\n",
        "import tensorflow_model_optimization as tfmot\n",
        "import numpy as np\n",
        "from tensorflow.keras import Sequential\n",
        "from tensorflow.keras.layers import MaxPooling1D, Flatten, Dense, BatchNormalization\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "import threading\n",
        "from sklearn.metrics import precision_score, recall_score, f1_score\n",
        "from tensorflow.keras.layers import Dropout\n",
        "# Apply pruning\n",
        "prune_low_magnitude = tfmot.sparsity.keras.prune_low_magnitude\n",
        "\n",
        "# Server-side model\n",
        "def create_server_model():\n",
        "    model = keras.Sequential([\n",
        "        keras.layers.MaxPooling1D(pool_size=2,input_shape=(20, 64)),\n",
        "        keras.layers.Conv1D(128, kernel_size=3, activation='relu',padding='same'),\n",
        "        keras.layers.BatchNormalization(),\n",
        "        keras.layers.Conv1D(128, kernel_size=3, activation='relu',padding='same'),\n",
        "        keras.layers.BatchNormalization(),\n",
        "        keras.layers.MaxPooling1D(pool_size=2),\n",
        "        keras.layers.Conv1D(256, kernel_size=3, activation='relu',padding='same'),\n",
        "        keras.layers.BatchNormalization(),\n",
        "        keras.layers.Conv1D(256, kernel_size=3, activation='relu',padding='same'),\n",
        "        keras.layers.BatchNormalization(),\n",
        "        keras.layers.MaxPooling1D(pool_size=2),\n",
        "        keras.layers.Flatten(),\n",
        "        keras.layers.Dense(256, activation='relu'),\n",
        "        keras.layers.Dropout(0.3),\n",
        "        keras.layers.Dense(128, activation='relu'),\n",
        "        keras.layers.Dropout(0.2),\n",
        "        keras.layers.Dense(11, activation='softmax')\n",
        "    ])\n",
        "    return model\n",
        "\n",
        "pruning_params = {\"pruning_schedule\": tfmot.sparsity.keras.PolynomialDecay(initial_sparsity=0.0, final_sparsity=0.6, begin_step=0, end_step=5530, power=3)}\n",
        "server_model = prune_low_magnitude(create_server_model(), **pruning_params)\n",
        "server_model.build(input_shape=(None, 20, 64))\n",
        "server_model.compile(optimizer='adam',loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "# Deserialize and decompress data\n",
        "def deserialize_data(data):\n",
        "    return pickle.loads(zlib.decompress(data))\n",
        "\n",
        "# Server function\n",
        "def start_server(host='127.0.0.1', port=65438):\n",
        "\n",
        "    pruned_server_model=server_model\n",
        "    pruning_callback = tfmot.sparsity.keras.UpdatePruningStep()\n",
        "    log_callback = tfmot.sparsity.keras.PruningSummaries(log_dir=\"logs\")\n",
        "\n",
        "\n",
        "    server_socket = socket.socket(socket.AF_INET, socket.SOCK_STREAM)\n",
        "    server_socket.bind((host, port))\n",
        "    server_socket.listen(1)\n",
        "    print(\"Server waiting for connection...\")\n",
        "    conn, addr = server_socket.accept()\n",
        "    print(f\"Connected to client: {addr}\")\n",
        "    lr_schedule = tf.keras.optimizers.schedules.ExponentialDecay(\n",
        "    initial_learning_rate=0.001,\n",
        "    decay_steps=10000,\n",
        "    decay_rate=0.9\n",
        "    )\n",
        "    optimizer = tf.keras.optimizers.Adam(learning_rate=lr_schedule)\n",
        "\n",
        "    total_comm_overhead = 0  # Track communication overhead\n",
        "    pruning_callback.set_model(pruned_server_model)\n",
        "    log_callback.set_model(pruned_server_model)\n",
        "    pruning_callback.on_train_begin()\n",
        "\n",
        "    all_true_labels = []\n",
        "    all_pred_labels = []\n",
        "\n",
        "    training_start_time = time.time()\n",
        "\n",
        "\n",
        "    while True:\n",
        "        try:\n",
        "            # Receive header indicating batch size\n",
        "            header = conn.recv(8)\n",
        "            if not header:\n",
        "                break\n",
        "            data_size = int(header.decode('utf-8').strip())\n",
        "\n",
        "\n",
        "            # If a special flag (e.g., -1) is sent, switch to evaluation\n",
        "            if data_size == -1:\n",
        "              print(\"Switching to evaluation phase...\")\n",
        "              break\n",
        "\n",
        "            # Receive the batch data\n",
        "            data = b\"\"\n",
        "            while len(data) < data_size:\n",
        "                packet = conn.recv(4096)\n",
        "                if not packet:\n",
        "                    break\n",
        "                data += packet\n",
        "            total_comm_overhead += len(data)  # Update comm overhead\n",
        "\n",
        "            # Deserialize the data\n",
        "            intermediate_output, labels = deserialize_data(data)\n",
        "            pruning_callback.on_train_batch_begin(batch=-1)\n",
        "\n",
        "            # Perform forward pass and backpropagation on batch\n",
        "            with tf.GradientTape() as tape:\n",
        "                logits = pruned_server_model(np.array(intermediate_output), training=True)\n",
        "                loss = tf.reduce_mean(\n",
        "                    tf.keras.losses.categorical_crossentropy(np.array(labels), logits)\n",
        "                )\n",
        "            gradients = tape.gradient(loss, pruned_server_model.trainable_variables)\n",
        "            optimizer.apply_gradients(zip(gradients, pruned_server_model.trainable_variables))\n",
        "            pruning_callback.on_epoch_end(batch=-1)\n",
        "\n",
        "            pred_classes = np.argmax(logits.numpy(), axis=1)\n",
        "            true_classes = np.argmax(labels, axis=1)\n",
        "\n",
        "            all_pred_labels.extend(pred_classes)\n",
        "            all_true_labels.extend(true_classes)\n",
        "\n",
        "            correct_predictions = int(np.sum(\n",
        "                np.argmax(logits.numpy(), axis=1) == np.argmax(labels, axis=1)\n",
        "            ))\n",
        "            response = f\"{loss.numpy():.4f},{correct_predictions}\"\n",
        "            conn.sendall(f\"{len(response):08}\".encode('utf-8'))\n",
        "            conn.sendall(response.encode('utf-8'))\n",
        "\n",
        "        except Exception as e:\n",
        "            print(f\"Error: {e}\")\n",
        "            break\n",
        "\n",
        "    training_end_time = time.time()\n",
        "    print(f\"Total Training Time: {training_end_time - training_start_time:.2f} sec\")\n",
        "    print(f\"Total Communication Overhead: {total_comm_overhead / 1024:.2f} KB\")\n",
        "\n",
        "\n",
        "    # At the end of training\n",
        "    precision = precision_score(all_true_labels, all_pred_labels, average='macro')\n",
        "    recall = recall_score(all_true_labels, all_pred_labels, average='macro')\n",
        "    f1 = f1_score(all_true_labels, all_pred_labels, average='macro')\n",
        "    print(f\"\\nTraining Metrics → Precision: {precision:.4f}, Recall: {recall:.4f}, F1 Score: {f1:.4f}\")\n",
        "\n",
        "    # Strip pruning and save the final model\n",
        "    pruned_server_model = tfmot.sparsity.keras.strip_pruning(pruned_server_model)\n",
        "    server_model.save(\"server_model_pruned.h5\")\n",
        "\n",
        "    converter = tf.lite.TFLiteConverter.from_keras_model(pruned_server_model)\n",
        "    tflite_model = converter.convert()\n",
        "    with open(\"server_model_pruned.tflite\", \"wb\") as f:\n",
        "        f.write(tflite_model)\n",
        "\n",
        "    print(\"Model saved in .h5 and .tflite formats.\")\n",
        "\n",
        "    # Handle test evaluation\n",
        "    print(\"Evaluating test data...\")\n",
        "\n",
        "    all_test_true = []\n",
        "    all_test_pred = []\n",
        "\n",
        "    while True:\n",
        "        header = conn.recv(8)\n",
        "        if not header:\n",
        "            break\n",
        "        test_data_size = int(header.decode('utf-8').strip())\n",
        "        test_data = b\"\"\n",
        "        while len(test_data) < test_data_size:\n",
        "            packet = conn.recv(4096)\n",
        "            if not packet:\n",
        "                break\n",
        "            test_data += packet\n",
        "\n",
        "        test_intermediate, test_labels = deserialize_data(test_data)\n",
        "        #logits = pruned_server_model(np.array(test_intermediate), training=False)\n",
        "\n",
        "        test_intermediate = np.array(test_intermediate)\n",
        "        test_labels = np.array(test_labels)\n",
        "\n",
        "        logits = pruned_server_model(test_intermediate, training=False)\n",
        "        pred_classes = np.argmax(logits.numpy(), axis=1)\n",
        "        true_classes = np.argmax(test_labels, axis=1)\n",
        "\n",
        "        all_test_pred.extend(pred_classes)\n",
        "        all_test_true.extend(true_classes)\n",
        "\n",
        "        correct_predictions = int(np.sum(\n",
        "            np.argmax(logits.numpy(), axis=1) == np.argmax(test_labels, axis=1)\n",
        "        ))\n",
        "        response = f\"{correct_predictions}\"\n",
        "        conn.sendall(f\"{len(response):08}\".encode('utf-8'))\n",
        "        conn.sendall(response.encode('utf-8'))\n",
        "\n",
        "        # Final test metrics\n",
        "        precision = precision_score(all_test_true, all_test_pred, average='macro')\n",
        "        recall = recall_score(all_test_true, all_test_pred, average='macro')\n",
        "        f1 = f1_score(all_test_true, all_test_pred, average='macro')\n",
        "        print(f\"\\nTesting Metrics → Precision: {precision:.4f}, Recall: {recall:.4f}, F1 Score: {f1:.4f}\")\n",
        "\n",
        "\n",
        "    conn.close()\n",
        "    server_socket.close()\n",
        "    print(\"Server connection closed.\")\n",
        "\n",
        "server_thread = threading.Thread(target=start_server)\n",
        "server_thread.start()\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "dgZZnHOtfbIS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d63be9d5-2277-46e7-9783-16cbb66998e3",
        "id": "EKb_zv6SIs4T",
        "collapsed": true
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Connected to server!Connected to client: ('127.0.0.1', 41396)\n",
            "\n",
            "\n",
            "Starting Training...\n",
            "\n",
            "Epoch 1/10\n",
            "Batch 553/553 - Progress: 100.00% - Loss: 0.2147\n",
            "Epoch 1 completed: Avg Loss = 0.2589, Training Accuracy = 0.8539\n",
            "\n",
            "Epoch 2/10\n",
            "Batch 553/553 - Progress: 100.00% - Loss: 0.2566\n",
            "Epoch 2 completed: Avg Loss = 0.1966, Training Accuracy = 0.8825\n",
            "\n",
            "Epoch 3/10\n",
            "Batch 553/553 - Progress: 100.00% - Loss: 0.1660\n",
            "Epoch 3 completed: Avg Loss = 0.2013, Training Accuracy = 0.8811\n",
            "\n",
            "Epoch 4/10\n",
            "Batch 553/553 - Progress: 100.00% - Loss: 0.1886\n",
            "Epoch 4 completed: Avg Loss = 0.2061, Training Accuracy = 0.8787\n",
            "\n",
            "Epoch 5/10\n",
            "Batch 553/553 - Progress: 100.00% - Loss: 0.2241\n",
            "Epoch 5 completed: Avg Loss = 0.2199, Training Accuracy = 0.8701\n",
            "\n",
            "Epoch 6/10\n",
            "Batch 553/553 - Progress: 100.00% - Loss: 0.2055\n",
            "Epoch 6 completed: Avg Loss = 0.2351, Training Accuracy = 0.8606\n",
            "\n",
            "Epoch 7/10\n",
            "Batch 553/553 - Progress: 100.00% - Loss: 0.1752\n",
            "Epoch 7 completed: Avg Loss = 0.2173, Training Accuracy = 0.8691\n",
            "\n",
            "Epoch 8/10\n",
            "Batch 553/553 - Progress: 100.00% - Loss: 0.2304\n",
            "Epoch 8 completed: Avg Loss = 0.1906, Training Accuracy = 0.8839\n",
            "\n",
            "Epoch 9/10\n",
            "Batch 553/553 - Progress: 100.00% - Loss: 0.1541\n",
            "Epoch 9 completed: Avg Loss = 0.1867, Training Accuracy = 0.8842\n",
            "\n",
            "Epoch 10/10\n",
            "Batch 552/553 - Progress: 99.82% - Loss: 0.1484"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-41-bb187517b709>:115: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native TF-Keras format, e.g. `model.save('my_model.keras')`.\n",
            "  keras.models.save_model(model_for_export, pruned_keras_file, include_optimizer=False)\n",
            "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\rBatch 553/553 - Progress: 100.00% - Loss: 0.1355\n",
            "Epoch 10 completed: Avg Loss = 0.1568, Training Accuracy = 0.8970\n",
            "\n",
            "Training completed in 5956.90 seconds.\n",
            "Total Communication Overhead: 12340109.82 KB\n",
            "Saved pruned Keras model to: /tmp/tmpn95jo1gu.h5\n",
            "Size of gzipped pruned Keras model: 49038.00 bytes\n",
            "Saved pruned TFLite model to: /tmp/tmpv2enu9ka.tflite\n",
            "Size of gzipped pruned TFlite model: 47708.00 bytes\n",
            "Training complete. Signaled server to start evaluation.\n",
            "\n",
            "Evaluating on test data...\n",
            "Switching to evaluation phase...\n",
            "Total Training Time: 5958.81 sec\n",
            "Total Communication Overhead: 12340109.82 KB\n",
            "\n",
            "Training Metrics → Precision: 0.8764, Recall: 0.8760, F1 Score: 0.8759\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/tf_keras/src/engine/training.py:3098: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native TF-Keras format, e.g. `model.save('my_model.keras')`.\n",
            "  saving_api.save_model(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model saved in .h5 and .tflite formats.\n",
            "Evaluating test data...\n",
            "\n",
            "Testing Metrics → Precision: 0.8187, Recall: 0.8583, F1 Score: 0.8199\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Testing Metrics → Precision: 0.8294, Recall: 0.8592, F1 Score: 0.8263\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Testing Metrics → Precision: 0.8275, Recall: 0.8601, F1 Score: 0.8246\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Testing Metrics → Precision: 0.8258, Recall: 0.8580, F1 Score: 0.8207\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Testing Metrics → Precision: 0.8250, Recall: 0.8577, F1 Score: 0.8204\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Testing Metrics → Precision: 0.8261, Recall: 0.8585, F1 Score: 0.8216\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Testing Metrics → Precision: 0.8262, Recall: 0.8584, F1 Score: 0.8220\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Testing Metrics → Precision: 0.8259, Recall: 0.8586, F1 Score: 0.8217\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Testing Metrics → Precision: 0.8277, Recall: 0.8589, F1 Score: 0.8233\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Testing Metrics → Precision: 0.8278, Recall: 0.8595, F1 Score: 0.8238\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Testing Metrics → Precision: 0.8272, Recall: 0.8590, F1 Score: 0.8230\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Testing Metrics → Precision: 0.8267, Recall: 0.8588, F1 Score: 0.8226\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Testing Metrics → Precision: 0.8262, Recall: 0.8586, F1 Score: 0.8225\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Testing Metrics → Precision: 0.8268, Recall: 0.8587, F1 Score: 0.8231\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Testing Metrics → Precision: 0.8271, Recall: 0.8596, F1 Score: 0.8239\n",
            "\n",
            "Testing Metrics → Precision: 0.9180, Recall: 0.8596, F1 Score: 0.8240\n",
            "\n",
            "Testing Metrics → Precision: 0.9183, Recall: 0.8599, F1 Score: 0.8245\n",
            "\n",
            "Testing Metrics → Precision: 0.9185, Recall: 0.8599, F1 Score: 0.8248\n",
            "\n",
            "Testing Metrics → Precision: 0.9194, Recall: 0.8602, F1 Score: 0.8259\n",
            "\n",
            "Testing Metrics → Precision: 0.9189, Recall: 0.8604, F1 Score: 0.8256\n",
            "\n",
            "Testing Metrics → Precision: 0.9185, Recall: 0.8609, F1 Score: 0.8256\n",
            "\n",
            "Testing Metrics → Precision: 0.9190, Recall: 0.8611, F1 Score: 0.8262\n",
            "\n",
            "Testing Metrics → Precision: 0.9186, Recall: 0.8609, F1 Score: 0.8258\n",
            "\n",
            "Testing Metrics → Precision: 0.9185, Recall: 0.8609, F1 Score: 0.8257\n",
            "\n",
            "Testing Metrics → Precision: 0.9186, Recall: 0.8606, F1 Score: 0.8254\n",
            "\n",
            "Testing Metrics → Precision: 0.9186, Recall: 0.8604, F1 Score: 0.8252\n",
            "\n",
            "Testing Metrics → Precision: 0.9187, Recall: 0.8604, F1 Score: 0.8253\n",
            "\n",
            "Testing Metrics → Precision: 0.9186, Recall: 0.8603, F1 Score: 0.8252\n",
            "\n",
            "Testing Metrics → Precision: 0.9189, Recall: 0.8604, F1 Score: 0.8254\n",
            "\n",
            "Testing Metrics → Precision: 0.9187, Recall: 0.8604, F1 Score: 0.8254\n",
            "\n",
            "Testing Metrics → Precision: 0.9189, Recall: 0.8606, F1 Score: 0.8256\n",
            "\n",
            "Testing Metrics → Precision: 0.9188, Recall: 0.8607, F1 Score: 0.8256\n",
            "\n",
            "Testing Metrics → Precision: 0.9190, Recall: 0.8605, F1 Score: 0.8257\n",
            "\n",
            "Testing Metrics → Precision: 0.9190, Recall: 0.8605, F1 Score: 0.8257\n",
            "\n",
            "Testing Metrics → Precision: 0.9194, Recall: 0.8606, F1 Score: 0.8260\n",
            "\n",
            "Testing Metrics → Precision: 0.9193, Recall: 0.8605, F1 Score: 0.8259\n",
            "\n",
            "Testing Metrics → Precision: 0.9194, Recall: 0.8604, F1 Score: 0.8260\n",
            "\n",
            "Testing Metrics → Precision: 0.9192, Recall: 0.8603, F1 Score: 0.8257\n",
            "\n",
            "Testing Metrics → Precision: 0.9190, Recall: 0.8603, F1 Score: 0.8257\n",
            "\n",
            "Testing Metrics → Precision: 0.9191, Recall: 0.8606, F1 Score: 0.8259\n",
            "\n",
            "Testing Metrics → Precision: 0.9191, Recall: 0.8606, F1 Score: 0.8260\n",
            "\n",
            "Testing Metrics → Precision: 0.9191, Recall: 0.8610, F1 Score: 0.8263\n",
            "\n",
            "Testing Metrics → Precision: 0.9190, Recall: 0.8611, F1 Score: 0.8262\n",
            "\n",
            "Testing Metrics → Precision: 0.9190, Recall: 0.8612, F1 Score: 0.8263\n",
            "\n",
            "Testing Metrics → Precision: 0.9189, Recall: 0.8612, F1 Score: 0.8263\n",
            "\n",
            "Testing Metrics → Precision: 0.9191, Recall: 0.8613, F1 Score: 0.8264\n",
            "\n",
            "Testing Metrics → Precision: 0.9192, Recall: 0.8614, F1 Score: 0.8266\n",
            "\n",
            "Testing Metrics → Precision: 0.9191, Recall: 0.8614, F1 Score: 0.8266\n",
            "\n",
            "Testing Metrics → Precision: 0.9192, Recall: 0.8614, F1 Score: 0.8265\n",
            "\n",
            "Testing Metrics → Precision: 0.9192, Recall: 0.8614, F1 Score: 0.8265\n",
            "\n",
            "Testing Metrics → Precision: 0.9192, Recall: 0.8612, F1 Score: 0.8263\n",
            "\n",
            "Testing Metrics → Precision: 0.9193, Recall: 0.8612, F1 Score: 0.8264\n",
            "\n",
            "Testing Metrics → Precision: 0.9196, Recall: 0.8612, F1 Score: 0.8267\n",
            "\n",
            "Testing Metrics → Precision: 0.9197, Recall: 0.8616, F1 Score: 0.8270\n",
            "\n",
            "Testing Metrics → Precision: 0.9197, Recall: 0.8615, F1 Score: 0.8270\n",
            "\n",
            "Testing Metrics → Precision: 0.9197, Recall: 0.8616, F1 Score: 0.8270\n",
            "\n",
            "Testing Metrics → Precision: 0.9197, Recall: 0.8615, F1 Score: 0.8269\n",
            "\n",
            "Testing Metrics → Precision: 0.9198, Recall: 0.8615, F1 Score: 0.8270\n",
            "\n",
            "Testing Metrics → Precision: 0.9199, Recall: 0.8615, F1 Score: 0.8271\n",
            "\n",
            "Testing Metrics → Precision: 0.9201, Recall: 0.8616, F1 Score: 0.8273\n",
            "\n",
            "Testing Metrics → Precision: 0.9200, Recall: 0.8618, F1 Score: 0.8274\n",
            "\n",
            "Testing Metrics → Precision: 0.9200, Recall: 0.8618, F1 Score: 0.8274\n",
            "\n",
            "Testing Metrics → Precision: 0.9200, Recall: 0.8618, F1 Score: 0.8274\n",
            "\n",
            "Testing Metrics → Precision: 0.9200, Recall: 0.8618, F1 Score: 0.8274\n",
            "\n",
            "Testing Metrics → Precision: 0.9201, Recall: 0.8617, F1 Score: 0.8275\n",
            "\n",
            "Testing Metrics → Precision: 0.9200, Recall: 0.8616, F1 Score: 0.8273\n",
            "\n",
            "Testing Metrics → Precision: 0.9200, Recall: 0.8616, F1 Score: 0.8274\n",
            "\n",
            "Testing Metrics → Precision: 0.9201, Recall: 0.8617, F1 Score: 0.8275\n",
            "\n",
            "Testing Metrics → Precision: 0.9202, Recall: 0.8618, F1 Score: 0.8277\n",
            "\n",
            "Testing Metrics → Precision: 0.9201, Recall: 0.8617, F1 Score: 0.8275\n",
            "\n",
            "Testing Metrics → Precision: 0.9200, Recall: 0.8618, F1 Score: 0.8276\n",
            "\n",
            "Testing Metrics → Precision: 0.9200, Recall: 0.8618, F1 Score: 0.8275\n",
            "\n",
            "Testing Metrics → Precision: 0.9200, Recall: 0.8618, F1 Score: 0.8275\n",
            "\n",
            "Testing Metrics → Precision: 0.9200, Recall: 0.8618, F1 Score: 0.8276\n",
            "\n",
            "Testing Metrics → Precision: 0.9200, Recall: 0.8619, F1 Score: 0.8277\n",
            "\n",
            "Testing Metrics → Precision: 0.9200, Recall: 0.8618, F1 Score: 0.8276\n",
            "\n",
            "Testing Metrics → Precision: 0.9201, Recall: 0.8618, F1 Score: 0.8276\n",
            "\n",
            "Testing Metrics → Precision: 0.9201, Recall: 0.8619, F1 Score: 0.8277\n",
            "\n",
            "Testing Metrics → Precision: 0.9199, Recall: 0.8620, F1 Score: 0.8277\n",
            "\n",
            "Testing Metrics → Precision: 0.9198, Recall: 0.8618, F1 Score: 0.8274\n",
            "\n",
            "Testing Metrics → Precision: 0.9198, Recall: 0.8618, F1 Score: 0.8275\n",
            "\n",
            "Testing Metrics → Precision: 0.9198, Recall: 0.8619, F1 Score: 0.8275\n",
            "\n",
            "Testing Metrics → Precision: 0.9197, Recall: 0.8618, F1 Score: 0.8274\n",
            "\n",
            "Testing Metrics → Precision: 0.9197, Recall: 0.8618, F1 Score: 0.8274\n",
            "\n",
            "Testing Metrics → Precision: 0.9198, Recall: 0.8618, F1 Score: 0.8275\n",
            "\n",
            "Testing Metrics → Precision: 0.9199, Recall: 0.8618, F1 Score: 0.8276\n",
            "\n",
            "Testing Metrics → Precision: 0.9199, Recall: 0.8617, F1 Score: 0.8276\n",
            "\n",
            "Testing Metrics → Precision: 0.9198, Recall: 0.8617, F1 Score: 0.8275\n",
            "\n",
            "Testing Metrics → Precision: 0.9198, Recall: 0.8616, F1 Score: 0.8274\n",
            "\n",
            "Testing Metrics → Precision: 0.9198, Recall: 0.8617, F1 Score: 0.8275\n",
            "\n",
            "Testing Metrics → Precision: 0.9197, Recall: 0.8616, F1 Score: 0.8273\n",
            "\n",
            "Testing Metrics → Precision: 0.9198, Recall: 0.8616, F1 Score: 0.8274\n",
            "\n",
            "Testing Metrics → Precision: 0.9197, Recall: 0.8615, F1 Score: 0.8273\n",
            "\n",
            "Testing Metrics → Precision: 0.9197, Recall: 0.8615, F1 Score: 0.8273\n",
            "\n",
            "Testing Metrics → Precision: 0.9196, Recall: 0.8614, F1 Score: 0.8272\n",
            "\n",
            "Testing Metrics → Precision: 0.9195, Recall: 0.8613, F1 Score: 0.8270\n",
            "\n",
            "Testing Metrics → Precision: 0.9195, Recall: 0.8613, F1 Score: 0.8270\n",
            "\n",
            "Testing Metrics → Precision: 0.9195, Recall: 0.8614, F1 Score: 0.8272\n",
            "\n",
            "Testing Metrics → Precision: 0.9196, Recall: 0.8614, F1 Score: 0.8272\n",
            "\n",
            "Testing Metrics → Precision: 0.9196, Recall: 0.8615, F1 Score: 0.8273\n",
            "\n",
            "Testing Metrics → Precision: 0.9197, Recall: 0.8616, F1 Score: 0.8274\n",
            "\n",
            "Testing Metrics → Precision: 0.9196, Recall: 0.8616, F1 Score: 0.8274\n",
            "\n",
            "Testing Metrics → Precision: 0.9196, Recall: 0.8617, F1 Score: 0.8275\n",
            "\n",
            "Testing Metrics → Precision: 0.9197, Recall: 0.8617, F1 Score: 0.8276\n",
            "\n",
            "Testing Metrics → Precision: 0.9197, Recall: 0.8617, F1 Score: 0.8276\n",
            "\n",
            "Testing Metrics → Precision: 0.9199, Recall: 0.8618, F1 Score: 0.8278\n",
            "\n",
            "Testing Metrics → Precision: 0.9198, Recall: 0.8618, F1 Score: 0.8278\n",
            "\n",
            "Testing Metrics → Precision: 0.9200, Recall: 0.8619, F1 Score: 0.8280\n",
            "\n",
            "Testing Metrics → Precision: 0.9202, Recall: 0.8620, F1 Score: 0.8282\n",
            "\n",
            "Testing Metrics → Precision: 0.9201, Recall: 0.8619, F1 Score: 0.8281\n",
            "\n",
            "Testing Metrics → Precision: 0.9202, Recall: 0.8619, F1 Score: 0.8282\n",
            "\n",
            "Testing Metrics → Precision: 0.9202, Recall: 0.8619, F1 Score: 0.8282\n",
            "\n",
            "Testing Metrics → Precision: 0.9203, Recall: 0.8619, F1 Score: 0.8282\n",
            "\n",
            "Testing Metrics → Precision: 0.9201, Recall: 0.8619, F1 Score: 0.8282\n",
            "\n",
            "Testing Metrics → Precision: 0.9202, Recall: 0.8619, F1 Score: 0.8282\n",
            "\n",
            "Testing Metrics → Precision: 0.9202, Recall: 0.8620, F1 Score: 0.8283\n",
            "\n",
            "Testing Metrics → Precision: 0.9202, Recall: 0.8620, F1 Score: 0.8283\n",
            "\n",
            "Testing Metrics → Precision: 0.9202, Recall: 0.8620, F1 Score: 0.8283\n",
            "\n",
            "Testing Metrics → Precision: 0.9202, Recall: 0.8621, F1 Score: 0.8283\n",
            "\n",
            "Testing Metrics → Precision: 0.9201, Recall: 0.8620, F1 Score: 0.8282\n",
            "\n",
            "Testing Metrics → Precision: 0.9201, Recall: 0.8620, F1 Score: 0.8282\n",
            "\n",
            "Testing Metrics → Precision: 0.9200, Recall: 0.8620, F1 Score: 0.8282\n",
            "\n",
            "Testing Metrics → Precision: 0.9200, Recall: 0.8620, F1 Score: 0.8282\n",
            "\n",
            "Testing Metrics → Precision: 0.9201, Recall: 0.8621, F1 Score: 0.8283\n",
            "\n",
            "Testing Metrics → Precision: 0.9202, Recall: 0.8621, F1 Score: 0.8283\n",
            "\n",
            "Testing Metrics → Precision: 0.9200, Recall: 0.8620, F1 Score: 0.8282\n",
            "\n",
            "Testing Metrics → Precision: 0.9201, Recall: 0.8620, F1 Score: 0.8282\n",
            "\n",
            "Testing Metrics → Precision: 0.9200, Recall: 0.8620, F1 Score: 0.8281\n",
            "\n",
            "Testing Metrics → Precision: 0.9200, Recall: 0.8620, F1 Score: 0.8281\n",
            "\n",
            "Testing Metrics → Precision: 0.9200, Recall: 0.8619, F1 Score: 0.8281\n",
            "\n",
            "Testing Metrics → Precision: 0.9200, Recall: 0.8620, F1 Score: 0.8281\n",
            "\n",
            "Testing Metrics → Precision: 0.9201, Recall: 0.8620, F1 Score: 0.8282\n",
            "\n",
            "Testing Metrics → Precision: 0.9201, Recall: 0.8621, F1 Score: 0.8282\n",
            "\n",
            "Testing Metrics → Precision: 0.9201, Recall: 0.8621, F1 Score: 0.8283\n",
            "\n",
            "Testing Metrics → Precision: 0.9201, Recall: 0.8621, F1 Score: 0.8283\n",
            "\n",
            "Testing Metrics → Precision: 0.9201, Recall: 0.8621, F1 Score: 0.8282\n",
            "\n",
            "Testing Metrics → Precision: 0.9201, Recall: 0.8621, F1 Score: 0.8283\n",
            "\n",
            "Testing Metrics → Precision: 0.9201, Recall: 0.8622, F1 Score: 0.8283\n",
            "\n",
            "Testing Metrics → Precision: 0.9201, Recall: 0.8621, F1 Score: 0.8282\n",
            "\n",
            "Testing Metrics → Precision: 0.9200, Recall: 0.8621, F1 Score: 0.8282\n",
            "\n",
            "Testing Metrics → Precision: 0.9201, Recall: 0.8622, F1 Score: 0.8283\n",
            "\n",
            "Testing Metrics → Precision: 0.9200, Recall: 0.8621, F1 Score: 0.8282\n",
            "\n",
            "Testing Metrics → Precision: 0.9200, Recall: 0.8621, F1 Score: 0.8282\n",
            "\n",
            "Testing Metrics → Precision: 0.9200, Recall: 0.8621, F1 Score: 0.8282\n",
            "\n",
            "Testing Metrics → Precision: 0.9200, Recall: 0.8621, F1 Score: 0.8282\n",
            "\n",
            "Testing Metrics → Precision: 0.9200, Recall: 0.8621, F1 Score: 0.8282\n",
            "\n",
            "Testing Metrics → Precision: 0.9201, Recall: 0.8621, F1 Score: 0.8282\n",
            "\n",
            "Testing Metrics → Precision: 0.9200, Recall: 0.8620, F1 Score: 0.8282\n",
            "\n",
            "Testing Metrics → Precision: 0.9200, Recall: 0.8620, F1 Score: 0.8281\n",
            "\n",
            "Testing Metrics → Precision: 0.9200, Recall: 0.8620, F1 Score: 0.8281\n",
            "\n",
            "Testing Metrics → Precision: 0.9200, Recall: 0.8620, F1 Score: 0.8282\n",
            "\n",
            "Testing Metrics → Precision: 0.9201, Recall: 0.8621, F1 Score: 0.8283\n",
            "\n",
            "Testing Metrics → Precision: 0.9201, Recall: 0.8621, F1 Score: 0.8283\n",
            "\n",
            "Testing Metrics → Precision: 0.9200, Recall: 0.8620, F1 Score: 0.8282\n",
            "\n",
            "Testing Metrics → Precision: 0.9200, Recall: 0.8620, F1 Score: 0.8281\n",
            "\n",
            "Testing Metrics → Precision: 0.9201, Recall: 0.8621, F1 Score: 0.8282\n",
            "\n",
            "Testing Metrics → Precision: 0.9200, Recall: 0.8622, F1 Score: 0.8282\n",
            "\n",
            "Testing Metrics → Precision: 0.9200, Recall: 0.8622, F1 Score: 0.8282\n",
            "\n",
            "Testing Metrics → Precision: 0.9201, Recall: 0.8622, F1 Score: 0.8283\n",
            "\n",
            "Testing Metrics → Precision: 0.9201, Recall: 0.8622, F1 Score: 0.8283\n",
            "\n",
            "Testing Metrics → Precision: 0.9200, Recall: 0.8622, F1 Score: 0.8283\n",
            "\n",
            "Testing Metrics → Precision: 0.9201, Recall: 0.8621, F1 Score: 0.8283\n",
            "\n",
            "Testing Metrics → Precision: 0.9201, Recall: 0.8622, F1 Score: 0.8283\n",
            "\n",
            "Testing Metrics → Precision: 0.9201, Recall: 0.8621, F1 Score: 0.8284\n",
            "\n",
            "Testing Metrics → Precision: 0.9201, Recall: 0.8621, F1 Score: 0.8283\n",
            "\n",
            "Testing Metrics → Precision: 0.9201, Recall: 0.8621, F1 Score: 0.8283\n",
            "\n",
            "Testing Metrics → Precision: 0.9201, Recall: 0.8621, F1 Score: 0.8283\n",
            "\n",
            "Testing Metrics → Precision: 0.9202, Recall: 0.8621, F1 Score: 0.8284\n",
            "\n",
            "Testing Metrics → Precision: 0.9202, Recall: 0.8621, F1 Score: 0.8284\n",
            "\n",
            "Testing Metrics → Precision: 0.9203, Recall: 0.8622, F1 Score: 0.8285\n",
            "\n",
            "Testing Metrics → Precision: 0.9202, Recall: 0.8621, F1 Score: 0.8284\n",
            "\n",
            "Testing Metrics → Precision: 0.9202, Recall: 0.8622, F1 Score: 0.8285\n",
            "\n",
            "Testing Metrics → Precision: 0.9202, Recall: 0.8622, F1 Score: 0.8284\n",
            "\n",
            "Testing Metrics → Precision: 0.9202, Recall: 0.8622, F1 Score: 0.8285\n",
            "\n",
            "Testing Metrics → Precision: 0.9203, Recall: 0.8623, F1 Score: 0.8286\n",
            "\n",
            "Testing Metrics → Precision: 0.9203, Recall: 0.8623, F1 Score: 0.8287\n",
            "\n",
            "Testing Metrics → Precision: 0.9203, Recall: 0.8622, F1 Score: 0.8286\n",
            "\n",
            "Testing Metrics → Precision: 0.9202, Recall: 0.8622, F1 Score: 0.8285\n",
            "\n",
            "Testing Metrics → Precision: 0.9202, Recall: 0.8622, F1 Score: 0.8285\n",
            "\n",
            "Testing Metrics → Precision: 0.9201, Recall: 0.8622, F1 Score: 0.8285\n",
            "\n",
            "Testing Metrics → Precision: 0.9201, Recall: 0.8622, F1 Score: 0.8285\n",
            "\n",
            "Testing Metrics → Precision: 0.9202, Recall: 0.8622, F1 Score: 0.8285\n",
            "\n",
            "Testing Metrics → Precision: 0.9202, Recall: 0.8622, F1 Score: 0.8285\n",
            "\n",
            "Testing Metrics → Precision: 0.9202, Recall: 0.8622, F1 Score: 0.8285\n",
            "\n",
            "Testing Metrics → Precision: 0.9202, Recall: 0.8622, F1 Score: 0.8286\n",
            "\n",
            "Testing Metrics → Precision: 0.9203, Recall: 0.8623, F1 Score: 0.8287\n",
            "\n",
            "Testing Metrics → Precision: 0.9202, Recall: 0.8623, F1 Score: 0.8286\n",
            "\n",
            "Testing Metrics → Precision: 0.9202, Recall: 0.8623, F1 Score: 0.8286\n",
            "\n",
            "Testing Metrics → Precision: 0.9203, Recall: 0.8623, F1 Score: 0.8287\n",
            "\n",
            "Testing Metrics → Precision: 0.9202, Recall: 0.8623, F1 Score: 0.8286\n",
            "\n",
            "Testing Metrics → Precision: 0.9201, Recall: 0.8624, F1 Score: 0.8286\n",
            "\n",
            "Testing Metrics → Precision: 0.9201, Recall: 0.8624, F1 Score: 0.8286\n",
            "\n",
            "Testing Metrics → Precision: 0.9201, Recall: 0.8624, F1 Score: 0.8286\n",
            "\n",
            "Testing Metrics → Precision: 0.9201, Recall: 0.8624, F1 Score: 0.8286\n",
            "\n",
            "Testing Metrics → Precision: 0.9201, Recall: 0.8624, F1 Score: 0.8286\n",
            "\n",
            "Testing Metrics → Precision: 0.9202, Recall: 0.8624, F1 Score: 0.8287\n",
            "\n",
            "Testing Metrics → Precision: 0.9202, Recall: 0.8624, F1 Score: 0.8287\n",
            "\n",
            "Testing Metrics → Precision: 0.9202, Recall: 0.8624, F1 Score: 0.8287\n",
            "\n",
            "Testing Metrics → Precision: 0.9202, Recall: 0.8624, F1 Score: 0.8287\n",
            "\n",
            "Testing Metrics → Precision: 0.9202, Recall: 0.8624, F1 Score: 0.8287\n",
            "\n",
            "Testing Metrics → Precision: 0.9202, Recall: 0.8624, F1 Score: 0.8287\n",
            "\n",
            "Testing Metrics → Precision: 0.9203, Recall: 0.8624, F1 Score: 0.8287\n",
            "\n",
            "Testing Metrics → Precision: 0.9202, Recall: 0.8624, F1 Score: 0.8287\n",
            "\n",
            "Testing Metrics → Precision: 0.9202, Recall: 0.8624, F1 Score: 0.8287\n",
            "\n",
            "Testing Metrics → Precision: 0.9202, Recall: 0.8624, F1 Score: 0.8287\n",
            "\n",
            "Testing Metrics → Precision: 0.9202, Recall: 0.8624, F1 Score: 0.8287\n",
            "\n",
            "Testing Metrics → Precision: 0.9202, Recall: 0.8624, F1 Score: 0.8287\n",
            "\n",
            "Testing Metrics → Precision: 0.9203, Recall: 0.8624, F1 Score: 0.8288\n",
            "\n",
            "Testing Metrics → Precision: 0.9203, Recall: 0.8625, F1 Score: 0.8288\n",
            "\n",
            "Testing Metrics → Precision: 0.9203, Recall: 0.8625, F1 Score: 0.8288\n",
            "\n",
            "Testing Metrics → Precision: 0.9203, Recall: 0.8624, F1 Score: 0.8288\n",
            "\n",
            "Testing Metrics → Precision: 0.9204, Recall: 0.8625, F1 Score: 0.8289\n",
            "\n",
            "Testing Metrics → Precision: 0.9204, Recall: 0.8624, F1 Score: 0.8289\n",
            "\n",
            "Testing Metrics → Precision: 0.9204, Recall: 0.8624, F1 Score: 0.8289\n",
            "\n",
            "Testing Metrics → Precision: 0.9204, Recall: 0.8625, F1 Score: 0.8289\n",
            "\n",
            "Testing Metrics → Precision: 0.9205, Recall: 0.8625, F1 Score: 0.8289\n",
            "\n",
            "Testing Metrics → Precision: 0.9204, Recall: 0.8625, F1 Score: 0.8289\n",
            "\n",
            "Testing Metrics → Precision: 0.9205, Recall: 0.8625, F1 Score: 0.8290\n",
            "\n",
            "Testing Metrics → Precision: 0.9206, Recall: 0.8625, F1 Score: 0.8290\n",
            "\n",
            "Testing Metrics → Precision: 0.9206, Recall: 0.8625, F1 Score: 0.8290\n",
            "\n",
            "Testing Metrics → Precision: 0.9206, Recall: 0.8625, F1 Score: 0.8290\n",
            "\n",
            "Testing Metrics → Precision: 0.9206, Recall: 0.8625, F1 Score: 0.8290\n",
            "\n",
            "Testing Metrics → Precision: 0.9206, Recall: 0.8625, F1 Score: 0.8290\n",
            "\n",
            "Testing Metrics → Precision: 0.9206, Recall: 0.8625, F1 Score: 0.8290\n",
            "\n",
            "Testing Metrics → Precision: 0.9205, Recall: 0.8625, F1 Score: 0.8290\n",
            "\n",
            "Testing Metrics → Precision: 0.9206, Recall: 0.8626, F1 Score: 0.8290\n",
            "\n",
            "Testing Metrics → Precision: 0.9205, Recall: 0.8626, F1 Score: 0.8290\n",
            "\n",
            "Testing Metrics → Precision: 0.9206, Recall: 0.8626, F1 Score: 0.8291\n",
            "\n",
            "Testing Metrics → Precision: 0.9207, Recall: 0.8626, F1 Score: 0.8292\n",
            "\n",
            "Testing Metrics → Precision: 0.9206, Recall: 0.8625, F1 Score: 0.8291\n",
            "\n",
            "Testing Metrics → Precision: 0.9206, Recall: 0.8625, F1 Score: 0.8291\n",
            "\n",
            "Testing Metrics → Precision: 0.9207, Recall: 0.8625, F1 Score: 0.8291\n",
            "\n",
            "Testing Metrics → Precision: 0.9206, Recall: 0.8624, F1 Score: 0.8290\n",
            "\n",
            "Testing Metrics → Precision: 0.9206, Recall: 0.8624, F1 Score: 0.8290\n",
            "\n",
            "Testing Metrics → Precision: 0.9205, Recall: 0.8624, F1 Score: 0.8289\n",
            "\n",
            "Testing Metrics → Precision: 0.9206, Recall: 0.8624, F1 Score: 0.8290\n",
            "\n",
            "Testing completed: Testing Accuracy = 0.8617\n",
            "\n",
            "Client connection closed.\n"
          ]
        }
      ],
      "source": [
        "import socket\n",
        "import pickle\n",
        "import zlib\n",
        "import time\n",
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "from tensorflow.keras import Sequential\n",
        "from tensorflow.keras.layers import Conv1D, MaxPooling1D, BatchNormalization\n",
        "from sklearn.model_selection import train_test_split\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "\n",
        "# Client-side model\n",
        "def create_client_model():\n",
        "    model =keras.Sequential([\n",
        "        keras.layers.InputLayer(input_shape=(40, 1)),\n",
        "        keras.layers.Conv1D(16, kernel_size=3, activation='relu',padding='same'),\n",
        "        keras.layers.BatchNormalization(),\n",
        "        keras.layers.Conv1D(32, kernel_size=3, activation='relu',padding='same'),\n",
        "        keras.layers.BatchNormalization(),\n",
        "        #MaxPooling1D(pool_size=2),\n",
        "        keras.layers.Conv1D(32, kernel_size=3, activation='relu',padding='same'),\n",
        "        keras.layers.BatchNormalization(),\n",
        "        #MaxPooling1D(pool_size=2),\n",
        "        keras.layers.Conv1D(64, kernel_size=3, activation='relu',padding='same'),\n",
        "        keras.layers.BatchNormalization(),\n",
        "        keras.layers.Conv1D(64, kernel_size=3, activation='relu',padding='same'),\n",
        "        keras.layers.BatchNormalization(),\n",
        "        keras.layers.MaxPooling1D(pool_size=2),\n",
        "\n",
        "    ])\n",
        "    return model\n",
        "\n",
        "    # Apply pruning\n",
        "pruning_params = {'pruning_schedule': tfmot.sparsity.keras.PolynomialDecay(initial_sparsity=0.0, final_sparsity=0.60, begin_step=0, end_step=5530,power=3)}\n",
        "pruned_client_model = prune_low_magnitude(create_client_model(), **pruning_params)\n",
        "pruned_client_model.build(input_shape=(None, 40, 1))\n",
        "#print(\"Size of gzipped baseline Keras model: %.2f bytes\" % (get_gzipped_model_size(pruned_client_model)))\n",
        "\n",
        "# Serialize and compress data using pickle\n",
        "def serialize_data(data):\n",
        "    return zlib.compress(pickle.dumps(data))\n",
        "\n",
        "# Client function\n",
        "def start_client(host='127.0.0.1', port=65438):\n",
        "    client_model = create_client_model()\n",
        "    client_socket = socket.socket(socket.AF_INET, socket.SOCK_STREAM)\n",
        "    client_socket.connect((host, port))\n",
        "    print(\"Connected to server!\")\n",
        "\n",
        "    pruning_callback = tfmot.sparsity.keras.UpdatePruningStep()\n",
        "    pruning_callback.set_model(pruned_client_model)\n",
        "    pruning_callback.on_train_begin()\n",
        "\n",
        "    batch_size = 512\n",
        "    epochs =  10\n",
        "    total_batches = int(np.ceil(X_train_scaled.shape[0] / batch_size))\n",
        "    total_comm_overhead = 0\n",
        "\n",
        "    print(\"\\nStarting Training...\")\n",
        "    start_time = time.time()\n",
        "\n",
        "    for epoch in range(epochs):\n",
        "        print(f\"\\nEpoch {epoch + 1}/{epochs}\")\n",
        "        epoch_loss = 0\n",
        "        correct_predictions = 0\n",
        "        total_samples = 0\n",
        "\n",
        "        for batch_index, i in enumerate(range(0, X_train_scaled.shape[0], batch_size), start=1):\n",
        "            x_batch = X_train_scaled[i:min(i + batch_size, X_train_scaled.shape[0])]\n",
        "            y_batch = y_train[i:min(i + batch_size, y_train.shape[0])]\n",
        "\n",
        "            pruning_callback.on_train_batch_begin(batch=-1)\n",
        "\n",
        "            # Forward pass to get intermediate activations\n",
        "            intermediate_output = pruned_client_model(x_batch, training=True).numpy()\n",
        "\n",
        "            # Serialize and send data\n",
        "            data = serialize_data((intermediate_output.tolist(), y_batch.tolist()))\n",
        "            data_size = len(data)\n",
        "\n",
        "            client_socket.sendall(f\"{len(data):08}\".encode('utf-8'))\n",
        "            client_socket.sendall(data)\n",
        "\n",
        "            total_comm_overhead += data_size\n",
        "\n",
        "            # Receive server response\n",
        "            response_header = client_socket.recv(8)\n",
        "            response_size = int(response_header.decode('utf-8').strip())\n",
        "            response = client_socket.recv(response_size)\n",
        "            server_loss, batch_correct = map(float, response.decode('utf-8').split(','))\n",
        "            pruning_callback.on_epoch_end(batch=-1)\n",
        "\n",
        "            # Update statistics\n",
        "            epoch_loss += server_loss\n",
        "            correct_predictions += batch_correct\n",
        "            total_samples += x_batch.shape[0]\n",
        "\n",
        "            # Display batch progress\n",
        "            progress = (batch_index / total_batches) * 100\n",
        "            print(f\"\\rBatch {batch_index}/{total_batches} - Progress: {progress:.2f}% - Loss: {server_loss:.4f}\", end=\"\")\n",
        "\n",
        "        training_accuracy = correct_predictions / total_samples\n",
        "        print(f\"\\nEpoch {epoch + 1} completed: Avg Loss = {epoch_loss / total_batches:.4f}, \"\n",
        "              f\"Training Accuracy = {training_accuracy:.4f}\")\n",
        "\n",
        "    total_training_time = time.time() - start_time\n",
        "    print(f\"\\nTraining completed in {total_training_time:.2f} seconds.\")\n",
        "    print(f\"Total Communication Overhead: {total_comm_overhead / 1024:.2f} KB\")\n",
        "\n",
        "    #client_model = tfmot.sparsity.keras.strip_pruning(pruned_client_model)\n",
        "    #client_model.save(\"client_model_pruned.h5\")\n",
        "    model_for_export = tfmot.sparsity.keras.strip_pruning(pruned_client_model)\n",
        "\n",
        "    _, pruned_keras_file = tempfile.mkstemp('.h5')\n",
        "    keras.models.save_model(model_for_export, pruned_keras_file, include_optimizer=False)\n",
        "    print('Saved pruned Keras model to:', pruned_keras_file)\n",
        "\n",
        "    print(\"Size of gzipped pruned Keras model: %.2f bytes\" % (get_gzipped_model_size(pruned_keras_file)))\n",
        "\n",
        "    #converter = tf.lite.TFLiteConverter.from_keras_model(pruned_client_model)\n",
        "    #tflite_model = converter.convert()\n",
        "    #with open(\"client_model_pruned.tflite\", \"wb\") as f:\n",
        "        #f.write(tflite_model)\n",
        "    converter = tf.lite.TFLiteConverter.from_keras_model(model_for_export)\n",
        "    pruned_tflite_model = converter.convert()\n",
        "\n",
        "    _, pruned_tflite_file = tempfile.mkstemp('.tflite')\n",
        "\n",
        "    with open(pruned_tflite_file, 'wb') as f:\n",
        "        f.write(pruned_tflite_model)\n",
        "\n",
        "    print('Saved pruned TFLite model to:', pruned_tflite_file)\n",
        "    print(\"Size of gzipped pruned TFlite model: %.2f bytes\" % (get_gzipped_model_size(pruned_tflite_file)))\n",
        "\n",
        "        #print(\"Client model saved in .h5 and .tflite formats.\")\n",
        "    # Signal the server to switch to evaluation mode\n",
        "    client_socket.sendall(f\"{-1:08}\".encode('utf-8'))\n",
        "    print(\"Training complete. Signaled server to start evaluation.\")\n",
        "\n",
        "    # Evaluate testing accuracy in batches\n",
        "    print(\"\\nEvaluating on test data...\")\n",
        "    test_batch_size = 512  # Larger batch size for efficient testing\n",
        "    total_test_batches = int(np.ceil(X_test_scaled.shape[0] / test_batch_size))\n",
        "    correct_predictions = 0\n",
        "    total_samples = 0\n",
        "\n",
        "    for i in range(0, X_test_scaled.shape[0], test_batch_size):\n",
        "        x_test_batch = X_test_scaled[i:min(i + test_batch_size, X_test_scaled.shape[0])]\n",
        "        y_test_batch = y_test[i:min(i + test_batch_size, y_test.shape[0])]\n",
        "\n",
        "        test_intermediate = pruned_client_model.predict(x_test_batch, verbose=0)\n",
        "        test_data = serialize_data((test_intermediate.tolist(), y_test_batch.tolist()))\n",
        "\n",
        "        client_socket.sendall(f\"{len(test_data):08}\".encode('utf-8'))\n",
        "        client_socket.sendall(test_data)\n",
        "\n",
        "        # Receive test batch accuracy\n",
        "        test_accuracy_response = client_socket.recv(8)\n",
        "        test_accuracy_size = int(test_accuracy_response.decode('utf-8').strip())\n",
        "        test_accuracy_data = client_socket.recv(test_accuracy_size)\n",
        "        batch_correct = int(test_accuracy_data.decode('utf-8'))\n",
        "\n",
        "        correct_predictions += batch_correct\n",
        "        total_samples += x_test_batch.shape[0]\n",
        "\n",
        "    test_accuracy = correct_predictions / total_samples\n",
        "    print(f\"\\nTesting completed: Testing Accuracy = {test_accuracy:.4f}\")\n",
        "\n",
        "    client_socket.close()\n",
        "    print(\"\\nClient connection closed.\")\n",
        "\n",
        "# Start the client\n",
        "start_client()\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "cLJ2EaF7fbLA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Cg4NUWjcJ47b"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "x1sUs4nVU9oQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "OfPSs1e7U9rs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "t7LLyviMJ4_t"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "dbReDqARJ5EP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JaMyVRN7l_in"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8pevU2Y6l_ld"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "gpuType": "T4",
      "provenance": [],
      "machine_shape": "hm"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}