{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "waECmNJKoSJ-"
      },
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DF-czaxWx8ii"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import pathlib\n",
        "import socket, struct\n",
        "import imblearn\n",
        "from imblearn.under_sampling import RandomUnderSampler\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from collections import Counter\n",
        "from imblearn.over_sampling import SMOTE\n",
        "from imblearn.pipeline import make_pipeline\n",
        "from imblearn.under_sampling import NearMiss\n",
        "from sklearn.preprocessing import OneHotEncoder\n",
        "from sklearn.feature_selection import RFE\n",
        "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.preprocessing import LabelEncoder, StandardScaler, PowerTransformer\n",
        "from sklearn.decomposition import PCA"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iyvarGgDIG2L"
      },
      "outputs": [],
      "source": [
        "import socket\n",
        "import threading\n",
        "import pickle\n",
        "import numpy as np\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Conv1D, Flatten, Input\n",
        "from keras.optimizers import Adam\n",
        "import tensorflow as tf"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ufn6sytvYTKA"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QvSRXl8dy-st",
        "outputId": "54452d9a-58ff-4664-86f6-86454f61e254"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vLi0wjCSy-vr"
      },
      "outputs": [],
      "source": [
        "benign = pathlib.Path(\"/content/drive/MyDrive/scopus/N-BaIoT dataset/1.benign.csv\")\n",
        "g_c=pathlib.Path(\"/content/drive/MyDrive/scopus/N-BaIoT dataset/1.gafgyt.combo.csv\")\n",
        "g_j=pathlib.Path(\"/content/drive/MyDrive/scopus/N-BaIoT dataset/1.gafgyt.junk.csv\")\n",
        "g_s=pathlib.Path(\"/content/drive/MyDrive/scopus/N-BaIoT dataset/1.gafgyt.scan.csv\")\n",
        "g_t=pathlib.Path(\"/content/drive/MyDrive/scopus/N-BaIoT dataset/1.gafgyt.tcp.csv\")\n",
        "g_u=pathlib.Path(\"/content/drive/MyDrive/scopus/N-BaIoT dataset/1.gafgyt.udp.csv\")\n",
        "m_a=pathlib.Path(\"/content/drive/MyDrive/scopus/N-BaIoT dataset/1.mirai.ack.csv\")\n",
        "m_sc=pathlib.Path(\"/content/drive/MyDrive/scopus/N-BaIoT dataset/1.mirai.scan.csv\")\n",
        "m_sy=pathlib.Path(\"/content/drive/MyDrive/scopus/N-BaIoT dataset/1.mirai.syn.csv\")\n",
        "m_u=pathlib.Path(\"/content/drive/MyDrive/scopus/N-BaIoT dataset/1.mirai.udp.csv\")\n",
        "m_u_p=pathlib.Path(\"/content/drive/MyDrive/scopus/N-BaIoT dataset/1.mirai.udpplain.csv\")\n",
        "\n",
        "benign9 = pathlib.Path(\"/content/drive/MyDrive/scopus/N-BaIoT dataset/9.benign.csv\")\n",
        "g_c9=pathlib.Path(\"/content/drive/MyDrive/scopus/N-BaIoT dataset/9.gafgyt.combo.csv\")\n",
        "g_j9=pathlib.Path(\"/content/drive/MyDrive/scopus/N-BaIoT dataset/9.gafgyt.junk.csv\")\n",
        "g_s9=pathlib.Path(\"/content/drive/MyDrive/scopus/N-BaIoT dataset/9.gafgyt.scan.csv\")\n",
        "g_t9=pathlib.Path(\"/content/drive/MyDrive/scopus/N-BaIoT dataset/9.gafgyt.tcp.csv\")\n",
        "g_u9=pathlib.Path(\"/content/drive/MyDrive/scopus/N-BaIoT dataset/9.gafgyt.udp.csv\")\n",
        "m_a9=pathlib.Path(\"/content/drive/MyDrive/scopus/N-BaIoT dataset/9.mirai.ack.csv\")\n",
        "m_sc9=pathlib.Path(\"/content/drive/MyDrive/scopus/N-BaIoT dataset/9.mirai.scan.csv\")\n",
        "m_sy9=pathlib.Path(\"/content/drive/MyDrive/scopus/N-BaIoT dataset/9.mirai.syn.csv\")\n",
        "m_u9=pathlib.Path(\"/content/drive/MyDrive/scopus/N-BaIoT dataset/9.mirai.udp.csv\")\n",
        "m_u_p9=pathlib.Path(\"/content/drive/MyDrive/scopus/N-BaIoT dataset/9.mirai.udpplain.csv\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Onow6NoZETOu"
      },
      "outputs": [],
      "source": [
        "# Load your data\n",
        "benign = pd.read_csv(benign)\n",
        "g_c=pd.read_csv(g_c)\n",
        "g_j=pd.read_csv(g_j)\n",
        "g_s=pd.read_csv(g_s)\n",
        "g_t=pd.read_csv(g_t)\n",
        "g_u=pd.read_csv(g_u)\n",
        "m_a=pd.read_csv(m_a)\n",
        "m_sc=pd.read_csv(m_sc)\n",
        "m_sy=pd.read_csv(m_sy)\n",
        "m_u=pd.read_csv(m_u)\n",
        "m_u_p=pd.read_csv(m_u_p)\n",
        "\n",
        "benign9 = pd.read_csv(benign9)\n",
        "g_c9=pd.read_csv(g_c9)\n",
        "g_j9=pd.read_csv(g_j9)\n",
        "g_s9=pd.read_csv(g_s9)\n",
        "g_t9=pd.read_csv(g_t9)\n",
        "g_u9=pd.read_csv(g_u9)\n",
        "m_a9=pd.read_csv(m_a9)\n",
        "m_sc9=pd.read_csv(m_sc9)\n",
        "m_sy9=pd.read_csv(m_sy9)\n",
        "m_u9=pd.read_csv(m_u9)\n",
        "m_u_p9=pd.read_csv(m_u_p9)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "q8gtsdZRy-yy"
      },
      "outputs": [],
      "source": [
        "benign=benign.sample(frac=0.35,replace=False)\n",
        "g_c=g_c.sample(frac=0.25,replace=False)\n",
        "g_j=g_j.sample(frac=0.5,replace=False)\n",
        "g_s=g_s.sample(frac=0.5,replace=False)\n",
        "g_t=g_t.sample(frac=0.15,replace=False)\n",
        "g_u=g_u.sample(frac=0.15,replace=False)\n",
        "m_a=m_a.sample(frac=0.15,replace=False)\n",
        "m_sc=m_sc.sample(frac=0.15,replace=False)\n",
        "m_sy=m_sy.sample(frac=0.15,replace=False)\n",
        "m_u=m_u.sample(frac=0.08,replace=False)\n",
        "m_u_p=m_u_p.sample(frac=0.17,replace=False)\n",
        "\n",
        "benign9=benign9.sample(frac=0.35,replace=False)\n",
        "g_c9=g_c9.sample(frac=0.25,replace=False)\n",
        "g_j9=g_j9.sample(frac=0.5,replace=False)\n",
        "g_s9=g_s9.sample(frac=0.5,replace=False)\n",
        "g_t9=g_t9.sample(frac=0.15,replace=False)\n",
        "g_u9=g_u9.sample(frac=0.15,replace=False)\n",
        "m_a9=m_a9.sample(frac=0.15,replace=False)\n",
        "m_sc9=m_sc9.sample(frac=0.15,replace=False)\n",
        "m_sy9=m_sy9.sample(frac=0.15,replace=False)\n",
        "m_u9=m_u9.sample(frac=0.08,replace=False)\n",
        "m_u_p9=m_u_p9.sample(frac=0.17,replace=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0duD_tGsGoR7"
      },
      "outputs": [],
      "source": [
        "benign['type']='benign'\n",
        "m_u['type']='mirai_udp'\n",
        "g_c['type']='gafgyt_combo'\n",
        "g_j['type']='gafgyt_junk'\n",
        "g_s['type']='gafgyt_scan'\n",
        "g_t['type']='gafgyt_tcp'\n",
        "g_u['type']='gafgyt_udp'\n",
        "m_a['type']='mirai_ack'\n",
        "m_sc['type']='mirai_scan'\n",
        "m_sy['type']='mirai_syn'\n",
        "m_u_p['type']='mirai_udpplain'\n",
        "\n",
        "benign9['type']='benign'\n",
        "m_u9['type']='mirai_udp'\n",
        "g_c9['type']='gafgyt_combo'\n",
        "g_j9['type']='gafgyt_junk'\n",
        "g_s9['type']='gafgyt_scan'\n",
        "g_t9['type']='gafgyt_tcp'\n",
        "g_u9['type']='gafgyt_udp'\n",
        "m_a9['type']='mirai_ack'\n",
        "m_sc9['type']='mirai_scan'\n",
        "m_sy9['type']='mirai_syn'\n",
        "m_u_p9['type']='mirai_udpplain'\n",
        "\n",
        "data=pd.concat([benign,m_u,g_c,g_j,g_s,g_t,g_u,m_a,m_sc,m_sy,m_u_p,benign9,m_u9,g_c9,g_j9,g_s9,g_t9,g_u9,m_a9,m_sc9,m_sy9,m_u_p9],\n",
        "               axis=0, sort=False, ignore_index=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ftUFFIMQQ-5H",
        "outputId": "f9fe204e-942b-4e15-e893-0b6b0b08306d"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(322007, 116)"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ],
      "source": [
        "data.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pbuYEnWapEBj",
        "outputId": "96b7bbda-e834-4b87-af9c-1ed4724bc324"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array(['benign', 'mirai_udp', 'gafgyt_combo', 'gafgyt_junk',\n",
              "       'gafgyt_scan', 'gafgyt_tcp', 'gafgyt_udp', 'mirai_ack',\n",
              "       'mirai_scan', 'mirai_syn', 'mirai_udpplain'], dtype=object)"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ],
      "source": [
        "data.type.unique()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 460
        },
        "id": "vROqjqRoGoU-",
        "outputId": "d5c5269a-76cd-4940-9250-86755976d251"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "type\n",
              "benign            24177\n",
              "gafgyt_combo      29780\n",
              "gafgyt_junk       28240\n",
              "gafgyt_scan       29210\n",
              "gafgyt_tcp        28532\n",
              "gafgyt_udp        31328\n",
              "mirai_ack         31407\n",
              "mirai_scan        22704\n",
              "mirai_syn         36758\n",
              "mirai_udp         31580\n",
              "mirai_udpplain    28291\n",
              "Name: type, dtype: int64"
            ],
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>type</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>type</th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>benign</th>\n",
              "      <td>24177</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>gafgyt_combo</th>\n",
              "      <td>29780</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>gafgyt_junk</th>\n",
              "      <td>28240</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>gafgyt_scan</th>\n",
              "      <td>29210</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>gafgyt_tcp</th>\n",
              "      <td>28532</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>gafgyt_udp</th>\n",
              "      <td>31328</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>mirai_ack</th>\n",
              "      <td>31407</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>mirai_scan</th>\n",
              "      <td>22704</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>mirai_syn</th>\n",
              "      <td>36758</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>mirai_udp</th>\n",
              "      <td>31580</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>mirai_udpplain</th>\n",
              "      <td>28291</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div><br><label><b>dtype:</b> int64</label>"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ],
      "source": [
        "#how many instances of each class\n",
        "data.groupby('type')['type'].count()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 256
        },
        "id": "mIlf1rtfGodT",
        "outputId": "5b6a32bc-4454-46bd-f435-282fde13a664"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "        MI_dir_L5_weight  MI_dir_L5_mean  MI_dir_L5_variance  \\\n",
              "115187        124.434012      315.447400        64002.536297   \n",
              "156451        112.526213       71.894175           25.047047   \n",
              "220761        201.315139       75.290699          516.807236   \n",
              "302269        210.373601       68.553549           46.586487   \n",
              "211524        170.547840       74.103294            2.468375   \n",
              "\n",
              "        MI_dir_L3_weight  MI_dir_L3_mean  MI_dir_L3_variance  \\\n",
              "115187        195.177727      356.652257        62101.396719   \n",
              "156451        203.190340       70.862213           34.083310   \n",
              "220761        313.387608       75.000542          395.502360   \n",
              "302269        308.751721       69.167109           44.303639   \n",
              "211524        278.386315       74.079990            1.913354   \n",
              "\n",
              "        MI_dir_L1_weight  MI_dir_L1_mean  MI_dir_L1_variance  \\\n",
              "115187        600.118553      385.491154        58749.358768   \n",
              "156451        656.608775       69.886058           40.671256   \n",
              "220761        843.391802       74.467507          175.645093   \n",
              "302269        770.773162       70.202399           38.744644   \n",
              "211524        825.899734       74.054367            1.517173   \n",
              "\n",
              "        MI_dir_L0.1_weight  ...  HpHp_L0.1_covariance  HpHp_L0.1_pcc  \\\n",
              "115187         6310.217408  ...                   0.0            0.0   \n",
              "156451         6674.086636  ...                   0.0            0.0   \n",
              "220761         2431.102726  ...                   0.0            0.0   \n",
              "302269         6955.445694  ...                   0.0            0.0   \n",
              "211524         7100.083586  ...                   0.0            0.0   \n",
              "\n",
              "        HpHp_L0.01_weight  HpHp_L0.01_mean  HpHp_L0.01_std  \\\n",
              "115187                1.0             60.0             0.0   \n",
              "156451                1.0             74.0             0.0   \n",
              "220761                1.0             74.0             0.0   \n",
              "302269                1.0             60.0             0.0   \n",
              "211524                1.0             74.0             0.0   \n",
              "\n",
              "        HpHp_L0.01_magnitude  HpHp_L0.01_radius  HpHp_L0.01_covariance  \\\n",
              "115187                  60.0                0.0                    0.0   \n",
              "156451                  74.0                0.0                    0.0   \n",
              "220761                  74.0                0.0                    0.0   \n",
              "302269                  60.0                0.0                    0.0   \n",
              "211524                  74.0                0.0                    0.0   \n",
              "\n",
              "        HpHp_L0.01_pcc         type  \n",
              "115187             0.0    mirai_ack  \n",
              "156451             0.0    mirai_syn  \n",
              "220761             0.0  gafgyt_junk  \n",
              "302269             0.0    mirai_syn  \n",
              "211524             0.0  gafgyt_junk  \n",
              "\n",
              "[5 rows x 116 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-387e6af8-32bb-4631-aa94-bb251c2f34d4\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>MI_dir_L5_weight</th>\n",
              "      <th>MI_dir_L5_mean</th>\n",
              "      <th>MI_dir_L5_variance</th>\n",
              "      <th>MI_dir_L3_weight</th>\n",
              "      <th>MI_dir_L3_mean</th>\n",
              "      <th>MI_dir_L3_variance</th>\n",
              "      <th>MI_dir_L1_weight</th>\n",
              "      <th>MI_dir_L1_mean</th>\n",
              "      <th>MI_dir_L1_variance</th>\n",
              "      <th>MI_dir_L0.1_weight</th>\n",
              "      <th>...</th>\n",
              "      <th>HpHp_L0.1_covariance</th>\n",
              "      <th>HpHp_L0.1_pcc</th>\n",
              "      <th>HpHp_L0.01_weight</th>\n",
              "      <th>HpHp_L0.01_mean</th>\n",
              "      <th>HpHp_L0.01_std</th>\n",
              "      <th>HpHp_L0.01_magnitude</th>\n",
              "      <th>HpHp_L0.01_radius</th>\n",
              "      <th>HpHp_L0.01_covariance</th>\n",
              "      <th>HpHp_L0.01_pcc</th>\n",
              "      <th>type</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>115187</th>\n",
              "      <td>124.434012</td>\n",
              "      <td>315.447400</td>\n",
              "      <td>64002.536297</td>\n",
              "      <td>195.177727</td>\n",
              "      <td>356.652257</td>\n",
              "      <td>62101.396719</td>\n",
              "      <td>600.118553</td>\n",
              "      <td>385.491154</td>\n",
              "      <td>58749.358768</td>\n",
              "      <td>6310.217408</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>60.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>60.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>mirai_ack</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>156451</th>\n",
              "      <td>112.526213</td>\n",
              "      <td>71.894175</td>\n",
              "      <td>25.047047</td>\n",
              "      <td>203.190340</td>\n",
              "      <td>70.862213</td>\n",
              "      <td>34.083310</td>\n",
              "      <td>656.608775</td>\n",
              "      <td>69.886058</td>\n",
              "      <td>40.671256</td>\n",
              "      <td>6674.086636</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>74.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>74.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>mirai_syn</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>220761</th>\n",
              "      <td>201.315139</td>\n",
              "      <td>75.290699</td>\n",
              "      <td>516.807236</td>\n",
              "      <td>313.387608</td>\n",
              "      <td>75.000542</td>\n",
              "      <td>395.502360</td>\n",
              "      <td>843.391802</td>\n",
              "      <td>74.467507</td>\n",
              "      <td>175.645093</td>\n",
              "      <td>2431.102726</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>74.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>74.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>gafgyt_junk</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>302269</th>\n",
              "      <td>210.373601</td>\n",
              "      <td>68.553549</td>\n",
              "      <td>46.586487</td>\n",
              "      <td>308.751721</td>\n",
              "      <td>69.167109</td>\n",
              "      <td>44.303639</td>\n",
              "      <td>770.773162</td>\n",
              "      <td>70.202399</td>\n",
              "      <td>38.744644</td>\n",
              "      <td>6955.445694</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>60.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>60.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>mirai_syn</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>211524</th>\n",
              "      <td>170.547840</td>\n",
              "      <td>74.103294</td>\n",
              "      <td>2.468375</td>\n",
              "      <td>278.386315</td>\n",
              "      <td>74.079990</td>\n",
              "      <td>1.913354</td>\n",
              "      <td>825.899734</td>\n",
              "      <td>74.054367</td>\n",
              "      <td>1.517173</td>\n",
              "      <td>7100.083586</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>74.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>74.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>gafgyt_junk</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5 rows × 116 columns</p>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-387e6af8-32bb-4631-aa94-bb251c2f34d4')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-387e6af8-32bb-4631-aa94-bb251c2f34d4 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-387e6af8-32bb-4631-aa94-bb251c2f34d4');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "    <div id=\"df-12eae48f-3219-4d40-837a-919e4fd4ed7e\">\n",
              "      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-12eae48f-3219-4d40-837a-919e4fd4ed7e')\"\n",
              "                title=\"Suggest charts\"\n",
              "                style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "      </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "      <script>\n",
              "        async function quickchart(key) {\n",
              "          const quickchartButtonEl =\n",
              "            document.querySelector('#' + key + ' button');\n",
              "          quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "          quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "          try {\n",
              "            const charts = await google.colab.kernel.invokeFunction(\n",
              "                'suggestCharts', [key], {});\n",
              "          } catch (error) {\n",
              "            console.error('Error during call to suggestCharts:', error);\n",
              "          }\n",
              "          quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "          quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "        }\n",
              "        (() => {\n",
              "          let quickchartButtonEl =\n",
              "            document.querySelector('#df-12eae48f-3219-4d40-837a-919e4fd4ed7e button');\n",
              "          quickchartButtonEl.style.display =\n",
              "            google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "        })();\n",
              "      </script>\n",
              "    </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "data"
            }
          },
          "metadata": {},
          "execution_count": 13
        }
      ],
      "source": [
        "#shuffle rows of dataframe\n",
        "sampler=np.random.permutation(len(data))\n",
        "data=data.take(sampler)\n",
        "data.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vxRacyPkwgfH"
      },
      "outputs": [],
      "source": [
        "Y=data['type']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 256
        },
        "id": "UBhpnzcKImL4",
        "outputId": "0d744097-5caa-489f-f50d-8e1ea19250c6"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "        MI_dir_L5_weight  MI_dir_L5_mean  MI_dir_L5_variance  \\\n",
              "115187        124.434012      315.447400        64002.536297   \n",
              "156451        112.526213       71.894175           25.047047   \n",
              "220761        201.315139       75.290699          516.807236   \n",
              "302269        210.373601       68.553549           46.586487   \n",
              "211524        170.547840       74.103294            2.468375   \n",
              "\n",
              "        MI_dir_L3_weight  MI_dir_L3_mean  MI_dir_L3_variance  \\\n",
              "115187        195.177727      356.652257        62101.396719   \n",
              "156451        203.190340       70.862213           34.083310   \n",
              "220761        313.387608       75.000542          395.502360   \n",
              "302269        308.751721       69.167109           44.303639   \n",
              "211524        278.386315       74.079990            1.913354   \n",
              "\n",
              "        MI_dir_L1_weight  MI_dir_L1_mean  MI_dir_L1_variance  \\\n",
              "115187        600.118553      385.491154        58749.358768   \n",
              "156451        656.608775       69.886058           40.671256   \n",
              "220761        843.391802       74.467507          175.645093   \n",
              "302269        770.773162       70.202399           38.744644   \n",
              "211524        825.899734       74.054367            1.517173   \n",
              "\n",
              "        MI_dir_L0.1_weight  ...  HpHp_L0.1_radius  HpHp_L0.1_covariance  \\\n",
              "115187         6310.217408  ...               0.0                   0.0   \n",
              "156451         6674.086636  ...               0.0                   0.0   \n",
              "220761         2431.102726  ...               0.0                   0.0   \n",
              "302269         6955.445694  ...               0.0                   0.0   \n",
              "211524         7100.083586  ...               0.0                   0.0   \n",
              "\n",
              "        HpHp_L0.1_pcc  HpHp_L0.01_weight  HpHp_L0.01_mean  HpHp_L0.01_std  \\\n",
              "115187            0.0                1.0             60.0             0.0   \n",
              "156451            0.0                1.0             74.0             0.0   \n",
              "220761            0.0                1.0             74.0             0.0   \n",
              "302269            0.0                1.0             60.0             0.0   \n",
              "211524            0.0                1.0             74.0             0.0   \n",
              "\n",
              "        HpHp_L0.01_magnitude  HpHp_L0.01_radius  HpHp_L0.01_covariance  \\\n",
              "115187                  60.0                0.0                    0.0   \n",
              "156451                  74.0                0.0                    0.0   \n",
              "220761                  74.0                0.0                    0.0   \n",
              "302269                  60.0                0.0                    0.0   \n",
              "211524                  74.0                0.0                    0.0   \n",
              "\n",
              "        HpHp_L0.01_pcc  \n",
              "115187             0.0  \n",
              "156451             0.0  \n",
              "220761             0.0  \n",
              "302269             0.0  \n",
              "211524             0.0  \n",
              "\n",
              "[5 rows x 115 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-e85b1426-9a74-4140-b7e7-684469600dcd\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>MI_dir_L5_weight</th>\n",
              "      <th>MI_dir_L5_mean</th>\n",
              "      <th>MI_dir_L5_variance</th>\n",
              "      <th>MI_dir_L3_weight</th>\n",
              "      <th>MI_dir_L3_mean</th>\n",
              "      <th>MI_dir_L3_variance</th>\n",
              "      <th>MI_dir_L1_weight</th>\n",
              "      <th>MI_dir_L1_mean</th>\n",
              "      <th>MI_dir_L1_variance</th>\n",
              "      <th>MI_dir_L0.1_weight</th>\n",
              "      <th>...</th>\n",
              "      <th>HpHp_L0.1_radius</th>\n",
              "      <th>HpHp_L0.1_covariance</th>\n",
              "      <th>HpHp_L0.1_pcc</th>\n",
              "      <th>HpHp_L0.01_weight</th>\n",
              "      <th>HpHp_L0.01_mean</th>\n",
              "      <th>HpHp_L0.01_std</th>\n",
              "      <th>HpHp_L0.01_magnitude</th>\n",
              "      <th>HpHp_L0.01_radius</th>\n",
              "      <th>HpHp_L0.01_covariance</th>\n",
              "      <th>HpHp_L0.01_pcc</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>115187</th>\n",
              "      <td>124.434012</td>\n",
              "      <td>315.447400</td>\n",
              "      <td>64002.536297</td>\n",
              "      <td>195.177727</td>\n",
              "      <td>356.652257</td>\n",
              "      <td>62101.396719</td>\n",
              "      <td>600.118553</td>\n",
              "      <td>385.491154</td>\n",
              "      <td>58749.358768</td>\n",
              "      <td>6310.217408</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>60.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>60.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>156451</th>\n",
              "      <td>112.526213</td>\n",
              "      <td>71.894175</td>\n",
              "      <td>25.047047</td>\n",
              "      <td>203.190340</td>\n",
              "      <td>70.862213</td>\n",
              "      <td>34.083310</td>\n",
              "      <td>656.608775</td>\n",
              "      <td>69.886058</td>\n",
              "      <td>40.671256</td>\n",
              "      <td>6674.086636</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>74.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>74.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>220761</th>\n",
              "      <td>201.315139</td>\n",
              "      <td>75.290699</td>\n",
              "      <td>516.807236</td>\n",
              "      <td>313.387608</td>\n",
              "      <td>75.000542</td>\n",
              "      <td>395.502360</td>\n",
              "      <td>843.391802</td>\n",
              "      <td>74.467507</td>\n",
              "      <td>175.645093</td>\n",
              "      <td>2431.102726</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>74.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>74.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>302269</th>\n",
              "      <td>210.373601</td>\n",
              "      <td>68.553549</td>\n",
              "      <td>46.586487</td>\n",
              "      <td>308.751721</td>\n",
              "      <td>69.167109</td>\n",
              "      <td>44.303639</td>\n",
              "      <td>770.773162</td>\n",
              "      <td>70.202399</td>\n",
              "      <td>38.744644</td>\n",
              "      <td>6955.445694</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>60.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>60.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>211524</th>\n",
              "      <td>170.547840</td>\n",
              "      <td>74.103294</td>\n",
              "      <td>2.468375</td>\n",
              "      <td>278.386315</td>\n",
              "      <td>74.079990</td>\n",
              "      <td>1.913354</td>\n",
              "      <td>825.899734</td>\n",
              "      <td>74.054367</td>\n",
              "      <td>1.517173</td>\n",
              "      <td>7100.083586</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>74.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>74.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5 rows × 115 columns</p>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-e85b1426-9a74-4140-b7e7-684469600dcd')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-e85b1426-9a74-4140-b7e7-684469600dcd button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-e85b1426-9a74-4140-b7e7-684469600dcd');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "    <div id=\"df-ed8570b0-d006-4796-bc9d-8809120fb190\">\n",
              "      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-ed8570b0-d006-4796-bc9d-8809120fb190')\"\n",
              "                title=\"Suggest charts\"\n",
              "                style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "      </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "      <script>\n",
              "        async function quickchart(key) {\n",
              "          const quickchartButtonEl =\n",
              "            document.querySelector('#' + key + ' button');\n",
              "          quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "          quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "          try {\n",
              "            const charts = await google.colab.kernel.invokeFunction(\n",
              "                'suggestCharts', [key], {});\n",
              "          } catch (error) {\n",
              "            console.error('Error during call to suggestCharts:', error);\n",
              "          }\n",
              "          quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "          quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "        }\n",
              "        (() => {\n",
              "          let quickchartButtonEl =\n",
              "            document.querySelector('#df-ed8570b0-d006-4796-bc9d-8809120fb190 button');\n",
              "          quickchartButtonEl.style.display =\n",
              "            google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "        })();\n",
              "      </script>\n",
              "    </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "X"
            }
          },
          "metadata": {},
          "execution_count": 17
        }
      ],
      "source": [
        "#drop labels from training dataset\n",
        "X=data.drop(columns='type')\n",
        "X.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rlkwKK7Ep6vF",
        "outputId": "0bf2644a-1f15-45fd-ae41-fde8a793fca5"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(322007, 115)"
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ],
      "source": [
        "X.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CC1qGJ54xDkQ",
        "outputId": "dffeb33d-d6b6-4b5d-9726-bcf5fbe87f16"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(322007,)"
            ]
          },
          "metadata": {},
          "execution_count": 19
        }
      ],
      "source": [
        "Y.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 241
        },
        "id": "tUkMfaaVdC9U",
        "outputId": "3dda6afa-1440-43ac-cf9a-1559b6af0b07"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "115187      mirai_ack\n",
              "156451      mirai_syn\n",
              "220761    gafgyt_junk\n",
              "302269      mirai_syn\n",
              "211524    gafgyt_junk\n",
              "Name: type, dtype: object"
            ],
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>type</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>115187</th>\n",
              "      <td>mirai_ack</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>156451</th>\n",
              "      <td>mirai_syn</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>220761</th>\n",
              "      <td>gafgyt_junk</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>302269</th>\n",
              "      <td>mirai_syn</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>211524</th>\n",
              "      <td>gafgyt_junk</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div><br><label><b>dtype:</b> object</label>"
            ]
          },
          "metadata": {},
          "execution_count": 20
        }
      ],
      "source": [
        "Y.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zMLhU6IhVNF3"
      },
      "source": [
        "**ANOVA Feature selection method**\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qk0Tw7enPECp"
      },
      "outputs": [],
      "source": [
        "from sklearn.feature_selection import SelectKBest, SelectPercentile, chi2, f_classif, mutual_info_classif\n",
        "from sklearn.feature_selection import VarianceThreshold\n",
        "from sklearn.preprocessing import StandardScaler, LabelEncoder"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mQCn63skWI6r"
      },
      "outputs": [],
      "source": [
        "# Apply SelectKBest with the ANOVA F-test\n",
        "k = 40  # Define the number of top features to select\n",
        "selector = SelectKBest(score_func=f_classif, k=k)\n",
        "X_selected_A = selector.fit_transform(X,Y)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5eCGcXp8VLNS"
      },
      "outputs": [],
      "source": [
        "# Get selected feature indices and scores\n",
        "selected_indices = selector.get_support(indices=True)\n",
        "selected_feature_names = X.columns[selected_indices]\n",
        "selected_scores = selector.scores_[selected_indices]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "csi2pbRsVLRD",
        "outputId": "1ba6ba98-1b35-4e79-e043-3fe497095a85"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Selected top-k features based on ANOVA F-test:\n",
            "Feature: MI_dir_L5_weight, Score: 168076.4461830155\n",
            "Feature: MI_dir_L5_mean, Score: 185272.06943459314\n",
            "Feature: MI_dir_L5_variance, Score: 131628.47692110288\n",
            "Feature: MI_dir_L3_weight, Score: 284463.8743517018\n",
            "Feature: MI_dir_L3_mean, Score: 308599.74851945054\n",
            "Feature: MI_dir_L3_variance, Score: 286049.3959901718\n",
            "Feature: MI_dir_L1_weight, Score: 590057.369553962\n",
            "Feature: MI_dir_L1_mean, Score: 646613.2816798921\n",
            "Feature: MI_dir_L1_variance, Score: 1023563.6462573447\n",
            "Feature: MI_dir_L0.1_weight, Score: 481765.36715283664\n",
            "Feature: MI_dir_L0.1_mean, Score: 1115169.5513242092\n",
            "Feature: MI_dir_L0.1_variance, Score: 1843736.8810296496\n",
            "Feature: MI_dir_L0.01_weight, Score: 92832.79006634587\n",
            "Feature: MI_dir_L0.01_mean, Score: 1473558.8222519297\n",
            "Feature: MI_dir_L0.01_variance, Score: 1773699.2841217595\n",
            "Feature: H_L5_weight, Score: 168076.44618301344\n",
            "Feature: H_L5_mean, Score: 185272.06943464436\n",
            "Feature: H_L5_variance, Score: 131628.47692110273\n",
            "Feature: H_L3_weight, Score: 284463.8743503285\n",
            "Feature: H_L3_mean, Score: 308599.7486517587\n",
            "Feature: H_L3_variance, Score: 286049.3959897344\n",
            "Feature: H_L1_weight, Score: 590057.368597414\n",
            "Feature: H_L1_mean, Score: 646613.8688475761\n",
            "Feature: H_L1_variance, Score: 1023563.6465682158\n",
            "Feature: H_L0.1_weight, Score: 481765.3607514475\n",
            "Feature: H_L0.1_mean, Score: 1115986.723354642\n",
            "Feature: H_L0.1_variance, Score: 1843733.7983007513\n",
            "Feature: H_L0.01_weight, Score: 92832.78884781085\n",
            "Feature: H_L0.01_mean, Score: 1478910.4864875593\n",
            "Feature: H_L0.01_variance, Score: 1773649.9815942105\n",
            "Feature: HH_L5_weight, Score: 107775.38152589025\n",
            "Feature: HH_L3_weight, Score: 115839.10745355496\n",
            "Feature: HH_L1_weight, Score: 121430.0928711204\n",
            "Feature: HH_L0.1_weight, Score: 86331.34354693306\n",
            "Feature: HH_jit_L5_weight, Score: 107775.38152589038\n",
            "Feature: HH_jit_L3_weight, Score: 115839.10745355547\n",
            "Feature: HH_jit_L1_weight, Score: 121430.09287112049\n",
            "Feature: HH_jit_L0.1_weight, Score: 86331.34354693431\n",
            "Feature: HH_jit_L0.01_mean, Score: 47295.63466814239\n",
            "Feature: HH_jit_L0.01_variance, Score: 47215.90782973392\n"
          ]
        }
      ],
      "source": [
        "# Display selected features and their ANOVA F-scores\n",
        "print(\"Selected top-k features based on ANOVA F-test:\")\n",
        "for feature, score in zip(selected_feature_names, selected_scores):\n",
        "    print(f\"Feature: {feature}, Score: {score}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NEQki2ybVLUc"
      },
      "outputs": [],
      "source": [
        "# Create a DataFrame with selected features\n",
        "X_selected_dfA = pd.DataFrame(X_selected_A, columns=selected_feature_names)\n",
        "\n",
        "selected_data_A = pd.concat([X_selected_dfA, Y.reset_index(drop=True)], axis=1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 290
        },
        "id": "7ePcJnDMVLX1",
        "outputId": "382e8021-36ee-43e1-fb38-39bc0419d578"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "DataFrame with selected features and target label:\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "   MI_dir_L5_weight  MI_dir_L5_mean  MI_dir_L5_variance  MI_dir_L3_weight  \\\n",
              "0        124.434012      315.447400        64002.536297        195.177727   \n",
              "1        112.526213       71.894175           25.047047        203.190340   \n",
              "2        201.315139       75.290699          516.807236        313.387608   \n",
              "3        210.373601       68.553549           46.586487        308.751721   \n",
              "4        170.547840       74.103294            2.468375        278.386315   \n",
              "\n",
              "   MI_dir_L3_mean  MI_dir_L3_variance  MI_dir_L1_weight  MI_dir_L1_mean  \\\n",
              "0      356.652257        62101.396719        600.118553      385.491154   \n",
              "1       70.862213           34.083310        656.608775       69.886058   \n",
              "2       75.000542          395.502360        843.391802       74.467507   \n",
              "3       69.167109           44.303639        770.773162       70.202399   \n",
              "4       74.079990            1.913354        825.899734       74.054367   \n",
              "\n",
              "   MI_dir_L1_variance  MI_dir_L0.1_weight  ...  HH_L3_weight  HH_L1_weight  \\\n",
              "0        58749.358768         6310.217408  ...      1.000000      1.000000   \n",
              "1           40.671256         6674.086636  ...    157.649783    463.685178   \n",
              "2          175.645093         2431.102726  ...    311.135640    839.450514   \n",
              "3           38.744644         6955.445694  ...      1.000000      1.000000   \n",
              "4            1.517173         7100.083586  ...    277.458480    824.048082   \n",
              "\n",
              "   HH_L0.1_weight  HH_jit_L5_weight  HH_jit_L3_weight  HH_jit_L1_weight  \\\n",
              "0        1.000000          1.000000          1.000000          1.000000   \n",
              "1     4512.129096         95.600465        157.649783        463.685178   \n",
              "2     2421.911846        199.696019        311.135640        839.450514   \n",
              "3        1.000000          1.000000          1.000000          1.000000   \n",
              "4     7080.326584        169.813820        277.458480        824.048082   \n",
              "\n",
              "   HH_jit_L0.1_weight  HH_jit_L0.01_mean  HH_jit_L0.01_variance         type  \n",
              "0            1.000000       1.507658e+09           0.000000e+00    mirai_ack  \n",
              "1         4512.129096       1.332243e+04           2.008547e+13    mirai_syn  \n",
              "2         2421.911846       5.201024e+05           7.829589e+14  gafgyt_junk  \n",
              "3            1.000000       1.507657e+09           0.000000e+00    mirai_syn  \n",
              "4         7080.326584       8.655504e+04           1.303369e+14  gafgyt_junk  \n",
              "\n",
              "[5 rows x 41 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-4400a079-a9eb-4301-97bf-ea9501f6d3c7\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>MI_dir_L5_weight</th>\n",
              "      <th>MI_dir_L5_mean</th>\n",
              "      <th>MI_dir_L5_variance</th>\n",
              "      <th>MI_dir_L3_weight</th>\n",
              "      <th>MI_dir_L3_mean</th>\n",
              "      <th>MI_dir_L3_variance</th>\n",
              "      <th>MI_dir_L1_weight</th>\n",
              "      <th>MI_dir_L1_mean</th>\n",
              "      <th>MI_dir_L1_variance</th>\n",
              "      <th>MI_dir_L0.1_weight</th>\n",
              "      <th>...</th>\n",
              "      <th>HH_L3_weight</th>\n",
              "      <th>HH_L1_weight</th>\n",
              "      <th>HH_L0.1_weight</th>\n",
              "      <th>HH_jit_L5_weight</th>\n",
              "      <th>HH_jit_L3_weight</th>\n",
              "      <th>HH_jit_L1_weight</th>\n",
              "      <th>HH_jit_L0.1_weight</th>\n",
              "      <th>HH_jit_L0.01_mean</th>\n",
              "      <th>HH_jit_L0.01_variance</th>\n",
              "      <th>type</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>124.434012</td>\n",
              "      <td>315.447400</td>\n",
              "      <td>64002.536297</td>\n",
              "      <td>195.177727</td>\n",
              "      <td>356.652257</td>\n",
              "      <td>62101.396719</td>\n",
              "      <td>600.118553</td>\n",
              "      <td>385.491154</td>\n",
              "      <td>58749.358768</td>\n",
              "      <td>6310.217408</td>\n",
              "      <td>...</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.507658e+09</td>\n",
              "      <td>0.000000e+00</td>\n",
              "      <td>mirai_ack</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>112.526213</td>\n",
              "      <td>71.894175</td>\n",
              "      <td>25.047047</td>\n",
              "      <td>203.190340</td>\n",
              "      <td>70.862213</td>\n",
              "      <td>34.083310</td>\n",
              "      <td>656.608775</td>\n",
              "      <td>69.886058</td>\n",
              "      <td>40.671256</td>\n",
              "      <td>6674.086636</td>\n",
              "      <td>...</td>\n",
              "      <td>157.649783</td>\n",
              "      <td>463.685178</td>\n",
              "      <td>4512.129096</td>\n",
              "      <td>95.600465</td>\n",
              "      <td>157.649783</td>\n",
              "      <td>463.685178</td>\n",
              "      <td>4512.129096</td>\n",
              "      <td>1.332243e+04</td>\n",
              "      <td>2.008547e+13</td>\n",
              "      <td>mirai_syn</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>201.315139</td>\n",
              "      <td>75.290699</td>\n",
              "      <td>516.807236</td>\n",
              "      <td>313.387608</td>\n",
              "      <td>75.000542</td>\n",
              "      <td>395.502360</td>\n",
              "      <td>843.391802</td>\n",
              "      <td>74.467507</td>\n",
              "      <td>175.645093</td>\n",
              "      <td>2431.102726</td>\n",
              "      <td>...</td>\n",
              "      <td>311.135640</td>\n",
              "      <td>839.450514</td>\n",
              "      <td>2421.911846</td>\n",
              "      <td>199.696019</td>\n",
              "      <td>311.135640</td>\n",
              "      <td>839.450514</td>\n",
              "      <td>2421.911846</td>\n",
              "      <td>5.201024e+05</td>\n",
              "      <td>7.829589e+14</td>\n",
              "      <td>gafgyt_junk</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>210.373601</td>\n",
              "      <td>68.553549</td>\n",
              "      <td>46.586487</td>\n",
              "      <td>308.751721</td>\n",
              "      <td>69.167109</td>\n",
              "      <td>44.303639</td>\n",
              "      <td>770.773162</td>\n",
              "      <td>70.202399</td>\n",
              "      <td>38.744644</td>\n",
              "      <td>6955.445694</td>\n",
              "      <td>...</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.507657e+09</td>\n",
              "      <td>0.000000e+00</td>\n",
              "      <td>mirai_syn</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>170.547840</td>\n",
              "      <td>74.103294</td>\n",
              "      <td>2.468375</td>\n",
              "      <td>278.386315</td>\n",
              "      <td>74.079990</td>\n",
              "      <td>1.913354</td>\n",
              "      <td>825.899734</td>\n",
              "      <td>74.054367</td>\n",
              "      <td>1.517173</td>\n",
              "      <td>7100.083586</td>\n",
              "      <td>...</td>\n",
              "      <td>277.458480</td>\n",
              "      <td>824.048082</td>\n",
              "      <td>7080.326584</td>\n",
              "      <td>169.813820</td>\n",
              "      <td>277.458480</td>\n",
              "      <td>824.048082</td>\n",
              "      <td>7080.326584</td>\n",
              "      <td>8.655504e+04</td>\n",
              "      <td>1.303369e+14</td>\n",
              "      <td>gafgyt_junk</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5 rows × 41 columns</p>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-4400a079-a9eb-4301-97bf-ea9501f6d3c7')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-4400a079-a9eb-4301-97bf-ea9501f6d3c7 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-4400a079-a9eb-4301-97bf-ea9501f6d3c7');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "    <div id=\"df-b9aae2dd-f06b-4e56-8473-9380f69b4f6c\">\n",
              "      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-b9aae2dd-f06b-4e56-8473-9380f69b4f6c')\"\n",
              "                title=\"Suggest charts\"\n",
              "                style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "      </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "      <script>\n",
              "        async function quickchart(key) {\n",
              "          const quickchartButtonEl =\n",
              "            document.querySelector('#' + key + ' button');\n",
              "          quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "          quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "          try {\n",
              "            const charts = await google.colab.kernel.invokeFunction(\n",
              "                'suggestCharts', [key], {});\n",
              "          } catch (error) {\n",
              "            console.error('Error during call to suggestCharts:', error);\n",
              "          }\n",
              "          quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "          quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "        }\n",
              "        (() => {\n",
              "          let quickchartButtonEl =\n",
              "            document.querySelector('#df-b9aae2dd-f06b-4e56-8473-9380f69b4f6c button');\n",
              "          quickchartButtonEl.style.display =\n",
              "            google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "        })();\n",
              "      </script>\n",
              "    </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "selected_data_A"
            }
          },
          "metadata": {},
          "execution_count": 26
        }
      ],
      "source": [
        "print(\"\\nDataFrame with selected features and target label:\")\n",
        "selected_data_A.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VPJEX-D1nILU"
      },
      "source": [
        "**Split learning Model using pearson ANOVA-F based feature selection**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "D4234ejIzk5V"
      },
      "outputs": [],
      "source": [
        "# Convert application names to numbers\n",
        "encoder = LabelEncoder()\n",
        "encoder.fit(Y)\n",
        "encoded_Y = encoder.transform(Y)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ODxE56TI0iWa",
        "outputId": "18a7e3c4-101b-4dcc-c0be-2d5e136f5865"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[('benign', 24177), ('gafgyt_combo', 29780), ('gafgyt_junk', 28240), ('gafgyt_scan', 29210), ('gafgyt_tcp', 28532), ('gafgyt_udp', 31328), ('mirai_ack', 31407), ('mirai_scan', 22704), ('mirai_syn', 36758), ('mirai_udp', 31580), ('mirai_udpplain', 28291)]\n"
          ]
        }
      ],
      "source": [
        "print(sorted(Counter(Y).items()))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hjLsV6E4zmLx"
      },
      "outputs": [],
      "source": [
        "smote = SMOTE(sampling_strategy='auto', random_state=42)\n",
        "X_resampled, y_resampled = smote.fit_resample(X_selected_dfA, encoded_Y)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RrychZk2zmO5",
        "outputId": "07562313-70b2-476e-9a21-ca41e69e105f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[(np.int64(0), 24177), (np.int64(1), 29780), (np.int64(2), 28240), (np.int64(3), 29210), (np.int64(4), 28532), (np.int64(5), 31328), (np.int64(6), 31407), (np.int64(7), 22704), (np.int64(8), 36758), (np.int64(9), 31580), (np.int64(10), 28291)]\n"
          ]
        }
      ],
      "source": [
        "print(sorted(Counter(encoded_Y).items()))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gv3MHntt4qQz",
        "outputId": "e939dc83-8710-4ad3-bf29-4a12242fa28b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[(np.int64(0), 36758), (np.int64(1), 36758), (np.int64(2), 36758), (np.int64(3), 36758), (np.int64(4), 36758), (np.int64(5), 36758), (np.int64(6), 36758), (np.int64(7), 36758), (np.int64(8), 36758), (np.int64(9), 36758), (np.int64(10), 36758)]\n"
          ]
        }
      ],
      "source": [
        "print(sorted(Counter(y_resampled).items()))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Huxo1pYzzmR1",
        "outputId": "5055d18b-1c28-4f8f-892f-416841f329c2"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([8, 2, 8, 2, 6, 8, 6, 9, 5])"
            ]
          },
          "metadata": {},
          "execution_count": 32
        }
      ],
      "source": [
        "encoded_Y[1:10]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MfV6rXCI1f_F",
        "outputId": "1706d5bd-b625-4eff-c834-03a3c4e5ea12"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(404338, 40)"
            ]
          },
          "metadata": {},
          "execution_count": 33
        }
      ],
      "source": [
        "X_resampled.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Md3RPXLF1gCl",
        "outputId": "ca15bac3-38f3-4c0f-e6aa-35d24f3f1388"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(404338,)"
            ]
          },
          "metadata": {},
          "execution_count": 34
        }
      ],
      "source": [
        " y_resampled.shape\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8Ihfq5rEVLg7"
      },
      "outputs": [],
      "source": [
        "#split data\n",
        "from sklearn.model_selection import train_test_split\n",
        "X_train, X_test, y_train, y_test,= train_test_split(X_resampled, y_resampled, train_size = 0.70, random_state=100)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mTG_CfygstP1"
      },
      "outputs": [],
      "source": [
        "# Data Transformation to Reduce Skewness\n",
        "power_transformer = PowerTransformer(method='yeo-johnson')\n",
        "X_train_transformed = power_transformer.fit_transform(X_train)\n",
        "X_test_transformed = power_transformer.transform(X_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "X0aOdT1TstU4"
      },
      "outputs": [],
      "source": [
        "# Standard Scaling After Transformation\n",
        "scaler = StandardScaler()\n",
        "X_train_scaled = scaler.fit_transform(X_train_transformed)\n",
        "X_test_scaled = scaler.transform(X_test_transformed)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-ZgGNdmcbzaO"
      },
      "outputs": [],
      "source": [
        "y_train=tf.keras.utils.to_categorical(y_train, num_classes=11)\n",
        "y_test = tf.keras.utils.to_categorical(y_test, num_classes=11)  # One-hot encoding for test labels"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "unique, counts = np.unique(y_train, return_counts=True)\n",
        "print(dict(zip(unique, counts)))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kQFfO0dlt7Gp",
        "outputId": "d538e0af-1652-48bd-9af7-2ad2c7c46f15"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{np.float64(0.0): np.int64(2830360), np.float64(1.0): np.int64(283036)}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from collections import Counter\n",
        "\n",
        "# Assuming your labels are one-hot encoded, convert to class indices\n",
        "y_train_labels = np.argmax(y_train, axis=1)\n",
        "y_test_labels = np.argmax(y_test, axis=1)\n",
        "\n",
        "# Print class distribution\n",
        "print(\"Training class distribution:\")\n",
        "print(Counter(y_train_labels))\n",
        "\n",
        "print(\"\\nTesting class distribution:\")\n",
        "print(Counter(y_test_labels))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "o8hw0ztTuoRH",
        "outputId": "a6477210-2879-44ee-e8f1-e56c41cd95fb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training class distribution:\n",
            "Counter({np.int64(1): 25852, np.int64(5): 25806, np.int64(0): 25806, np.int64(3): 25800, np.int64(4): 25752, np.int64(2): 25739, np.int64(9): 25702, np.int64(6): 25683, np.int64(10): 25671, np.int64(8): 25656, np.int64(7): 25569})\n",
            "\n",
            "Testing class distribution:\n",
            "Counter({np.int64(7): 11189, np.int64(8): 11102, np.int64(10): 11087, np.int64(6): 11075, np.int64(9): 11056, np.int64(2): 11019, np.int64(4): 11006, np.int64(3): 10958, np.int64(5): 10952, np.int64(0): 10952, np.int64(1): 10906})\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y_train[1:10]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XRYljQRZ03TG",
        "outputId": "fc0f3992-b0af-4e3b-aa36-27ec2d781507"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0.],\n",
              "       [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
              "       [0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0.],\n",
              "       [0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0.],\n",
              "       [0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0.],\n",
              "       [0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0.],\n",
              "       [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
              "       [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
              "       [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.]])"
            ]
          },
          "metadata": {},
          "execution_count": 39
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5KQZ8U8I7cCn",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ee5ec98c-abf9-4177-88c2-1fa38bc6567d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m61.0/61.0 kB\u001b[0m \u001b[31m2.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m242.5/242.5 kB\u001b[0m \u001b[31m5.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m18.3/18.3 MB\u001b[0m \u001b[31m58.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "thinc 8.3.6 requires numpy<3.0.0,>=2.0.0, but you have numpy 1.26.4 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0m"
          ]
        }
      ],
      "source": [
        "! pip install -q tensorflow-model-optimization"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "***Dt:23/04/25***\n"
      ],
      "metadata": {
        "id": "obnaaCBj2QMx"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "E4ig60K1HPjd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f34f0802-d257-4abb-a746-426c6d4cb2c7",
        "id": "qczLuDvvmSuz"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/keras/src/layers/pooling/base_pooling.py:23: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(name=name, **kwargs)\n"
          ]
        }
      ],
      "source": [
        "import socket\n",
        "import pickle\n",
        "import zlib\n",
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "from tensorflow.keras import Sequential\n",
        "from tensorflow.keras.layers import MaxPooling1D, Flatten, Dense, BatchNormalization\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "import threading\n",
        "from sklearn.metrics import precision_score, recall_score, f1_score\n",
        "from tensorflow.keras.layers import Dropout\n",
        "from sklearn.metrics import confusion_matrix\n",
        "# Server-side model\n",
        "def create_server_model():\n",
        "    model = Sequential([\n",
        "        MaxPooling1D(pool_size=2,input_shape=(20, 64)),\n",
        "        Conv1D(128, kernel_size=3, activation='relu',padding='same'),\n",
        "        BatchNormalization(),\n",
        "        Conv1D(128, kernel_size=3, activation='relu',padding='same'),\n",
        "        BatchNormalization(),\n",
        "        MaxPooling1D(pool_size=2),\n",
        "        Conv1D(256, kernel_size=3, activation='relu',padding='same'),\n",
        "        BatchNormalization(),\n",
        "        Conv1D(256, kernel_size=3, activation='relu',padding='same'),\n",
        "        BatchNormalization(),\n",
        "        MaxPooling1D(pool_size=2),\n",
        "        Flatten(),\n",
        "        Dense(256, activation='relu'),\n",
        "        Dropout(0.3),\n",
        "        Dense(128, activation='relu'),\n",
        "        Dropout(0.2),\n",
        "        Dense(11, activation='softmax')\n",
        "    ])\n",
        "    model.compile(optimizer=Adam(learning_rate=0.001),\n",
        "                  loss='categorical_crossentropy',\n",
        "                  metrics=['accuracy'])\n",
        "    return model\n",
        "\n",
        "# Deserialize and decompress data\n",
        "def deserialize_data(data):\n",
        "    return pickle.loads(zlib.decompress(data))\n",
        "\n",
        "# Server function\n",
        "def start_server(host='127.0.0.1', port=65436):\n",
        "    server_model = create_server_model()\n",
        "    server_socket = socket.socket(socket.AF_INET, socket.SOCK_STREAM)\n",
        "    server_socket.bind((host, port))\n",
        "    server_socket.listen(1)\n",
        "    print(\"Server waiting for connection...\")\n",
        "    conn, addr = server_socket.accept()\n",
        "    print(f\"Connected to client: {addr}\")\n",
        "    lr_schedule = tf.keras.optimizers.schedules.ExponentialDecay(\n",
        "    initial_learning_rate=0.001,\n",
        "    decay_steps=10000,\n",
        "    decay_rate=0.9\n",
        "    )\n",
        "    optimizer = tf.keras.optimizers.Adam(learning_rate=lr_schedule)\n",
        "\n",
        "    all_true_labels = []\n",
        "    all_pred_labels = []\n",
        "\n",
        "\n",
        "    while True:\n",
        "        try:\n",
        "            # Receive header indicating batch size\n",
        "            header = conn.recv(8)\n",
        "            if not header:\n",
        "                break\n",
        "            data_size = int(header.decode('utf-8').strip())\n",
        "\n",
        "\n",
        "            # If a special flag (e.g., -1) is sent, switch to evaluation\n",
        "            if data_size == -1:\n",
        "              print(\"Switching to evaluation phase...\")\n",
        "              break\n",
        "\n",
        "            # Receive the batch data\n",
        "            data = b\"\"\n",
        "            while len(data) < data_size:\n",
        "                packet = conn.recv(4096)\n",
        "                if not packet:\n",
        "                    break\n",
        "                data += packet\n",
        "\n",
        "            # Deserialize the data\n",
        "            intermediate_output, labels = deserialize_data(data)\n",
        "\n",
        "            # Perform forward pass and backpropagation on batch\n",
        "            with tf.GradientTape() as tape:\n",
        "                logits = server_model(np.array(intermediate_output), training=True)\n",
        "                loss = tf.reduce_mean(\n",
        "                    tf.keras.losses.categorical_crossentropy(np.array(labels), logits)\n",
        "                )\n",
        "            gradients = tape.gradient(loss, server_model.trainable_variables)\n",
        "            optimizer.apply_gradients(zip(gradients, server_model.trainable_variables))\n",
        "\n",
        "            pred_classes = np.argmax(logits.numpy(), axis=1)\n",
        "            true_classes = np.argmax(labels, axis=1)\n",
        "\n",
        "            all_pred_labels.extend(pred_classes)\n",
        "            all_true_labels.extend(true_classes)\n",
        "\n",
        "            correct_predictions = int(np.sum(\n",
        "                np.argmax(logits.numpy(), axis=1) == np.argmax(labels, axis=1)\n",
        "            ))\n",
        "            response = f\"{loss.numpy():.4f},{correct_predictions}\"\n",
        "            conn.sendall(f\"{len(response):08}\".encode('utf-8'))\n",
        "            conn.sendall(response.encode('utf-8'))\n",
        "\n",
        "        except Exception as e:\n",
        "            print(f\"Error: {e}\")\n",
        "            break\n",
        "\n",
        "    # At the end of training\n",
        "    precision = precision_score(all_true_labels, all_pred_labels, average='macro')\n",
        "    recall = recall_score(all_true_labels, all_pred_labels, average='macro')\n",
        "    f1 = f1_score(all_true_labels, all_pred_labels, average='macro')\n",
        "    print(f\"\\nTraining Metrics → Precision: {precision:.4f}, Recall: {recall:.4f}, F1 Score: {f1:.4f}\")\n",
        "\n",
        "    # Handle test evaluation\n",
        "    print(\"Evaluating test data...\")\n",
        "\n",
        "    all_test_true = []\n",
        "    all_test_pred = []\n",
        "\n",
        "    while True:\n",
        "        header = conn.recv(8)\n",
        "        if not header:\n",
        "            break\n",
        "        test_data_size = int(header.decode('utf-8').strip())\n",
        "        test_data = b\"\"\n",
        "        while len(test_data) < test_data_size:\n",
        "            packet = conn.recv(4096)\n",
        "            if not packet:\n",
        "                break\n",
        "            test_data += packet\n",
        "\n",
        "        test_intermediate, test_labels = deserialize_data(test_data)\n",
        "        logits = server_model(np.array(test_intermediate), training=False)\n",
        "\n",
        "        test_intermediate = np.array(test_intermediate)\n",
        "        test_labels = np.array(test_labels)\n",
        "\n",
        "        logits = server_model(test_intermediate, training=False)\n",
        "        pred_classes = np.argmax(logits.numpy(), axis=1)\n",
        "        true_classes = np.argmax(test_labels, axis=1)\n",
        "\n",
        "        all_test_pred.extend(pred_classes)\n",
        "        all_test_true.extend(true_classes)\n",
        "        conf_matrix_test = confusion_matrix(all_test_true, all_test_pred)\n",
        "        print(\"Testing Confusion Matrix:\\n\", conf_matrix_test)\n",
        "        correct_predictions = int(np.sum(\n",
        "            np.argmax(logits.numpy(), axis=1) == np.argmax(test_labels, axis=1)\n",
        "        ))\n",
        "        response = f\"{correct_predictions}\"\n",
        "        conn.sendall(f\"{len(response):08}\".encode('utf-8'))\n",
        "        conn.sendall(response.encode('utf-8'))\n",
        "\n",
        "    # Final test metrics\n",
        "    precision = precision_score(all_test_true, all_test_pred, average='macro')\n",
        "    recall = recall_score(all_test_true, all_test_pred, average='macro')\n",
        "    f1 = f1_score(all_test_true, all_test_pred, average='macro')\n",
        "    conf_matrix_test = confusion_matrix(all_test_true, all_test_pred)\n",
        "    print(f\"\\nTesting Metrics → Precision: {precision:.4f}, Recall: {recall:.4f}, F1 Score: {f1:.4f}\")\n",
        "    print(\"Testing Confusion Matrix:\\n\", conf_matrix_test)\n",
        "\n",
        "\n",
        "    conn.close()\n",
        "    server_socket.close()\n",
        "    print(\"Server connection closed.\")\n",
        "\n",
        "server_thread = threading.Thread(target=start_server)\n",
        "server_thread.start()\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "k5u9AMmkmNAZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d44331ff-3ec0-4598-9669-dca7b2121026",
        "id": "o3SV7DC-mYaP",
        "collapsed": true
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/keras/src/layers/convolutional/base_conv.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Connected to client: ('127.0.0.1', 41010)\n",
            "Connected to server!\n",
            "\n",
            "Starting Training...\n",
            "\n",
            "Epoch 1/1\n",
            "Batch 553/553 - Progress: 100.00% - Loss: 0.1672\n",
            "Epoch 1 completed: Avg Loss = 0.2537, Training Accuracy = 0.8545\n",
            "\n",
            "Training completed in 961.52 seconds.\n",
            "Switching to evaluation phase...\n",
            "Training complete. Signaled server to start evaluation.\n",
            "\n",
            "Evaluating on test data...\n",
            "\n",
            "Training Metrics → Precision: 0.8554, Recall: 0.8547, F1 Score: 0.8545\n",
            "Evaluating test data...\n",
            "Testing Confusion Matrix:\n",
            " [[46  0  0  0  0  0  0  0  0  0  0]\n",
            " [ 0 42  1  0  0  0  0  0  0  0  0]\n",
            " [ 0  2 34  0  0  0  0  0  0  0  0]\n",
            " [ 0  0  0 43  0  0  0  0  0  0  0]\n",
            " [ 0  0  0  0  0 51  0  0  0  0  0]\n",
            " [ 0  0  0  0  0 48  0  0  0  0  0]\n",
            " [ 0  0  0  0  0  0  0  0  0 46  0]\n",
            " [ 0  0  0  0  0  0  0 45  0  0  0]\n",
            " [ 0  0  0  0  0  0  0  0 48  0  0]\n",
            " [ 0  0  0  0  0  0  0  0  0 52  0]\n",
            " [ 0  0  0  0  0  0  1  0  0 38 15]]\n",
            "Batch 1/237 - Batch Inference Time: 2.8099 seconds\n",
            "Testing Confusion Matrix:\n",
            " [[ 87   0   0   0   0   0   0   0   0   0   0]\n",
            " [  0  77   3   0   0   0   0   0   0   0   0]\n",
            " [  0   3  61   0   0   0   0   0   0   0   0]\n",
            " [  0   0   0  89   0   0   0   0   0   0   0]\n",
            " [  0   0   0   0   0 105   0   0   0   0   0]\n",
            " [  0   0   0   0   0  89   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0   0   0 102   0]\n",
            " [  0   0   0   0   0   0   0  99   0   0   0]\n",
            " [  0   0   0   0   0   0   0   0  94   0   0]\n",
            " [  0   0   0   0   0   0   0   0   0 102   0]\n",
            " [  0   0   0   0   0   0   1   0   0  79  33]]\n",
            "Batch 2/237 - Batch Inference Time: 1.3128 seconds\n",
            "Testing Confusion Matrix:\n",
            " [[138   0   0   0   0   0   0   0   0   0   0]\n",
            " [  0 125   4   0   0   0   0   0   0   0   0]\n",
            " [  0   5 110   0   0   0   0   0   0   0   0]\n",
            " [  0   0   0 126   0   0   0   0   0   0   0]\n",
            " [  0   0   0   0   0 152   0   0   0   0   0]\n",
            " [  0   0   0   0   0 133   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0   0   0 148   0]\n",
            " [  0   0   0   0   0   0   0 138   0   0   0]\n",
            " [  0   0   0   0   0   0   0   0 140   0   0]\n",
            " [  0   0   0   0   0   0   0   0   0 155   0]\n",
            " [  0   0   0   0   0   0   3   0   0 113  46]]\n",
            "Batch 3/237 - Batch Inference Time: 1.2617 seconds\n",
            "Testing Confusion Matrix:\n",
            " [[190   0   0   0   0   0   0   0   0   0   0]\n",
            " [  0 172   5   0   0   0   0   0   0   0   0]\n",
            " [  0   8 158   0   0   0   0   0   0   0   0]\n",
            " [  0   0   0 166   0   0   0   0   0   0   0]\n",
            " [  0   0   1   0   0 207   0   0   0   0   0]\n",
            " [  0   0   0   0   0 173   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0   0   0 185   0]\n",
            " [  0   0   0   0   0   0   0 207   0   0   0]\n",
            " [  0   0   0   0   0   0   0   0 175   0   0]\n",
            " [  0   0   0   0   0   0   0   0   0 204   0]\n",
            " [  0   0   0   0   0   0   3   0   0 133  61]]\n",
            "Batch 4/237 - Batch Inference Time: 1.3141 seconds\n",
            "Testing Confusion Matrix:\n",
            " [[242   0   0   0   0   0   0   0   0   0   0]\n",
            " [  0 222   5   0   0   0   0   0   0   0   0]\n",
            " [  0   8 192   0   0   0   0   0   0   0   0]\n",
            " [  0   0   0 218   0   0   0   0   0   0   0]\n",
            " [  0   0   1   0   0 258   0   0   0   0   0]\n",
            " [  0   0   0   0   0 216   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0   0   0 230   0]\n",
            " [  0   0   0   0   0   0   0 254   0   0   0]\n",
            " [  0   0   0   0   0   0   0   0 225   0   0]\n",
            " [  0   0   0   0   0   0   0   0   0 248   0]\n",
            " [  0   0   0   0   0   0   3   0   0 160  78]]\n",
            "Batch 5/237 - Batch Inference Time: 1.2474 seconds\n",
            "Testing Confusion Matrix:\n",
            " [[290   0   0   0   0   0   0   0   0   0   0]\n",
            " [  0 266   7   0   0   0   0   0   0   0   0]\n",
            " [  0   9 246   0   0   0   0   0   0   0   0]\n",
            " [  0   0   0 257   0   0   0   0   0   0   0]\n",
            " [  0   0   1   0   0 300   0   0   0   0   0]\n",
            " [  0   0   0   0   0 265   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0   0   0 280   0]\n",
            " [  0   0   0   0   0   0   0 299   0   0   0]\n",
            " [  0   0   0   0   0   0   0   0 272   0   0]\n",
            " [  0   0   0   0   0   0   0   0   0 295   0]\n",
            " [  0   0   0   0   0   0   3   0   0 188  94]]\n",
            "Batch 6/237 - Batch Inference Time: 1.2593 seconds\n",
            "Testing Confusion Matrix:\n",
            " [[333   0   0   0   0   0   0   0   0   0   0]\n",
            " [  0 303   8   0   0   0   0   0   0   0   0]\n",
            " [  0  11 303   0   0   0   0   0   0   0   0]\n",
            " [  0   0   0 296   0   0   0   0   0   0   0]\n",
            " [  0   0   1   0   0 337   0   0   0   0   0]\n",
            " [  0   0   0   0   0 316   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0   0   0 323   0]\n",
            " [  0   0   0   0   0   0   0 356   0   0   0]\n",
            " [  0   0   0   0   0   0   0   0 321   0   0]\n",
            " [  0   0   0   0   0   0   0   0   0 350   0]\n",
            " [  0   0   0   0   0   0   5   0   0 212 109]]\n",
            "Batch 7/237 - Batch Inference Time: 1.6037 seconds\n",
            "Testing Confusion Matrix:\n",
            " [[375   0   0   0   0   0   0   0   0   0   0]\n",
            " [  0 349   8   0   0   0   0   0   0   0   0]\n",
            " [  0  14 346   0   0   0   0   0   0   0   0]\n",
            " [  0   0   0 351   0   0   0   0   0   0   0]\n",
            " [  0   0   1   0   0 380   0   0   0   0   0]\n",
            " [  0   0   0   0   0 350   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0   0   0 366   0]\n",
            " [  0   0   0   0   0   0   0 407   0   0   0]\n",
            " [  0   0   0   0   0   0   0   0 380   0   0]\n",
            " [  0   0   0   0   0   0   0   0   0 394   0]\n",
            " [  0   0   0   0   0   0   5   0   0 239 131]]\n",
            "Batch 8/237 - Batch Inference Time: 1.7296 seconds\n",
            "Testing Confusion Matrix:\n",
            " [[421   0   0   0   0   0   0   0   0   0   0]\n",
            " [  0 391  12   0   0   0   0   0   0   0   0]\n",
            " [  0  16 391   0   0   0   0   0   0   0   0]\n",
            " [  0   0   0 388   0   0   0   0   0   0   0]\n",
            " [  0   0   1   0   0 428   0   0   0   0   0]\n",
            " [  0   0   0   0   0 401   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0   0   0 408   0]\n",
            " [  0   0   0   0   0   0   0 456   0   0   0]\n",
            " [  0   0   0   0   0   0   0   0 425   0   0]\n",
            " [  0   0   0   0   0   0   0   0   0 444   0]\n",
            " [  0   0   0   0   0   0   6   0   0 270 150]]\n",
            "Batch 9/237 - Batch Inference Time: 1.8048 seconds\n",
            "Testing Confusion Matrix:\n",
            " [[463   0   0   0   0   0   0   0   0   0   0]\n",
            " [  0 432  12   0   0   0   0   0   0   0   0]\n",
            " [  0  17 431   0   0   0   0   0   0   0   0]\n",
            " [  0   0   0 439   0   0   0   0   0   0   0]\n",
            " [  0   0   1   0   0 478   0   0   0   0   0]\n",
            " [  0   0   0   0   0 440   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0   0   0 454   0]\n",
            " [  0   0   0   0   0   0   0 501   0   0   0]\n",
            " [  0   0   0   0   0   0   0   0 480   0   0]\n",
            " [  0   0   0   0   0   0   0   0   0 501   0]\n",
            " [  0   0   0   0   0   0   6   0   0 301 164]]\n",
            "Batch 10/237 - Batch Inference Time: 1.3414 seconds\n",
            "Testing Confusion Matrix:\n",
            " [[501   0   0   0   0   0   0   0   0   0   0]\n",
            " [  0 472  12   0   0   0   0   0   0   0   0]\n",
            " [  0  20 465   0   0   0   0   0   0   0   0]\n",
            " [  0   0   0 484   0   0   0   0   0   0   0]\n",
            " [  0   0   1   0   0 527   0   0   0   0   0]\n",
            " [  0   0   0   0   0 488   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0   0   0 504   0]\n",
            " [  0   0   0   0   0   0   0 548   0   0   0]\n",
            " [  0   0   0   0   0   0   0   0 528   0   0]\n",
            " [  0   0   0   0   0   0   0   0   0 555   0]\n",
            " [  0   0   0   0   0   0   7   0   0 333 187]]\n",
            "Batch 11/237 - Batch Inference Time: 1.2934 seconds\n",
            "Testing Confusion Matrix:\n",
            " [[558   0   0   0   0   0   0   0   0   0   0]\n",
            " [  0 507  13   0   0   0   0   0   0   0   0]\n",
            " [  0  23 497   0   0   0   0   0   0   0   0]\n",
            " [  0   0   0 543   0   0   0   0   0   0   0]\n",
            " [  0   0   1   0   0 569   0   0   0   0   0]\n",
            " [  0   0   0   0   0 532   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0   0   0 547   0]\n",
            " [  0   0   0   0   0   0   0 601   0   0   0]\n",
            " [  0   0   0   0   0   0   0   0 572   0   0]\n",
            " [  0   0   0   0   0   0   0   0   0 598   0]\n",
            " [  0   0   0   0   0   0   8   0   0 361 214]]\n",
            "Batch 12/237 - Batch Inference Time: 1.2596 seconds\n",
            "Testing Confusion Matrix:\n",
            " [[601   0   0   0   0   0   0   0   0   0   0]\n",
            " [  0 550  14   0   0   0   0   0   0   0   0]\n",
            " [  0  26 541   0   0   0   0   0   0   0   0]\n",
            " [  0   0   0 604   0   0   0   0   0   0   0]\n",
            " [  0   0   1   0   0 616   0   0   0   0   0]\n",
            " [  0   0   0   0   0 572   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0   0   0 592   0]\n",
            " [  0   0   0   0   0   0   0 649   0   0   0]\n",
            " [  0   0   0   0   0   0   0   0 617   0   0]\n",
            " [  0   0   0   0   0   0   0   0   0 653   0]\n",
            " [  0   0   0   0   0   0   9   0   0 380 231]]\n",
            "Batch 13/237 - Batch Inference Time: 1.2499 seconds\n",
            "Testing Confusion Matrix:\n",
            " [[641   0   0   0   0   0   0   0   0   0   0]\n",
            " [  0 599  14   0   0   0   0   0   0   0   0]\n",
            " [  0  27 598   0   0   0   0   0   0   0   0]\n",
            " [  0   0   0 649   0   0   0   0   0   0   0]\n",
            " [  0   0   1   0   0 653   0   0   0   0   0]\n",
            " [  0   0   0   0   0 611   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0   0   0 650   0]\n",
            " [  0   0   0   0   0   0   0 690   0   0   0]\n",
            " [  0   0   0   0   0   0   0   0 671   0   0]\n",
            " [  0   0   0   0   0   0   0   0   0 695   0]\n",
            " [  0   0   0   0   0   0   9   0   0 415 245]]\n",
            "Batch 14/237 - Batch Inference Time: 1.2927 seconds\n",
            "Testing Confusion Matrix:\n",
            " [[682   0   0   0   0   0   0   0   0   0   0]\n",
            " [  0 645  16   0   0   0   0   0   0   0   0]\n",
            " [  0  29 631   0   0   0   0   0   0   0   0]\n",
            " [  0   0   0 691   0   0   0   0   0   0   0]\n",
            " [  0   0   1   0   0 708   0   0   0   0   0]\n",
            " [  0   0   0   0   0 653   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0   0   0 688   0]\n",
            " [  0   0   0   0   0   0   0 744   0   0   0]\n",
            " [  0   0   0   0   0   0   0   0 722   0   0]\n",
            " [  0   0   0   0   0   0   0   0   0 748   0]\n",
            " [  0   0   0   0   0   0  10   0   0 444 268]]\n",
            "Batch 15/237 - Batch Inference Time: 1.2625 seconds\n",
            "Testing Confusion Matrix:\n",
            " [[718   0   0   0   0   0   0   0   0   0   0]\n",
            " [  0 694  16   0   0   0   0   0   0   0   0]\n",
            " [  0  33 666   0   0   0   0   0   0   0   0]\n",
            " [  0   0   0 738   0   0   0   0   0   0   0]\n",
            " [  0   0   1   0   0 760   0   0   0   0   0]\n",
            " [  0   0   0   0   0 709   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0   0   0 733   0]\n",
            " [  0   0   0   0   0   0   0 795   0   0   0]\n",
            " [  0   0   0   0   0   0   0   0 768   0   0]\n",
            " [  0   0   0   0   0   0   0   0   0 796   0]\n",
            " [  0   0   0   0   0   0  11   0   0 465 289]]\n",
            "Batch 16/237 - Batch Inference Time: 1.2900 seconds\n",
            "Testing Confusion Matrix:\n",
            " [[763   0   0   0   0   0   0   0   0   0   0]\n",
            " [  0 731  17   0   0   0   0   0   0   0   0]\n",
            " [  0  34 700   0   0   0   0   0   0   0   0]\n",
            " [  0   0   0 781   0   0   0   0   0   0   0]\n",
            " [  0   0   1   0   0 809   0   0   0   0   0]\n",
            " [  0   0   0   0   0 761   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0   0   0 780   0]\n",
            " [  0   0   0   0   0   0   0 844   0   0   0]\n",
            " [  0   0   0   0   0   0   0   0 819   0   0]\n",
            " [  0   0   0   0   0   0   0   0   0 849   0]\n",
            " [  0   0   0   0   0   0  12   0   0 492 311]]\n",
            "Batch 17/237 - Batch Inference Time: 1.5496 seconds\n",
            "Testing Confusion Matrix:\n",
            " [[811   0   0   0   0   0   0   0   0   0   0]\n",
            " [  0 769  18   0   0   0   0   0   0   0   0]\n",
            " [  0  35 743   0   0   0   0   0   0   0   0]\n",
            " [  0   0   0 832   0   0   0   0   0   0   0]\n",
            " [  0   0   1   0   0 855   0   0   0   0   0]\n",
            " [  0   0   0   0   0 812   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0   0   0 814   0]\n",
            " [  0   0   0   0   0   0   0 890   0   0   0]\n",
            " [  0   0   0   0   0   0   0   0 879   0   0]\n",
            " [  0   0   0   0   0   0   0   0   0 888   0]\n",
            " [  0   0   0   0   0   0  13   0   0 528 328]]\n",
            "Batch 18/237 - Batch Inference Time: 1.7138 seconds\n",
            "Testing Confusion Matrix:\n",
            " [[868   0   0   0   0   0   0   0   0   0   0]\n",
            " [  0 816  19   0   0   0   0   0   0   0   0]\n",
            " [  0  43 786   0   0   0   0   0   0   0   0]\n",
            " [  0   0   0 867   0   0   0   0   0   0   0]\n",
            " [  0   0   1   0   0 901   0   0   0   0   0]\n",
            " [  0   0   0   0   0 851   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0   0   0 858   0]\n",
            " [  0   0   0   0   0   0   0 937   0   0   0]\n",
            " [  0   0   0   0   0   0   0   0 928   0   0]\n",
            " [  0   0   0   0   0   0   0   0   0 936   0]\n",
            " [  0   0   0   0   0   0  15   0   0 561 341]]\n",
            "Batch 19/237 - Batch Inference Time: 1.7897 seconds\n",
            "Testing Confusion Matrix:\n",
            " [[911   0   0   0   0   0   0   0   0   0   0]\n",
            " [  0 870  21   0   0   0   0   0   0   0   0]\n",
            " [  0  48 817   0   0   0   0   0   0   0   0]\n",
            " [  0   0   0 924   0   0   0   0   0   0   0]\n",
            " [  0   0   1   0   0 954   0   0   0   0   0]\n",
            " [  0   0   0   0   0 896   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0   0   0 907   0]\n",
            " [  0   0   0   0   0   0   0 977   0   0   0]\n",
            " [  0   0   0   0   0   0   0   0 965   0   0]\n",
            " [  0   0   0   0   0   0   0   0   0 983   0]\n",
            " [  0   0   0   0   0   0  16   0   0 595 355]]\n",
            "Batch 20/237 - Batch Inference Time: 1.2988 seconds\n",
            "Testing Confusion Matrix:\n",
            " [[ 968    0    0    0    0    0    0    0    0    0    0]\n",
            " [   0  910   21    0    0    0    0    0    0    0    0]\n",
            " [   0   50  854    0    0    0    0    0    0    0    0]\n",
            " [   0    0    0  968    0    0    0    0    0    0    0]\n",
            " [   0    0    1    0    0  998    0    0    0    0    0]\n",
            " [   0    0    0    0    0  928    0    0    0    0    0]\n",
            " [   0    0    0    0    0    0    0    0    0  967    0]\n",
            " [   0    0    0    0    0    0    0 1030    0    0    0]\n",
            " [   0    0    0    0    0    0    0    0 1013    0    0]\n",
            " [   0    0    0    0    0    0    0    0    0 1037    0]\n",
            " [   0    0    0    0    0    0   16    0    0  622  369]]\n",
            "Batch 21/237 - Batch Inference Time: 1.3453 seconds\n",
            "Testing Confusion Matrix:\n",
            " [[1015    0    0    0    0    0    0    0    0    0    0]\n",
            " [   0  944   21    0    0    0    0    0    0    0    0]\n",
            " [   0   53  910    0    0    0    0    0    0    0    0]\n",
            " [   0    0    0 1014    0    0    0    0    0    0    0]\n",
            " [   0    0    1    0    0 1041    0    0    0    0    0]\n",
            " [   0    0    0    0    0  964    0    0    0    0    0]\n",
            " [   0    0    0    0    0    0    0    0    0 1020    0]\n",
            " [   0    0    0    0    0    0    0 1067    0    0    0]\n",
            " [   0    0    0    0    0    0    0    0 1066    0    0]\n",
            " [   0    0    0    0    0    0    0    0    0 1089    0]\n",
            " [   0    0    0    0    0    0   17    0    0  654  388]]\n",
            "Batch 22/237 - Batch Inference Time: 1.3362 seconds\n",
            "Testing Confusion Matrix:\n",
            " [[1059    0    0    0    0    0    0    0    0    0    0]\n",
            " [   0  989   24    0    0    0    0    0    0    0    0]\n",
            " [   0   55  958    0    0    0    0    0    0    0    0]\n",
            " [   0    0    0 1052    0    0    0    0    0    0    0]\n",
            " [   0    0    1    0    0 1088    0    0    0    0    0]\n",
            " [   0    0    0    0    0 1016    0    0    0    0    0]\n",
            " [   0    0    0    0    0    0    0    0    0 1068    0]\n",
            " [   0    0    0    0    0    0    0 1121    0    0    0]\n",
            " [   0    0    0    0    0    0    0    0 1106    0    0]\n",
            " [   0    0    0    0    0    0    0    0    0 1119    0]\n",
            " [   0    0    0    0    0    0   17    0    0  688  415]]\n",
            "Batch 23/237 - Batch Inference Time: 1.2796 seconds\n",
            "Testing Confusion Matrix:\n",
            " [[1095    0    0    0    0    0    0    0    0    0    0]\n",
            " [   0 1029   25    0    0    0    0    0    0    0    0]\n",
            " [   0   57 1001    0    0    0    0    0    0    0    0]\n",
            " [   0    0    0 1088    0    0    0    0    0    0    0]\n",
            " [   0    0    1    0    0 1129    0    0    0    0    0]\n",
            " [   0    0    0    0    0 1074    0    0    0    0    0]\n",
            " [   0    0    0    0    0    0    0    0    0 1123    0]\n",
            " [   0    0    0    0    0    0    0 1177    0    0    0]\n",
            " [   0    0    0    0    0    0    0    0 1162    0    0]\n",
            " [   0    0    0    0    0    0    0    0    0 1162    0]\n",
            " [   0    0    0    0    0    0   18    0    0  716  431]]\n",
            "Batch 24/237 - Batch Inference Time: 1.2498 seconds\n",
            "Testing Confusion Matrix:\n",
            " [[1142    0    0    0    0    0    0    0    0    0    0]\n",
            " [   0 1089   27    0    0    0    0    0    0    0    0]\n",
            " [   0   60 1052    0    0    0    0    0    0    0    0]\n",
            " [   0    0    0 1127    0    0    0    0    0    0    0]\n",
            " [   0    0    1    0    0 1164    0    0    0    0    0]\n",
            " [   0    0    0    0    0 1123    0    0    0    0    0]\n",
            " [   0    0    0    0    0    0    0    0    0 1159    0]\n",
            " [   0    0    0    0    0    0    0 1231    0    0    0]\n",
            " [   0    0    0    0    0    0    0    0 1210    0    0]\n",
            " [   0    0    0    0    0    0    0    0    0 1205    0]\n",
            " [   0    0    0    0    0    0   18    0    0  747  445]]\n",
            "Batch 25/237 - Batch Inference Time: 1.3216 seconds\n",
            "Testing Confusion Matrix:\n",
            " [[1180    0    0    0    0    0    0    0    0    0    0]\n",
            " [   0 1144   27    0    0    0    0    0    0    0    0]\n",
            " [   0   63 1090    0    0    0    0    0    0    0    0]\n",
            " [   0    0    0 1176    0    0    0    0    0    0    0]\n",
            " [   0    0    1    0    0 1219    0    0    0    0    0]\n",
            " [   0    0    0    0    0 1169    0    0    0    0    0]\n",
            " [   0    0    0    0    0    0    0    0    0 1205    0]\n",
            " [   0    0    0    0    0    0    0 1282    0    0    0]\n",
            " [   0    0    0    0    0    0    0    0 1252    0    0]\n",
            " [   0    0    0    0    0    0    0    0    0 1257    0]\n",
            " [   0    0    0    0    0    0   19    0    0  776  452]]\n",
            "Batch 26/237 - Batch Inference Time: 1.2317 seconds\n",
            "Testing Confusion Matrix:\n",
            " [[1213    0    0    0    0    0    0    0    0    0    0]\n",
            " [   0 1186   27    0    0    0    0    0    0    0    0]\n",
            " [   0   69 1137    1    0    0    0    0    0    0    0]\n",
            " [   0    0    0 1232    0    0    0    0    0    0    0]\n",
            " [   0    0    1    0    0 1277    0    0    0    0    0]\n",
            " [   0    0    0    0    0 1215    0    0    0    0    0]\n",
            " [   0    0    0    0    0    0    0    0    0 1243    0]\n",
            " [   0    0    0    0    0    0    0 1319    0    0    0]\n",
            " [   0    0    0    0    0    0    0    0 1297    0    0]\n",
            " [   0    0    0    0    0    0    0    0    0 1305    0]\n",
            " [   0    0    0    0    0    0   19    0    0  812  471]]\n",
            "Batch 27/237 - Batch Inference Time: 2.0567 seconds\n",
            "Testing Confusion Matrix:\n",
            " [[1252    0    0    0    0    0    0    0    0    0    0]\n",
            " [   0 1230   29    0    0    0    0    0    0    0    0]\n",
            " [   0   73 1169    1    0    0    0    0    0    0    0]\n",
            " [   0    0    0 1281    0    0    0    0    0    0    0]\n",
            " [   0    0    1    0    0 1325    0    0    0    0    0]\n",
            " [   0    0    0    0    0 1273    0    0    0    0    0]\n",
            " [   0    0    0    0    0    0    0    0    0 1296    0]\n",
            " [   0    0    0    0    0    0    0 1366    0    0    0]\n",
            " [   0    0    0    0    0    0    0    0 1342    0    0]\n",
            " [   0    0    0    0    0    0    0    0    0 1351    0]\n",
            " [   0    0    0    0    0    0   19    0    0  842  486]]\n",
            "Batch 28/237 - Batch Inference Time: 1.7027 seconds\n",
            "Testing Confusion Matrix:\n",
            " [[1291    0    0    0    0    0    0    0    0    0    0]\n",
            " [   0 1285   35    0    0    0    0    0    0    0    0]\n",
            " [   0   75 1212    1    0    0    0    0    0    0    0]\n",
            " [   0    0    0 1323    0    0    0    0    0    0    0]\n",
            " [   1    0    1    0    0 1375    0    0    0    0    0]\n",
            " [   0    0    0    0    0 1321    0    0    0    0    0]\n",
            " [   0    0    0    0    0    0    0    0    0 1343    0]\n",
            " [   0    0    0    0    0    0    0 1416    0    0    0]\n",
            " [   0    0    0    0    0    0    0    0 1380    0    0]\n",
            " [   0    0    0    0    0    0    0    0    0 1395    0]\n",
            " [   0    0    0    0    0    0   21    0    0  869  504]]\n",
            "Batch 29/237 - Batch Inference Time: 1.3055 seconds\n",
            "Testing Confusion Matrix:\n",
            " [[1336    0    0    0    0    0    0    0    0    0    0]\n",
            " [   0 1336   38    0    0    0    0    0    0    0    0]\n",
            " [   0   78 1261    1    0    0    0    0    0    0    0]\n",
            " [   0    0    0 1364    0    0    0    0    0    0    0]\n",
            " [   1    0    1    0    0 1426    0    0    0    0    0]\n",
            " [   0    0    0    0    0 1365    0    0    0    0    0]\n",
            " [   0    0    0    0    0    0    0    0    0 1394    0]\n",
            " [   0    0    0    0    0    0    0 1460    0    0    0]\n",
            " [   0    0    0    0    0    0    0    0 1430    0    0]\n",
            " [   0    0    0    0    0    0    0    0    0 1438    0]\n",
            " [   0    0    0    0    0    0   21    0    0  889  521]]\n",
            "Batch 30/237 - Batch Inference Time: 1.2467 seconds\n",
            "Testing Confusion Matrix:\n",
            " [[1391    0    0    0    0    0    0    0    0    0    0]\n",
            " [   0 1388   39    0    0    0    0    0    0    0    0]\n",
            " [   0   79 1295    1    0    0    0    0    0    0    0]\n",
            " [   0    0    0 1408    0    0    0    0    0    0    0]\n",
            " [   1    0    1    0    0 1467    0    0    0    0    0]\n",
            " [   0    0    0    0    0 1412    0    0    0    0    0]\n",
            " [   0    0    0    0    0    0    0    0    0 1444    0]\n",
            " [   0    0    0    0    0    0    0 1506    0    0    0]\n",
            " [   0    0    0    0    0    0    0    0 1476    0    0]\n",
            " [   0    0    0    0    0    0    0    0    0 1484    0]\n",
            " [   0    0    0    0    0    0   21    0    0  920  539]]\n",
            "Batch 31/237 - Batch Inference Time: 1.2744 seconds\n",
            "Testing Confusion Matrix:\n",
            " [[1438    0    0    0    0    0    0    0    0    0    0]\n",
            " [   0 1438   40    0    0    0    0    0    0    0    0]\n",
            " [   0   81 1335    1    0    0    0    0    0    0    0]\n",
            " [   0    0    0 1448    0    0    0    0    0    0    0]\n",
            " [   1    0    1    0    0 1518    0    0    0    0    0]\n",
            " [   0    0    0    0    0 1454    0    0    0    0    0]\n",
            " [   0    0    0    0    0    0    0    0    0 1484    0]\n",
            " [   0    0    0    0    0    0    0 1560    0    0    0]\n",
            " [   0    0    0    0    0    0    0    0 1529    0    0]\n",
            " [   0    0    0    0    0    0    0    0    0 1529    0]\n",
            " [   0    0    0    0    0    0   22    0    0  953  552]]\n",
            "Batch 32/237 - Batch Inference Time: 1.2666 seconds\n",
            "Testing Confusion Matrix:\n",
            " [[1481    0    0    0    0    0    0    0    0    0    0]\n",
            " [   0 1492   42    0    0    0    0    0    0    0    0]\n",
            " [   0   82 1376    1    0    0    0    0    0    0    0]\n",
            " [   0    0    0 1487    0    0    0    0    0    0    0]\n",
            " [   1    0    1    0    0 1556    0    0    0    0    0]\n",
            " [   0    0    0    0    0 1517    0    0    0    0    0]\n",
            " [   0    0    0    0    0    0    0    0    0 1529    0]\n",
            " [   0    0    0    0    0    0    0 1600    0    0    0]\n",
            " [   0    0    0    0    0    0    0    0 1578    0    0]\n",
            " [   0    0    0    0    0    0    0    0    0 1579    0]\n",
            " [   0    0    0    0    0    0   23    0    0  981  570]]\n",
            "Batch 33/237 - Batch Inference Time: 1.2430 seconds\n",
            "Testing Confusion Matrix:\n",
            " [[1520    0    0    0    0    0    0    0    0    0    0]\n",
            " [   0 1528   46    0    0    0    0    0    0    0    0]\n",
            " [   0   85 1409    1    0    0    0    0    0    0    0]\n",
            " [   0    0    0 1533    0    0    0    0    0    0    0]\n",
            " [   1    0    1    0    0 1603    0    0    0    0    0]\n",
            " [   0    0    0    0    0 1581    0    0    0    0    0]\n",
            " [   0    0    0    0    0    0    0    0    0 1578    0]\n",
            " [   0    0    0    0    0    0    0 1650    0    0    0]\n",
            " [   0    0    0    0    0    0    0    0 1624    0    0]\n",
            " [   0    0    0    0    0    0    0    0    0 1626    0]\n",
            " [   0    0    0    0    0    0   23    0    0 1010  589]]\n",
            "Batch 34/237 - Batch Inference Time: 1.2300 seconds\n",
            "Testing Confusion Matrix:\n",
            " [[1552    0    0    0    0    0    0    0    0    0    0]\n",
            " [   0 1577   48    0    0    0    0    0    0    0    0]\n",
            " [   0   92 1445    1    0    0    0    0    0    0    0]\n",
            " [   0    0    0 1586    0    0    0    0    0    0    0]\n",
            " [   1    0    1    0    0 1647    0    0    0    0    0]\n",
            " [   0    0    0    0    0 1630    0    0    0    0    0]\n",
            " [   0    0    0    0    0    0    0    0    0 1630    0]\n",
            " [   0    0    0    0    0    0    0 1692    0    0    0]\n",
            " [   0    0    0    0    0    0    0    0 1674    0    0]\n",
            " [   0    0    0    0    0    0    0    0    0 1678    0]\n",
            " [   0    0    0    0    0    0   23    0    0 1040  603]]\n",
            "Batch 35/237 - Batch Inference Time: 1.2544 seconds\n",
            "Testing Confusion Matrix:\n",
            " [[1593    0    0    0    0    0    0    0    0    0    0]\n",
            " [   0 1623   52    0    0    0    0    0    0    0    0]\n",
            " [   0   93 1490    1    0    0    0    0    0    0    0]\n",
            " [   0    0    0 1633    0    0    0    0    0    0    0]\n",
            " [   1    0    1    0    0 1697    0    0    0    0    0]\n",
            " [   0    0    0    0    0 1676    0    0    0    0    0]\n",
            " [   0    0    0    0    0    0    0    0    0 1687    0]\n",
            " [   0    0    0    0    0    0    0 1748    0    0    0]\n",
            " [   0    0    0    0    0    0    0    0 1714    0    0]\n",
            " [   0    0    0    0    0    0    0    0    0 1718    0]\n",
            " [   0    0    0    0    0    0   24    0    0 1064  617]]\n",
            "Batch 36/237 - Batch Inference Time: 1.3175 seconds\n",
            "Testing Confusion Matrix:\n",
            " [[1644    0    0    0    0    0    0    0    0    0    0]\n",
            " [   0 1671   54    0    0    0    0    0    0    0    0]\n",
            " [   0   98 1537    1    0    0    0    0    0    0    0]\n",
            " [   0    0    0 1674    0    0    0    0    0    0    0]\n",
            " [   1    0    1    0    0 1736    0    0    0    0    0]\n",
            " [   0    0    0    0    0 1721    0    0    0    0    0]\n",
            " [   0    0    0    0    0    0    0    0    0 1731    0]\n",
            " [   0    0    0    0    0    0    0 1795    0    0    0]\n",
            " [   0    0    0    0    0    0    0    0 1757    0    0]\n",
            " [   0    0    0    0    0    0    0    0    0 1772    0]\n",
            " [   0    0    0    0    0    0   24    0    0 1098  629]]\n",
            "Batch 37/237 - Batch Inference Time: 1.6856 seconds\n",
            "Testing Confusion Matrix:\n",
            " [[1677    0    0    0    0    0    0    0    0    0    0]\n",
            " [   0 1717   55    0    0    0    0    0    0    0    0]\n",
            " [   0  100 1581    1    0    0    0    0    0    0    0]\n",
            " [   0    0    0 1735    0    0    0    0    0    0    0]\n",
            " [   1    0    1    0    0 1787    0    0    0    0    0]\n",
            " [   0    0    0    0    0 1760    0    0    0    0    0]\n",
            " [   0    0    0    0    0    0    0    0    0 1778    0]\n",
            " [   0    0    0    0    0    0    0 1851    0    0    0]\n",
            " [   0    0    0    0    0    0    0    0 1792    0    0]\n",
            " [   0    0    0    0    0    0    0    0    0 1820    0]\n",
            " [   0    0    0    0    0    0   24    0    0 1119  657]]\n",
            "Batch 38/237 - Batch Inference Time: 1.7148 seconds\n",
            "Testing Confusion Matrix:\n",
            " [[1726    0    0    0    0    0    0    0    0    0    0]\n",
            " [   0 1771   56    0    0    0    0    0    0    0    0]\n",
            " [   0  101 1625    1    0    0    0    0    0    0    0]\n",
            " [   0    0    0 1778    0    0    0    0    0    0    0]\n",
            " [   1    0    1    0    0 1843    0    0    0    0    0]\n",
            " [   0    0    0    0    0 1807    0    0    0    0    0]\n",
            " [   0    0    0    0    0    0    0    0    0 1832    0]\n",
            " [   0    0    0    0    0    0    0 1890    0    0    0]\n",
            " [   0    0    0    0    0    0    0    0 1829    0    0]\n",
            " [   0    0    0    0    0    0    0    0    0 1863    0]\n",
            " [   0    0    0    0    0    0   25    0    0 1140  679]]\n",
            "Batch 39/237 - Batch Inference Time: 1.6745 seconds\n",
            "Testing Confusion Matrix:\n",
            " [[1768    0    0    0    0    0    0    0    0    0    0]\n",
            " [   0 1821   57    0    0    0    0    0    0    0    0]\n",
            " [   0  104 1675    1    0    0    0    0    0    0    0]\n",
            " [   0    0    0 1820    0    0    0    0    0    0    0]\n",
            " [   2    0    1    0    0 1886    0    0    0    0    0]\n",
            " [   0    0    0    0    0 1852    0    0    0    0    0]\n",
            " [   0    0    0    0    0    0    0    0    0 1878    0]\n",
            " [   0    0    0    0    0    0    0 1928    0    0    0]\n",
            " [   0    0    0    0    0    0    0    0 1876    0    0]\n",
            " [   0    0    0    0    0    0    0    0    0 1910    0]\n",
            " [   0    0    0    0    0    0   25    0    0 1171  705]]\n",
            "Batch 40/237 - Batch Inference Time: 1.2797 seconds\n",
            "Testing Confusion Matrix:\n",
            " [[1807    0    0    0    0    0    0    0    0    0    0]\n",
            " [   0 1865   58    0    0    0    0    0    0    0    0]\n",
            " [   0  105 1725    1    0    0    0    0    0    0    0]\n",
            " [   0    0    0 1882    0    0    0    0    0    0    0]\n",
            " [   2    0    1    0    0 1929    0    0    0    0    0]\n",
            " [   0    0    0    0    0 1895    0    0    0    0    0]\n",
            " [   0    0    0    0    0    0    0    0    0 1927    0]\n",
            " [   0    0    0    0    0    0    0 1974    0    0    0]\n",
            " [   0    0    0    0    0    0    0    0 1923    0    0]\n",
            " [   0    0    0    0    0    0    0    0    0 1950    0]\n",
            " [   0    0    0    0    0    0   25    0    0 1203  720]]\n",
            "Batch 41/237 - Batch Inference Time: 1.2703 seconds\n",
            "Testing Confusion Matrix:\n",
            " [[1859    0    0    0    0    0    0    0    0    0    0]\n",
            " [   0 1912   59    0    0    0    0    0    0    1    0]\n",
            " [   0  105 1763    1    0    0    0    0    0    0    0]\n",
            " [   0    0    0 1929    0    0    0    0    0    0    0]\n",
            " [   2    0    1    0    0 1994    0    0    0    0    0]\n",
            " [   0    0    0    0    0 1941    0    0    0    0    0]\n",
            " [   0    0    0    0    0    0    0    0    0 1970    0]\n",
            " [   0    0    0    0    0    0    0 2032    0    0    0]\n",
            " [   0    0    0    0    0    0    0    0 1965    0    0]\n",
            " [   0    0    0    0    0    0    0    0    0 1983    0]\n",
            " [   0    0    0    0    0    0   25    0    0 1228  734]]\n",
            "Batch 42/237 - Batch Inference Time: 1.2797 seconds\n",
            "Testing Confusion Matrix:\n",
            " [[1917    0    0    0    0    0    0    1    0    0    0]\n",
            " [   0 1959   61    0    0    0    0    0    0    1    0]\n",
            " [   0  109 1807    1    0    0    0    0    0    0    0]\n",
            " [   0    0    0 1970    0    0    0    0    0    0    0]\n",
            " [   3    0    1    0    0 2039    0    0    0    0    0]\n",
            " [   0    0    0    0    0 1982    0    0    0    0    0]\n",
            " [   0    0    0    0    0    0    0    0    0 2026    0]\n",
            " [   0    0    0    0    0    0    0 2082    0    0    0]\n",
            " [   0    0    0    0    0    0    0    0 2004    0    0]\n",
            " [   0    0    0    0    0    0    0    0    0 2032    0]\n",
            " [   0    0    0    0    0    0   25    0    0 1243  753]]\n",
            "Batch 43/237 - Batch Inference Time: 1.2936 seconds\n",
            "Testing Confusion Matrix:\n",
            " [[1961    0    0    0    0    0    0    1    0    0    0]\n",
            " [   0 2008   63    0    0    0    0    0    0    1    0]\n",
            " [   0  113 1848    1    0    0    0    0    0    0    0]\n",
            " [   0    0    0 2017    0    0    0    0    0    0    0]\n",
            " [   3    0    1    0    0 2096    0    0    0    0    0]\n",
            " [   0    0    0    0    0 2021    0    0    0    0    0]\n",
            " [   0    0    0    0    0    0    0    0    0 2071    0]\n",
            " [   0    0    0    0    0    0    0 2139    0    0    0]\n",
            " [   0    0    0    0    0    0    0    0 2046    0    0]\n",
            " [   0    0    0    0    0    0    0    0    0 2079    0]\n",
            " [   0    0    0    0    0    0   25    0    0 1268  766]]\n",
            "Batch 44/237 - Batch Inference Time: 1.2759 seconds\n",
            "Testing Confusion Matrix:\n",
            " [[2019    0    0    0    0    0    0    1    0    0    0]\n",
            " [   0 2047   65    0    0    0    0    0    0    1    0]\n",
            " [   0  115 1890    1    0    0    0    0    0    0    0]\n",
            " [   0    0    0 2058    0    0    0    0    0    0    0]\n",
            " [   3    0    1    0    0 2148    0    0    0    0    0]\n",
            " [   0    0    0    0    0 2070    0    0    0    0    0]\n",
            " [   0    0    0    0    0    0    0    0    0 2118    0]\n",
            " [   0    0    0    0    0    0    0 2186    0    0    0]\n",
            " [   0    0    0    0    0    0    0    0 2092    0    0]\n",
            " [   0    0    0    0    0    0    0    0    0 2123    0]\n",
            " [   0    0    0    0    0    0   26    0    0 1295  781]]\n",
            "Batch 45/237 - Batch Inference Time: 1.2474 seconds\n",
            "Testing Confusion Matrix:\n",
            " [[2081    0    0    0    0    0    0    1    0    0    0]\n",
            " [   0 2085   67    0    0    0    0    0    0    1    0]\n",
            " [   0  119 1928    1    0    0    0    0    0    0    0]\n",
            " [   0    0    0 2105    0    0    0    0    0    0    0]\n",
            " [   3    0    1    0    0 2195    0    0    0    0    0]\n",
            " [   0    0    0    0    0 2108    0    0    0    0    0]\n",
            " [   0    0    0    0    0    0    0    0    0 2158    0]\n",
            " [   0    0    0    0    0    0    0 2235    0    0    0]\n",
            " [   0    0    0    0    0    0    0    0 2134    0    0]\n",
            " [   0    0    0    0    0    0    0    0    0 2178    0]\n",
            " [   0    0    0    0    0    0   26    0    0 1326  800]]\n",
            "Batch 46/237 - Batch Inference Time: 1.3343 seconds\n",
            "Testing Confusion Matrix:\n",
            " [[2140    0    0    0    0    0    0    1    0    0    0]\n",
            " [   0 2122   70    0    0    0    0    0    0    1    0]\n",
            " [   0  121 1969    1    0    0    0    0    0    0    0]\n",
            " [   0    0    0 2138    0    0    0    0    0    0    0]\n",
            " [   3    0    1    0    0 2251    0    0    0    0    0]\n",
            " [   0    0    0    0    0 2166    0    0    0    0    0]\n",
            " [   0    0    0    0    0    0    0    0    0 2203    0]\n",
            " [   0    0    0    0    0    0    0 2279    0    0    0]\n",
            " [   0    0    0    0    0    0    0    0 2170    0    0]\n",
            " [   0    0    0    0    0    0    0    0    0 2219    0]\n",
            " [   0    0    0    0    0    0   26    0    0 1360  823]]\n",
            "Batch 47/237 - Batch Inference Time: 1.7060 seconds\n",
            "Testing Confusion Matrix:\n",
            " [[2188    0    0    0    0    0    0    1    0    0    0]\n",
            " [   0 2173   71    0    0    0    0    0    0    1    0]\n",
            " [   0  124 2011    1    0    0    0    0    0    0    0]\n",
            " [   0    0    0 2185    0    0    0    0    0    0    0]\n",
            " [   4    0    1    0    0 2295    0    0    0    0    0]\n",
            " [   1    0    0    0    0 2209    0    0    0    0    0]\n",
            " [   0    0    0    0    0    0    0    0    0 2245    0]\n",
            " [   0    0    0    0    0    0    0 2327    0    0    0]\n",
            " [   0    0    0    0    0    0    0    0 2221    0    0]\n",
            " [   0    0    0    0    0    0    0    0    0 2259    0]\n",
            " [   0    0    0    0    0    0   28    0    0 1394  837]]\n",
            "Batch 48/237 - Batch Inference Time: 1.7044 seconds\n",
            "Testing Confusion Matrix:\n",
            " [[2237    0    0    0    0    0    0    1    0    0    0]\n",
            " [   0 2216   71    0    0    0    0    0    0    1    0]\n",
            " [   0  126 2066    1    0    0    0    0    0    0    0]\n",
            " [   0    0    0 2224    0    0    0    0    0    0    0]\n",
            " [   4    0    1    0    0 2339    0    0    0    0    0]\n",
            " [   1    0    0    0    0 2256    0    0    0    0    0]\n",
            " [   0    0    0    0    0    0    0    0    0 2300    0]\n",
            " [   0    0    0    0    0    0    0 2365    0    0    0]\n",
            " [   0    0    0    0    0    0    0    0 2269    0    0]\n",
            " [   0    0    0    0    0    0    0    0    0 2304    0]\n",
            " [   0    0    0    0    0    0   29    0    0 1426  851]]\n",
            "Batch 49/237 - Batch Inference Time: 1.3887 seconds\n",
            "Testing Confusion Matrix:\n",
            " [[2280    0    0    0    0    0    0    1    0    0    0]\n",
            " [   0 2266   71    0    0    0    0    0    0    1    0]\n",
            " [   0  128 2101    1    0    0    0    0    0    0    0]\n",
            " [   0    0    0 2274    0    0    0    0    0    0    0]\n",
            " [   4    0    1    0    0 2396    0    0    0    0    0]\n",
            " [   1    0    0    0    0 2296    0    0    0    0    0]\n",
            " [   0    0    0    0    0    0    0    0    0 2343    0]\n",
            " [   0    0    0    0    0    0    0 2405    0    0    0]\n",
            " [   0    0    0    0    0    0    0    0 2320    0    0]\n",
            " [   0    0    0    0    0    0    0    0    0 2364    0]\n",
            " [   0    0    0    0    0    0   30    0    0 1447  870]]\n",
            "Batch 50/237 - Batch Inference Time: 1.5742 seconds\n",
            "Testing Confusion Matrix:\n",
            " [[2332    0    0    0    0    0    0    1    0    0    0]\n",
            " [   0 2308   73    0    0    0    0    0    0    1    0]\n",
            " [   0  131 2146    1    0    0    0    0    0    0    0]\n",
            " [   0    0    0 2316    0    0    0    0    0    0    0]\n",
            " [   4    0    1    0    0 2446    0    0    0    0    0]\n",
            " [   1    0    0    0    0 2340    0    0    0    0    0]\n",
            " [   0    0    0    0    0    0    0    0    0 2394    0]\n",
            " [   0    0    0    0    0    0    0 2457    0    0    0]\n",
            " [   0    0    0    0    0    0    0    0 2365    0    0]\n",
            " [   0    0    0    0    0    0    0    0    0 2404    0]\n",
            " [   0    0    0    0    0    0   31    0    0 1467  893]]\n",
            "Batch 51/237 - Batch Inference Time: 1.2570 seconds\n",
            "Testing Confusion Matrix:\n",
            " [[2373    0    0    0    0    0    0    1    0    0    0]\n",
            " [   0 2350   74    0    0    0    0    0    0    1    0]\n",
            " [   0  132 2189    1    0    0    0    0    0    0    0]\n",
            " [   0    0    0 2361    0    0    0    0    0    0    0]\n",
            " [   4    0    1    0    0 2496    0    0    0    0    0]\n",
            " [   1    0    0    0    0 2386    0    0    0    0    0]\n",
            " [   0    0    0    0    0    0    0    0    0 2443    0]\n",
            " [   0    0    0    0    0    0    0 2499    0    0    0]\n",
            " [   0    0    0    0    0    0    0    0 2409    0    0]\n",
            " [   0    0    0    0    0    0    0    0    0 2464    0]\n",
            " [   0    0    0    0    0    0   31    0    0 1496  912]]\n",
            "Batch 52/237 - Batch Inference Time: 1.3012 seconds\n",
            "Testing Confusion Matrix:\n",
            " [[2425    0    0    0    0    0    0    1    0    0    0]\n",
            " [   0 2392   75    0    0    0    0    0    0    1    0]\n",
            " [   0  140 2232    1    0    0    0    0    0    0    0]\n",
            " [   0    0    0 2406    0    0    0    0    0    0    0]\n",
            " [   4    0    1    0    0 2540    0    0    0    0    0]\n",
            " [   1    0    0    0    0 2423    0    0    0    0    0]\n",
            " [   0    0    0    0    0    0    0    0    0 2498    0]\n",
            " [   0    0    0    0    0    0    0 2550    0    0    0]\n",
            " [   0    0    0    0    0    0    0    0 2455    0    0]\n",
            " [   0    0    0    0    0    0    0    0    0 2505    0]\n",
            " [   0    0    0    0    0    0   31    0    0 1523  932]]\n",
            "Batch 53/237 - Batch Inference Time: 1.2940 seconds\n",
            "Testing Confusion Matrix:\n",
            " [[2466    0    0    0    0    0    0    1    0    0    0]\n",
            " [   0 2445   75    0    0    0    0    0    0    1    0]\n",
            " [   0  140 2263    1    0    0    0    0    0    0    0]\n",
            " [   0    0    0 2452    0    0    0    0    0    0    0]\n",
            " [   4    0    1    0    0 2593    0    0    0    0    0]\n",
            " [   1    0    0    0    0 2459    0    0    0    0    0]\n",
            " [   0    0    0    0    0    0    0    0    0 2546    0]\n",
            " [   0    0    0    0    0    0    0 2603    0    0    0]\n",
            " [   0    0    0    0    0    0    0    0 2502    0    0]\n",
            " [   0    0    0    0    0    0    0    0    0 2549    0]\n",
            " [   0    0    0    0    0    0   32    0    0 1554  960]]\n",
            "Batch 54/237 - Batch Inference Time: 1.2688 seconds\n",
            "Testing Confusion Matrix:\n",
            " [[2500    0    0    0    0    1    0    1    0    0    0]\n",
            " [   0 2499   75    1    0    0    0    0    0    1    0]\n",
            " [   0  140 2308    1    0    0    0    0    0    0    0]\n",
            " [   0    0    0 2487    0    0    0    0    0    0    0]\n",
            " [   4    0    1    0    0 2647    0    0    0    0    0]\n",
            " [   1    0    0    0    0 2506    0    0    0    0    0]\n",
            " [   0    0    0    0    0    0    0    0    0 2602    0]\n",
            " [   0    0    0    0    0    0    0 2653    0    0    0]\n",
            " [   0    0    0    0    0    0    0    0 2548    0    0]\n",
            " [   0    0    0    0    0    0    0    0    0 2586    0]\n",
            " [   0    0    0    0    0    0   32    0    0 1584  982]]\n",
            "Batch 55/237 - Batch Inference Time: 1.3153 seconds\n",
            "Testing Confusion Matrix:\n",
            " [[2552    0    0    0    0    1    0    1    0    0    0]\n",
            " [   0 2541   78    1    0    0    0    0    0    1    0]\n",
            " [   0  145 2339    1    0    0    0    0    0    0    0]\n",
            " [   0    0    0 2530    0    0    0    0    0    0    0]\n",
            " [   4    0    1    0    0 2699    0    0    0    0    0]\n",
            " [   1    0    0    0    0 2550    0    0    0    0    0]\n",
            " [   0    0    0    0    0    0    0    0    0 2653    0]\n",
            " [   0    0    0    0    0    0    0 2699    0    0    0]\n",
            " [   0    0    0    0    0    0    0    0 2601    0    0]\n",
            " [   0    0    0    0    0    0    0    0    0 2627    0]\n",
            " [   0    0    0    0    0    0   32    0    0 1616  999]]\n",
            "Batch 56/237 - Batch Inference Time: 1.4588 seconds\n",
            "Testing Confusion Matrix:\n",
            " [[2589    0    0    0    0    1    0    1    0    0    0]\n",
            " [   0 2596   81    1    0    0    0    0    0    1    0]\n",
            " [   0  151 2380    1    0    0    0    0    0    0    0]\n",
            " [   0    0    0 2580    0    0    0    0    0    0    0]\n",
            " [   4    0    1    0    0 2750    0    0    0    0    0]\n",
            " [   1    0    0    0    0 2591    0    0    0    0    0]\n",
            " [   0    0    0    0    0    0    0    0    0 2708    0]\n",
            " [   0    0    0    0    0    0    0 2747    0    0    0]\n",
            " [   0    0    0    0    0    0    0    0 2650    0    0]\n",
            " [   0    0    0    0    0    0    0    0    0 2662    0]\n",
            " [   0    0    0    0    0    0   33    0    0 1642 1013]]\n",
            "Batch 57/237 - Batch Inference Time: 1.7318 seconds\n",
            "Testing Confusion Matrix:\n",
            " [[2641    0    0    0    0    1    0    1    0    0    0]\n",
            " [   0 2641   81    1    0    0    0    0    0    1    0]\n",
            " [   0  151 2427    1    0    0    0    0    0    0    0]\n",
            " [   0    0    0 2631    0    0    0    0    0    0    0]\n",
            " [   4    0    1    0    0 2799    0    0    0    0    0]\n",
            " [   1    0    0    0    0 2649    0    0    0    0    0]\n",
            " [   0    0    0    0    0    0    0    0    0 2743    0]\n",
            " [   0    0    0    0    0    0    0 2785    0    0    0]\n",
            " [   0    0    0    0    0    0    0    0 2696    0    0]\n",
            " [   0    0    0    0    0    0    0    0    0 2715    0]\n",
            " [   0    0    0    0    0    0   34    0    0 1667 1025]]\n",
            "Batch 58/237 - Batch Inference Time: 1.8536 seconds\n",
            "Testing Confusion Matrix:\n",
            " [[2688    0    0    0    0    1    0    1    0    0    0]\n",
            " [   0 2685   84    1    0    0    0    0    0    1    0]\n",
            " [   0  155 2469    1    0    0    0    0    0    0    0]\n",
            " [   0    0    0 2681    0    0    0    0    0    0    0]\n",
            " [   4    0    1    0    0 2847    0    0    0    0    0]\n",
            " [   1    0    0    0    0 2700    0    0    0    0    0]\n",
            " [   0    0    0    0    0    0    0    0    0 2796    0]\n",
            " [   0    0    0    0    0    0    0 2822    0    0    0]\n",
            " [   0    0    0    0    0    0    0    0 2744    0    0]\n",
            " [   0    0    0    0    0    0    0    0    0 2754    0]\n",
            " [   0    0    0    0    0    0   35    0    0 1692 1045]]\n",
            "Batch 59/237 - Batch Inference Time: 1.3361 seconds\n",
            "Testing Confusion Matrix:\n",
            " [[2745    0    0    0    0    1    0    1    0    0    0]\n",
            " [   0 2727   85    1    0    0    0    0    0    1    0]\n",
            " [   0  158 2506    1    0    0    0    0    0    0    0]\n",
            " [   0    0    0 2733    0    0    0    0    0    0    0]\n",
            " [   5    0    1    0    0 2893    0    0    0    0    0]\n",
            " [   1    0    0    0    0 2750    0    0    0    0    0]\n",
            " [   0    0    0    0    0    0    0    0    0 2834    0]\n",
            " [   0    0    0    0    0    0    0 2876    0    0    0]\n",
            " [   0    0    0    0    0    0    0    0 2802    0    0]\n",
            " [   0    0    0    0    0    0    0    0    0 2790    0]\n",
            " [   0    0    0    0    0    0   35    0    0 1709 1065]]\n",
            "Batch 60/237 - Batch Inference Time: 1.3626 seconds\n",
            "Testing Confusion Matrix:\n",
            " [[2799    0    0    0    0    1    0    1    0    0    0]\n",
            " [   0 2766   85    1    0    0    0    0    0    1    0]\n",
            " [   0  162 2546    1    0    0    0    0    0    0    0]\n",
            " [   0    0    0 2773    0    0    0    0    0    0    0]\n",
            " [   5    0    1    0    0 2935    0    0    0    0    0]\n",
            " [   1    0    0    0    0 2793    0    0    0    0    0]\n",
            " [   0    0    0    0    0    0    0    0    0 2879    0]\n",
            " [   0    0    0    0    0    0    0 2940    0    0    0]\n",
            " [   0    0    0    0    0    0    0    0 2856    0    0]\n",
            " [   0    0    0    0    0    0    0    0    0 2832    0]\n",
            " [   0    0    0    0    0    0   35    0    0 1735 1084]]\n",
            "Batch 61/237 - Batch Inference Time: 1.2868 seconds\n",
            "Testing Confusion Matrix:\n",
            " [[2838    0    0    0    0    1    0    1    0    0    0]\n",
            " [   0 2817   87    1    0    0    0    0    0    1    0]\n",
            " [   0  165 2585    1    0    0    0    0    0    0    0]\n",
            " [   0    0    0 2828    0    0    0    0    0    0    0]\n",
            " [   5    0    1    0    0 2979    0    0    0    0    0]\n",
            " [   1    0    0    0    0 2839    0    0    0    0    0]\n",
            " [   0    0    0    0    0    0    0    0    0 2922    0]\n",
            " [   0    0    0    0    0    0    0 2987    0    0    0]\n",
            " [   0    0    0    0    0    0    0    0 2901    0    0]\n",
            " [   0    0    0    0    0    0    0    0    0 2882    0]\n",
            " [   0    0    0    0    0    0   35    0    0 1767 1100]]\n",
            "Batch 62/237 - Batch Inference Time: 1.3176 seconds\n",
            "Testing Confusion Matrix:\n",
            " [[2889    0    0    0    0    1    0    1    0    0    0]\n",
            " [   0 2860   89    1    0    0    0    0    0    1    0]\n",
            " [   0  166 2629    1    0    0    0    0    0    0    0]\n",
            " [   0    0    0 2883    0    0    0    0    0    0    0]\n",
            " [   5    0    1    0    0 3008    0    0    0    0    0]\n",
            " [   2    0    0    0    0 2884    0    0    0    0    0]\n",
            " [   0    0    0    0    0    0    0    0    0 2971    0]\n",
            " [   0    0    0    0    0    0    0 3036    0    0    0]\n",
            " [   0    0    0    0    0    0    0    0 2952    0    0]\n",
            " [   0    0    0    0    0    0    0    0    0 2929    0]\n",
            " [   0    0    0    0    0    0   38    0    0 1789 1120]]\n",
            "Batch 63/237 - Batch Inference Time: 1.2933 seconds\n",
            "Testing Confusion Matrix:\n",
            " [[2940    0    0    0    0    1    0    1    0    0    0]\n",
            " [   0 2898   90    1    0    0    0    0    0    1    0]\n",
            " [   0  170 2668    1    0    0    0    0    0    0    0]\n",
            " [   0    0    0 2927    0    0    0    0    0    0    0]\n",
            " [   5    0    1    0    0 3050    0    0    0    0    0]\n",
            " [   2    0    0    0    0 2942    0    0    0    0    0]\n",
            " [   0    0    0    0    0    0    0    0    0 3024    0]\n",
            " [   0    0    0    0    0    0    0 3073    0    0    0]\n",
            " [   0    0    0    0    0    0    0    0 3001    0    0]\n",
            " [   0    0    0    0    0    0    0    0    0 2979    0]\n",
            " [   0    0    0    0    0    0   39    0    0 1813 1141]]\n",
            "Batch 64/237 - Batch Inference Time: 1.3526 seconds\n",
            "Testing Confusion Matrix:\n",
            " [[2991    0    0    0    0    1    0    1    0    0    0]\n",
            " [   0 2936   92    1    0    0    0    0    0    1    0]\n",
            " [   0  170 2720    1    0    0    0    0    0    0    0]\n",
            " [   0    0    0 2967    0    0    0    0    0    0    0]\n",
            " [   5    0    1    0    0 3099    0    0    0    0    0]\n",
            " [   2    0    0    0    0 2982    0    0    0    0    0]\n",
            " [   0    0    0    0    0    0    0    0    0 3054    0]\n",
            " [   0    0    0    0    0    0    0 3121    0    0    0]\n",
            " [   0    0    0    0    0    0    0    0 3058    0    0]\n",
            " [   0    0    0    0    0    0    0    0    0 3038    0]\n",
            " [   0    0    0    0    0    0   39    0    0 1839 1161]]\n",
            "Batch 65/237 - Batch Inference Time: 1.2768 seconds\n",
            "Testing Confusion Matrix:\n",
            " [[3043    0    0    0    0    1    0    1    0    0    0]\n",
            " [   0 2964   95    1    0    0    0    0    0    1    0]\n",
            " [   0  172 2755    1    0    0    0    0    0    0    0]\n",
            " [   0    0    0 3016    0    0    0    0    0    0    0]\n",
            " [   5    0    1    0    0 3152    0    0    0    0    0]\n",
            " [   3    0    0    0    0 3016    0    0    0    0    0]\n",
            " [   0    0    0    0    0    0    0    0    0 3101    0]\n",
            " [   0    0    0    0    0    0    0 3175    0    0    0]\n",
            " [   0    0    0    0    0    0    0    0 3107    0    0]\n",
            " [   0    0    0    0    0    0    0    0    0 3096    0]\n",
            " [   0    0    0    0    0    0   40    0    0 1873 1173]]\n",
            "Batch 66/237 - Batch Inference Time: 2.0100 seconds\n",
            "Testing Confusion Matrix:\n",
            " [[3086    0    0    0    0    1    0    1    0    0    0]\n",
            " [   0 3023   96    1    0    0    0    0    0    1    0]\n",
            " [   0  174 2796    1    0    0    0    0    0    0    0]\n",
            " [   0    0    0 3057    0    0    0    0    0    0    0]\n",
            " [   5    0    1    0    0 3194    0    0    0    0    0]\n",
            " [   3    0    0    0    0 3066    0    0    0    0    0]\n",
            " [   0    0    0    0    0    0    1    0    0 3142    0]\n",
            " [   1    0    0    0    0    0    0 3218    0    0    0]\n",
            " [   0    0    0    0    0    0    0    0 3162    0    0]\n",
            " [   0    0    0    0    0    0    0    0    0 3139    0]\n",
            " [   0    0    0    0    0    0   40    0    0 1907 1188]]\n",
            "Batch 67/237 - Batch Inference Time: 1.7546 seconds\n",
            "Testing Confusion Matrix:\n",
            " [[3120    0    0    0    0    1    0    1    0    0    0]\n",
            " [   0 3067   99    1    0    0    0    0    0    1    0]\n",
            " [   0  178 2848    1    0    0    0    0    0    0    0]\n",
            " [   0    0    0 3103    0    0    0    0    0    0    0]\n",
            " [   5    0    1    0    0 3241    0    0    0    0    0]\n",
            " [   3    0    0    0    0 3119    0    0    0    0    0]\n",
            " [   0    0    0    0    0    0    2    0    0 3196    0]\n",
            " [   1    0    0    0    0    0    0 3274    0    0    0]\n",
            " [   0    0    0    0    0    0    0    0 3201    0    0]\n",
            " [   0    0    0    0    0    0    0    0    0 3173    0]\n",
            " [   0    0    0    0    0    0   40    0    0 1934 1206]]\n",
            "Batch 68/237 - Batch Inference Time: 1.5315 seconds\n",
            "Testing Confusion Matrix:\n",
            " [[3161    0    0    0    0    1    0    2    0    0    0]\n",
            " [   0 3114  101    1    0    0    0    0    0    1    0]\n",
            " [   0  178 2890    1    0    0    0    0    0    0    0]\n",
            " [   0    0    0 3159    0    0    0    0    0    0    0]\n",
            " [   5    0    1    0    0 3284    0    0    0    0    0]\n",
            " [   3    0    0    0    0 3168    0    0    0    0    0]\n",
            " [   0    0    0    0    0    0    2    0    0 3245    0]\n",
            " [   1    0    0    0    0    0    0 3327    0    0    0]\n",
            " [   0    0    0    0    0    0    0    0 3244    0    0]\n",
            " [   0    0    0    0    0    0    0    0    0 3218    0]\n",
            " [   0    0    0    0    0    0   42    0    0 1955 1224]]\n",
            "Batch 69/237 - Batch Inference Time: 1.2667 seconds\n",
            "Testing Confusion Matrix:\n",
            " [[3196    0    0    0    0    1    0    2    0    0    0]\n",
            " [   0 3161  104    1    0    0    0    0    0    1    0]\n",
            " [   0  181 2934    1    0    0    0    0    0    0    0]\n",
            " [   0    0    0 3206    0    0    0    0    0    0    0]\n",
            " [   5    0    1    0    0 3336    0    0    0    0    0]\n",
            " [   3    0    0    0    0 3209    0    0    0    0    0]\n",
            " [   0    0    0    0    0    0    2    0    0 3294    0]\n",
            " [   1    0    0    0    0    0    0 3377    0    0    0]\n",
            " [   0    0    0    0    0    0    0    0 3291    0    0]\n",
            " [   0    0    0    0    0    0    0    0    0 3268    0]\n",
            " [   0    0    0    0    0    0   44    0    0 1985 1236]]\n",
            "Batch 70/237 - Batch Inference Time: 1.9349 seconds\n",
            "Testing Confusion Matrix:\n",
            " [[3232    0    0    0    0    1    0    2    0    0    0]\n",
            " [   0 3210  105    1    0    0    0    0    0    1    0]\n",
            " [   0  185 2973    1    0    0    0    0    0    0    0]\n",
            " [   0    0    0 3259    0    0    0    0    0    0    0]\n",
            " [   5    0    1    0    0 3374    0    0    0    0    0]\n",
            " [   3    0    0    0    0 3262    0    0    0    0    0]\n",
            " [   0    0    0    0    0    0    2    0    0 3348    0]\n",
            " [   1    0    0    0    0    0    0 3415    0    0    0]\n",
            " [   0    0    0    0    0    0    0    0 3342    0    0]\n",
            " [   0    0    0    0    0    0    0    0    0 3319    0]\n",
            " [   0    0    0    0    0    0   44    0    0 2015 1251]]\n",
            "Batch 71/237 - Batch Inference Time: 2.3178 seconds\n",
            "Testing Confusion Matrix:\n",
            " [[3282    0    0    0    0    1    0    2    0    0    0]\n",
            " [   0 3258  105    1    0    0    0    0    0    1    0]\n",
            " [   0  189 3017    1    0    0    0    0    0    0    0]\n",
            " [   0    0    0 3302    0    0    0    0    0    0    0]\n",
            " [   5    0    1    0    0 3416    0    0    0    0    0]\n",
            " [   3    0    0    0    0 3307    0    0    0    0    0]\n",
            " [   0    0    0    0    0    0    2    0    0 3400    0]\n",
            " [   1    0    0    0    0    0    0 3463    0    0    0]\n",
            " [   0    0    0    0    0    0    0    0 3388    0    0]\n",
            " [   0    0    0    0    0    0    0    0    0 3366    0]\n",
            " [   0    0    0    0    0    0   44    0    0 2035 1274]]\n",
            "Batch 72/237 - Batch Inference Time: 2.3549 seconds\n",
            "Testing Confusion Matrix:\n",
            " [[3335    0    0    0    0    1    0    2    0    0    0]\n",
            " [   0 3299  106    1    0    0    0    0    0    1    0]\n",
            " [   0  189 3058    1    0    0    0    0    0    0    0]\n",
            " [   0    0    0 3357    0    0    0    0    0    0    0]\n",
            " [   5    0    1    0    0 3465    0    0    0    0    0]\n",
            " [   3    0    0    0    0 3350    0    0    0    0    0]\n",
            " [   0    0    0    0    0    0    2    0    0 3442    0]\n",
            " [   1    0    0    0    0    0    0 3514    0    0    0]\n",
            " [   0    0    0    0    0    0    0    0 3430    0    0]\n",
            " [   0    0    0    0    0    0    0    0    0 3399    0]\n",
            " [   0    0    0    0    0    0   44    0    0 2068 1302]]\n",
            "Batch 73/237 - Batch Inference Time: 1.4774 seconds\n",
            "Testing Confusion Matrix:\n",
            " [[3378    0    0    0    0    1    0    2    0    0    0]\n",
            " [   0 3339  108    1    0    0    0    0    0    1    0]\n",
            " [   0  191 3107    1    0    0    0    0    0    0    0]\n",
            " [   0    0    0 3395    0    0    0    0    0    0    0]\n",
            " [   5    0    1    0    0 3537    0    0    0    0    0]\n",
            " [   3    0    0    0    0 3391    0    0    0    0    0]\n",
            " [   0    0    0    0    0    0    2    0    0 3486    0]\n",
            " [   1    0    0    0    0    0    0 3567    0    0    0]\n",
            " [   0    0    0    0    0    0    0    0 3470    0    0]\n",
            " [   0    0    0    0    0    0    0    0    0 3443    0]\n",
            " [   0    0    0    0    0    0   47    0    0 2093 1318]]\n",
            "Batch 74/237 - Batch Inference Time: 1.7113 seconds\n",
            "Testing Confusion Matrix:\n",
            " [[3421    0    0    0    0    1    0    2    0    0    0]\n",
            " [   0 3381  111    1    0    0    0    0    0    1    0]\n",
            " [   0  193 3147    1    0    0    0    0    0    0    0]\n",
            " [   0    0    0 3444    0    0    0    0    0    0    0]\n",
            " [   5    0    1    0    0 3580    0    0    0    0    0]\n",
            " [   3    0    0    0    0 3435    0    0    0    0    0]\n",
            " [   0    0    0    0    0    0    2    0    0 3538    0]\n",
            " [   1    0    0    0    0    0    0 3612    0    0    0]\n",
            " [   0    0    0    0    0    0    0    0 3526    0    0]\n",
            " [   0    0    0    0    0    0    0    0    0 3484    0]\n",
            " [   0    0    0    0    0    0   49    0    0 2126 1335]]\n",
            "Batch 75/237 - Batch Inference Time: 1.9332 seconds\n",
            "Testing Confusion Matrix:\n",
            " [[3470    0    0    0    0    1    0    2    0    0    0]\n",
            " [   0 3426  111    1    0    0    0    0    0    1    0]\n",
            " [   0  193 3190    1    0    0    0    0    0    0    0]\n",
            " [   0    0    0 3484    0    0    0    0    0    0    0]\n",
            " [   5    0    1    0    0 3623    0    0    0    0    0]\n",
            " [   3    0    0    0    0 3488    0    0    0    0    0]\n",
            " [   0    0    0    0    0    0    2    0    0 3578    0]\n",
            " [   1    0    0    0    0    0    0 3662    0    0    0]\n",
            " [   0    0    0    0    0    0    0    0 3571    0    0]\n",
            " [   0    0    0    0    0    0    0    0    0 3540    0]\n",
            " [   0    0    0    0    0    0   50    0    0 2155 1353]]\n",
            "Batch 76/237 - Batch Inference Time: 1.3295 seconds\n",
            "Testing Confusion Matrix:\n",
            " [[3517    0    0    0    0    1    0    2    0    0    0]\n",
            " [   0 3492  113    1    0    0    0    0    0    1    0]\n",
            " [   0  197 3216    1    0    0    0    0    0    0    0]\n",
            " [   0    0    0 3526    0    0    0    0    0    0    0]\n",
            " [   5    0    1    0    0 3676    0    0    0    0    0]\n",
            " [   3    0    0    0    0 3530    0    0    0    0    0]\n",
            " [   0    0    0    0    0    0    2    0    0 3640    0]\n",
            " [   1    0    0    0    0    0    0 3703    0    0    0]\n",
            " [   0    0    0    0    0    0    0    0 3618    0    0]\n",
            " [   0    0    0    0    0    0    0    0    0 3581    0]\n",
            " [   0    0    0    0    0    0   50    0    0 2179 1368]]\n",
            "Batch 77/237 - Batch Inference Time: 1.3253 seconds\n",
            "Testing Confusion Matrix:\n",
            " [[3551    0    0    0    0    1    0    2    0    0    0]\n",
            " [   0 3534  115    1    0    0    0    0    0    1    0]\n",
            " [   0  200 3267    1    0    0    0    0    0    0    0]\n",
            " [   0    0    0 3573    0    0    0    0    0    0    0]\n",
            " [   5    0    1    0    0 3720    0    0    0    0    0]\n",
            " [   3    0    0    0    0 3583    0    0    0    0    0]\n",
            " [   0    0    0    0    0    0    2    0    0 3701    0]\n",
            " [   1    0    0    0    0    0    0 3750    0    0    0]\n",
            " [   0    0    0    0    0    0    0    0 3661    0    0]\n",
            " [   0    0    0    0    0    0    0    0    0 3631    0]\n",
            " [   0    0    0    0    0    0   50    0    0 2201 1381]]\n",
            "Batch 78/237 - Batch Inference Time: 1.2685 seconds\n",
            "Testing Confusion Matrix:\n",
            " [[3597    0    0    0    0    1    0    2    0    0    0]\n",
            " [   0 3570  115    1    0    0    0    0    0    1    0]\n",
            " [   0  202 3311    1    0    0    0    0    0    0    0]\n",
            " [   0    0    0 3618    0    0    0    0    0    0    0]\n",
            " [   5    0    1    0    0 3781    0    0    0    0    0]\n",
            " [   3    0    0    0    0 3630    0    0    0    0    0]\n",
            " [   0    0    0    0    0    0    2    0    0 3756    0]\n",
            " [   1    0    0    0    0    0    0 3797    0    0    0]\n",
            " [   0    0    0    0    0    0    0    0 3706    0    0]\n",
            " [   0    0    0    0    0    0    0    0    0 3670    0]\n",
            " [   0    0    0    0    0    0   50    0    0 2231 1396]]\n",
            "Batch 79/237 - Batch Inference Time: 1.2824 seconds\n",
            "Testing Confusion Matrix:\n",
            " [[3635    0    0    0    0    1    0    2    0    0    0]\n",
            " [   0 3605  116    1    0    0    0    0    0    1    0]\n",
            " [   0  204 3355    1    0    0    0    0    0    0    0]\n",
            " [   0    0    0 3670    0    0    0    0    0    0    0]\n",
            " [   5    0    1    0    0 3827    0    0    0    0    0]\n",
            " [   3    0    0    0    0 3682    0    0    0    0    0]\n",
            " [   0    0    0    0    0    0    2    0    0 3809    0]\n",
            " [   1    0    0    0    0    0    0 3842    0    0    0]\n",
            " [   0    0    0    0    0    0    0    0 3750    0    0]\n",
            " [   0    0    0    0    0    0    0    0    0 3724    0]\n",
            " [   0    0    0    0    0    0   50    0    0 2257 1416]]\n",
            "Batch 80/237 - Batch Inference Time: 1.3053 seconds\n",
            "Testing Confusion Matrix:\n",
            " [[3689    0    0    0    0    1    0    2    0    0    0]\n",
            " [   0 3650  116    1    0    0    0    0    0    1    0]\n",
            " [   0  205 3393    1    0    0    0    0    0    0    0]\n",
            " [   0    0    0 3710    0    0    0    0    0    0    0]\n",
            " [   5    0    1    0    0 3880    0    0    0    0    0]\n",
            " [   3    0    0    0    0 3731    0    0    0    0    0]\n",
            " [   0    0    0    0    0    0    2    0    0 3850    0]\n",
            " [   1    0    0    0    0    0    0 3887    0    0    0]\n",
            " [   0    0    0    0    0    0    0    0 3788    0    0]\n",
            " [   0    0    0    0    0    0    0    0    0 3773    0]\n",
            " [   0    0    0    0    0    0   51    0    0 2297 1434]]\n",
            "Batch 81/237 - Batch Inference Time: 1.3382 seconds\n",
            "Testing Confusion Matrix:\n",
            " [[3729    0    0    0    0    1    0    2    0    0    0]\n",
            " [   0 3683  117    1    0    0    0    0    0    1    0]\n",
            " [   0  210 3428    1    0    0    0    0    0    0    0]\n",
            " [   0    0    0 3762    0    0    0    0    0    0    0]\n",
            " [   5    0    1    0    0 3926    0    0    0    0    0]\n",
            " [   3    0    0    0    0 3787    0    0    0    0    0]\n",
            " [   0    0    0    0    0    0    2    0    0 3901    0]\n",
            " [   1    0    0    0    0    0    0 3929    0    0    0]\n",
            " [   0    0    0    0    0    0    0    0 3838    0    0]\n",
            " [   0    0    0    0    0    0    0    0    0 3825    0]\n",
            " [   0    0    0    0    0    0   51    0    0 2324 1456]]\n",
            "Batch 82/237 - Batch Inference Time: 1.2649 seconds\n",
            "Testing Confusion Matrix:\n",
            " [[3767    0    0    0    0    1    0    2    0    0    0]\n",
            " [   0 3730  117    1    0    0    0    0    0    1    0]\n",
            " [   0  213 3470    1    0    0    0    0    0    0    0]\n",
            " [   0    0    0 3809    0    0    0    0    0    0    0]\n",
            " [   5    0    1    0    0 3973    0    0    0    0    0]\n",
            " [   3    0    0    0    0 3838    0    0    0    0    0]\n",
            " [   0    0    0    0    0    0    2    0    0 3944    0]\n",
            " [   1    0    0    0    0    0    0 3966    0    0    0]\n",
            " [   0    0    0    0    0    0    0    0 3894    0    0]\n",
            " [   0    0    0    0    0    0    0    0    0 3884    0]\n",
            " [   0    0    0    0    0    0   51    0    0 2349 1473]]\n",
            "Batch 83/237 - Batch Inference Time: 1.5789 seconds\n",
            "Testing Confusion Matrix:\n",
            " [[3812    0    0    0    0    1    0    2    0    0    0]\n",
            " [   0 3783  118    1    0    0    0    0    0    1    0]\n",
            " [   0  216 3518    1    0    0    0    0    0    0    0]\n",
            " [   0    0    0 3842    0    0    0    0    0    0    0]\n",
            " [   5    0    1    0    0 4020    0    0    0    0    0]\n",
            " [   3    0    0    0    0 3881    0    0    0    0    0]\n",
            " [   0    0    0    0    0    0    2    0    0 3988    0]\n",
            " [   1    0    0    0    0    0    0 4018    0    0    0]\n",
            " [   0    0    0    0    0    0    0    0 3949    0    0]\n",
            " [   0    0    0    0    0    0    0    0    0 3924    0]\n",
            " [   0    0    0    0    0    0   51    0    0 2378 1492]]\n",
            "Batch 84/237 - Batch Inference Time: 2.0730 seconds\n",
            "Testing Confusion Matrix:\n",
            " [[3850    0    0    0    0    1    0    2    0    0    0]\n",
            " [   0 3823  120    1    0    0    0    0    0    1    0]\n",
            " [   0  219 3563    1    0    0    0    0    1    0    0]\n",
            " [   0    0    0 3897    0    0    0    0    0    0    0]\n",
            " [   5    0    1    0    0 4062    0    0    0    0    0]\n",
            " [   3    0    0    0    0 3929    0    0    0    0    0]\n",
            " [   0    0    0    0    0    0    2    0    0 4048    0]\n",
            " [   1    0    0    0    0    0    0 4068    0    0    0]\n",
            " [   0    0    0    0    0    0    0    0 3987    0    0]\n",
            " [   0    0    0    0    0    0    0    0    0 3973    0]\n",
            " [   0    0    0    0    0    0   51    0    0 2399 1512]]\n",
            "Batch 85/237 - Batch Inference Time: 1.4822 seconds\n",
            "Testing Confusion Matrix:\n",
            " [[3893    0    0    0    0    1    0    2    0    0    0]\n",
            " [   0 3867  124    1    0    0    0    0    0    1    0]\n",
            " [   0  222 3606    1    0    0    0    0    1    0    0]\n",
            " [   0    0    0 3952    0    0    0    0    0    0    0]\n",
            " [   5    0    1    0    0 4097    0    0    0    0    0]\n",
            " [   3    0    0    0    0 3972    0    0    0    0    0]\n",
            " [   0    0    0    0    0    0    2    0    0 4092    0]\n",
            " [   1    0    0    0    0    0    0 4116    0    0    0]\n",
            " [   0    0    0    0    0    0    0    0 4044    0    0]\n",
            " [   0    0    0    0    0    0    0    0    0 4023    0]\n",
            " [   0    0    0    0    0    0   51    0    0 2425 1529]]\n",
            "Batch 86/237 - Batch Inference Time: 1.3519 seconds\n",
            "Testing Confusion Matrix:\n",
            " [[3929    0    0    0    0    1    0    2    0    0    0]\n",
            " [   0 3912  125    1    0    0    0    0    0    1    0]\n",
            " [   0  225 3656    1    0    0    0    0    1    0    0]\n",
            " [   0    0    0 4001    0    0    0    0    0    0    0]\n",
            " [   5    0    1    0    0 4132    0    0    0    0    0]\n",
            " [   3    0    0    0    0 4027    0    0    0    0    0]\n",
            " [   0    0    0    0    0    0    2    0    0 4137    0]\n",
            " [   1    0    0    0    0    0    0 4168    0    0    0]\n",
            " [   0    0    0    0    0    0    0    0 4093    0    0]\n",
            " [   0    0    0    0    0    0    0    0    0 4068    0]\n",
            " [   0    0    0    0    0    0   51    0    0 2456 1545]]\n",
            "Batch 87/237 - Batch Inference Time: 1.2846 seconds\n",
            "Testing Confusion Matrix:\n",
            " [[3984    0    0    0    0    1    0    2    0    0    0]\n",
            " [   0 3959  126    1    0    0    0    0    0    1    0]\n",
            " [   0  226 3687    1    0    0    0    0    1    0    0]\n",
            " [   0    0    0 4055    0    0    0    0    0    0    0]\n",
            " [   5    0    1    0    0 4178    0    0    0    0    0]\n",
            " [   3    0    0    0    0 4082    0    0    0    0    0]\n",
            " [   0    0    0    0    0    0    2    0    0 4187    0]\n",
            " [   1    0    0    0    0    0    0 4205    0    0    0]\n",
            " [   0    0    0    0    0    0    0    0 4141    0    0]\n",
            " [   0    0    0    0    0    0    0    0    0 4113    0]\n",
            " [   0    0    0    0    0    0   51    0    0 2485 1558]]\n",
            "Batch 88/237 - Batch Inference Time: 1.2556 seconds\n",
            "Testing Confusion Matrix:\n",
            " [[4037    0    0    0    0    1    0    2    0    0    0]\n",
            " [   0 3997  126    1    0    0    0    0    0    1    0]\n",
            " [   0  231 3733    1    0    0    0    0    1    0    0]\n",
            " [   0    0    0 4099    0    0    0    0    0    0    0]\n",
            " [   5    0    1    0    0 4225    0    0    0    0    0]\n",
            " [   3    0    0    0    0 4133    0    0    0    0    0]\n",
            " [   0    0    0    0    0    0    2    0    0 4235    0]\n",
            " [   1    0    0    0    0    0    0 4254    0    0    0]\n",
            " [   0    0    0    0    0    0    0    0 4190    0    0]\n",
            " [   0    0    0    0    0    0    0    0    0 4157    0]\n",
            " [   0    0    0    0    0    0   52    0    0 2507 1573]]\n",
            "Batch 89/237 - Batch Inference Time: 1.2904 seconds\n",
            "Testing Confusion Matrix:\n",
            " [[4087    0    0    0    0    1    0    2    0    0    0]\n",
            " [   0 4044  129    1    0    0    0    0    0    1    0]\n",
            " [   0  238 3773    1    0    0    0    0    1    0    0]\n",
            " [   0    0    0 4135    0    0    0    0    0    0    0]\n",
            " [   5    0    1    0    0 4284    0    0    0    0    0]\n",
            " [   3    0    0    0    0 4172    0    0    0    0    0]\n",
            " [   0    0    0    0    0    0    2    0    0 4274    0]\n",
            " [   1    0    0    0    0    0    0 4295    0    0    0]\n",
            " [   0    0    0    0    0    0    0    0 4232    0    0]\n",
            " [   0    0    0    0    0    0    0    0    0 4207    0]\n",
            " [   0    0    0    0    0    0   52    0    0 2539 1600]]\n",
            "Batch 90/237 - Batch Inference Time: 1.3321 seconds\n",
            "Testing Confusion Matrix:\n",
            " [[4139    0    0    0    0    1    0    2    0    0    0]\n",
            " [   0 4090  131    1    0    0    0    0    0    1    0]\n",
            " [   0  238 3825    1    0    0    0    0    1    0    0]\n",
            " [   0    0    0 4175    0    0    0    0    0    0    0]\n",
            " [   5    0    1    0    0 4327    0    0    0    0    0]\n",
            " [   3    0    0    0    0 4224    0    0    0    0    0]\n",
            " [   0    0    0    0    0    0    2    0    0 4312    0]\n",
            " [   1    0    0    0    0    0    0 4340    0    0    0]\n",
            " [   0    0    0    0    0    0    0    0 4275    0    0]\n",
            " [   0    0    0    0    0    0    0    0    0 4250    0]\n",
            " [   0    0    0    0    0    0   56    0    0 2573 1618]]\n",
            "Batch 91/237 - Batch Inference Time: 1.2842 seconds\n",
            "Testing Confusion Matrix:\n",
            " [[4194    0    0    0    0    1    0    2    0    0    0]\n",
            " [   0 4132  131    1    0    0    0    0    0    1    0]\n",
            " [   0  238 3866    1    0    0    0    0    1    0    0]\n",
            " [   0    0    0 4234    0    0    0    0    0    0    0]\n",
            " [   5    0    1    0    0 4370    0    0    0    0    0]\n",
            " [   3    0    0    0    0 4264    0    0    0    0    0]\n",
            " [   0    0    0    0    0    0    2    0    0 4358    0]\n",
            " [   1    0    0    0    1    0    0 4379    0    0    0]\n",
            " [   0    0    0    0    0    0    0    0 4323    0    0]\n",
            " [   0    0    0    0    0    0    0    0    0 4300    0]\n",
            " [   0    0    0    0    0    0   58    0    0 2600 1637]]\n",
            "Batch 92/237 - Batch Inference Time: 1.2921 seconds\n",
            "Testing Confusion Matrix:\n",
            " [[4232    0    0    0    0    2    0    2    0    0    0]\n",
            " [   0 4175  136    1    0    0    0    0    0    1    0]\n",
            " [   1  239 3913    1    0    0    0    0    1    0    0]\n",
            " [   0    0    0 4279    0    0    0    0    0    0    0]\n",
            " [   5    0    1    0    0 4428    0    0    0    0    0]\n",
            " [   3    0    0    0    0 4310    0    0    0    0    0]\n",
            " [   0    0    0    0    0    0    2    0    0 4416    0]\n",
            " [   1    0    0    0    1    0    0 4416    0    0    0]\n",
            " [   0    0    0    0    0    0    0    0 4374    0    0]\n",
            " [   0    0    0    0    0    0    0    0    0 4334    0]\n",
            " [   0    0    0    0    0    0   58    0    0 2630 1654]]\n",
            "Batch 93/237 - Batch Inference Time: 1.7206 seconds\n",
            "Testing Confusion Matrix:\n",
            " [[4279    0    0    0    0    2    0    2    0    0    0]\n",
            " [   0 4229  137    1    0    0    0    0    0    1    0]\n",
            " [   1  242 3959    1    0    0    0    0    1    0    0]\n",
            " [   0    0    0 4328    0    0    0    0    0    0    0]\n",
            " [   5    0    1    0    0 4479    0    0    0    0    0]\n",
            " [   3    0    0    0    0 4349    0    0    0    0    0]\n",
            " [   0    0    0    0    0    0    2    0    0 4464    0]\n",
            " [   1    0    0    0    1    0    0 4452    0    0    0]\n",
            " [   0    0    0    0    0    0    0    0 4421    0    0]\n",
            " [   0    0    0    0    0    0    0    0    0 4383    0]\n",
            " [   0    0    0    0    0    0   59    0    0 2659 1666]]\n",
            "Batch 94/237 - Batch Inference Time: 1.7610 seconds\n",
            "Testing Confusion Matrix:\n",
            " [[4325    0    0    0    0    3    0    2    0    0    0]\n",
            " [   0 4271  137    1    0    0    0    0    0    1    0]\n",
            " [   1  245 3991    1    0    0    0    0    1    0    0]\n",
            " [   0    0    0 4387    0    0    0    0    0    0    0]\n",
            " [   5    0    1    0    0 4528    0    0    0    0    0]\n",
            " [   3    0    0    0    0 4403    0    0    0    0    0]\n",
            " [   0    0    0    0    0    0    2    0    0 4510    0]\n",
            " [   1    0    0    0    1    0    0 4502    0    0    0]\n",
            " [   0    0    0    0    0    0    0    0 4470    0    0]\n",
            " [   0    0    0    0    0    0    0    0    0 4424    0]\n",
            " [   0    0    0    0    0    0   59    0    0 2689 1676]]\n",
            "Batch 95/237 - Batch Inference Time: 1.7050 seconds\n",
            "Testing Confusion Matrix:\n",
            " [[4378    0    0    0    0    3    0    2    0    0    0]\n",
            " [   0 4311  137    1    0    0    0    0    0    1    0]\n",
            " [   1  247 4038    1    0    0    0    0    1    0    0]\n",
            " [   0    0    0 4430    0    0    0    0    0    0    0]\n",
            " [   5    0    1    0    0 4578    0    0    0    0    0]\n",
            " [   3    0    0    0    0 4449    0    0    0    0    0]\n",
            " [   0    0    0    0    0    0    2    0    0 4556    0]\n",
            " [   1    0    0    0    1    0    0 4547    0    0    0]\n",
            " [   0    0    0    0    0    0    0    0 4517    0    0]\n",
            " [   0    0    0    0    0    0    0    0    0 4476    0]\n",
            " [   0    0    0    0    0    0   60    0    0 2719 1686]]\n",
            "Batch 96/237 - Batch Inference Time: 1.2685 seconds\n",
            "Testing Confusion Matrix:\n",
            " [[4425    0    0    0    0    4    0    2    0    0    0]\n",
            " [   0 4347  139    1    0    0    0    0    0    1    0]\n",
            " [   1  248 4085    1    0    0    0    0    1    0    0]\n",
            " [   0    0    0 4480    0    0    0    0    0    0    0]\n",
            " [   5    0    1    0    0 4623    0    0    0    0    0]\n",
            " [   3    0    0    0    0 4501    0    0    0    0    0]\n",
            " [   0    0    0    0    0    0    2    0    0 4604    0]\n",
            " [   1    0    0    0    1    0    0 4589    0    0    0]\n",
            " [   0    0    0    0    0    0    0    0 4562    0    0]\n",
            " [   0    0    0    0    0    0    0    0    0 4517    0]\n",
            " [   0    0    0    0    0    0   60    0    0 2757 1703]]\n",
            "Batch 97/237 - Batch Inference Time: 1.3531 seconds\n",
            "Testing Confusion Matrix:\n",
            " [[4478    0    0    0    0    4    0    2    0    0    0]\n",
            " [   0 4395  139    1    0    0    0    0    0    1    0]\n",
            " [   1  252 4136    1    0    0    0    0    1    0    0]\n",
            " [   0    0    0 4530    0    0    0    0    0    0    0]\n",
            " [   5    0    1    0    0 4672    0    0    0    0    0]\n",
            " [   3    0    0    0    0 4544    0    0    0    0    0]\n",
            " [   0    0    0    0    0    0    2    0    0 4640    0]\n",
            " [   1    0    0    0    1    0    0 4633    0    0    0]\n",
            " [   0    0    0    0    0    0    0    0 4610    0    0]\n",
            " [   0    0    0    0    0    0    0    0    0 4562    0]\n",
            " [   0    0    0    0    0    0   60    0    0 2786 1715]]\n",
            "Batch 98/237 - Batch Inference Time: 1.3317 seconds\n",
            "Testing Confusion Matrix:\n",
            " [[4532    0    0    0    0    4    0    2    0    0    0]\n",
            " [   0 4447  143    1    0    0    0    0    0    1    0]\n",
            " [   1  254 4170    1    0    0    0    0    1    0    0]\n",
            " [   0    0    0 4580    0    0    0    0    0    0    0]\n",
            " [   5    0    1    0    0 4722    0    0    0    0    0]\n",
            " [   3    0    0    0    0 4589    0    0    0    0    0]\n",
            " [   0    0    0    0    0    0    2    0    0 4678    0]\n",
            " [   1    0    0    0    1    0    0 4678    0    0    0]\n",
            " [   0    0    0    0    0    0    0    0 4656    0    0]\n",
            " [   0    0    0    0    0    0    0    0    0 4607    0]\n",
            " [   0    0    0    0    0    0   60    0    0 2821 1727]]\n",
            "Batch 99/237 - Batch Inference Time: 1.2826 seconds\n",
            "Testing Confusion Matrix:\n",
            " [[4574    0    0    0    0    4    0    2    0    0    0]\n",
            " [   0 4497  144    1    0    0    0    0    0    1    0]\n",
            " [   1  259 4225    1    0    0    0    0    1    0    0]\n",
            " [   0    0    0 4617    0    0    0    0    0    0    0]\n",
            " [   5    0    1    0    0 4776    0    0    0    0    0]\n",
            " [   3    0    0    0    0 4634    0    0    0    0    0]\n",
            " [   0    0    0    0    0    0    2    0    0 4732    0]\n",
            " [   1    0    0    0    1    0    0 4720    0    0    0]\n",
            " [   0    0    0    0    0    0    0    0 4700    0    0]\n",
            " [   0    0    0    0    0    0    0    0    0 4652    0]\n",
            " [   0    0    0    0    0    0   61    0    0 2838 1747]]\n",
            "Batch 100/237 - Batch Inference Time: 1.3555 seconds\n",
            "Testing Confusion Matrix:\n",
            " [[4611    0    0    0    0    4    0    2    0    0    0]\n",
            " [   0 4543  145    1    0    0    0    0    0    1    0]\n",
            " [   1  264 4273    1    0    0    0    0    1    0    0]\n",
            " [   1    0    0 4671    0    0    0    0    0    0    0]\n",
            " [   5    0    1    0    0 4814    0    0    0    0    0]\n",
            " [   3    0    0    0    0 4695    0    0    0    0    0]\n",
            " [   0    0    0    0    0    0    2    0    0 4777    0]\n",
            " [   1    0    0    0    1    0    0 4764    0    0    0]\n",
            " [   0    0    0    0    0    0    0    0 4758    0    0]\n",
            " [   0    0    0    0    0    0    0    0    0 4689    0]\n",
            " [   0    0    0    0    0    0   63    0    0 2862 1758]]\n",
            "Batch 101/237 - Batch Inference Time: 1.3395 seconds\n",
            "Testing Confusion Matrix:\n",
            " [[4655    0    0    0    0    4    0    2    0    0    0]\n",
            " [   0 4586  148    1    0    0    0    0    0    1    0]\n",
            " [   1  270 4316    1    0    0    0    0    1    0    0]\n",
            " [   1    0    0 4729    0    0    0    0    0    0    0]\n",
            " [   6    0    1    0    0 4853    0    0    0    0    0]\n",
            " [   3    0    0    0    0 4737    0    0    0    0    0]\n",
            " [   0    0    0    0    0    0    2    0    0 4829    0]\n",
            " [   1    0    0    0    1    0    0 4818    0    0    0]\n",
            " [   0    0    0    0    0    0    0    0 4796    0    0]\n",
            " [   0    0    0    0    0    0    0    0    0 4730    0]\n",
            " [   0    0    0    0    0    0   63    0    0 2887 1781]]\n",
            "Batch 102/237 - Batch Inference Time: 1.6206 seconds\n",
            "Testing Confusion Matrix:\n",
            " [[4700    0    0    0    0    4    0    2    0    0    0]\n",
            " [   0 4640  149    1    0    0    0    0    0    1    0]\n",
            " [   1  271 4357    1    0    0    0    0    1    0    0]\n",
            " [   1    0    0 4773    0    0    0    0    0    0    0]\n",
            " [   6    0    1    0    0 4894    0    0    0    0    0]\n",
            " [   3    0    0    0    0 4786    0    0    0    0    0]\n",
            " [   0    0    0    0    0    0    2    0    0 4880    0]\n",
            " [   1    0    0    0    1    0    0 4865    0    0    0]\n",
            " [   0    0    0    0    0    0    0    0 4839    0    0]\n",
            " [   0    0    0    0    0    0    0    0    0 4778    0]\n",
            " [   0    0    0    0    0    0   64    0    0 2919 1795]]\n",
            "Batch 103/237 - Batch Inference Time: 2.2711 seconds\n",
            "Testing Confusion Matrix:\n",
            " [[4753    0    0    0    0    4    0    2    0    0    0]\n",
            " [   0 4681  149    1    0    0    0    0    0    1    0]\n",
            " [   1  271 4404    1    0    0    0    0    1    0    0]\n",
            " [   1    0    0 4811    0    0    0    0    0    0    0]\n",
            " [   6    0    1    0    0 4937    0    0    0    0    0]\n",
            " [   3    0    0    0    0 4834    0    0    0    0    0]\n",
            " [   0    0    0    0    0    0    2    0    0 4922    0]\n",
            " [   1    0    0    0    1    0    0 4910    0    0    0]\n",
            " [   0    0    0    0    0    0    0    0 4896    0    0]\n",
            " [   0    0    0    0    0    0    0    0    0 4826    0]\n",
            " [   0    0    0    0    0    0   65    0    0 2948 1815]]\n",
            "Batch 104/237 - Batch Inference Time: 1.8294 seconds\n",
            "Testing Confusion Matrix:\n",
            " [[4802    0    0    0    0    4    0    2    0    0    0]\n",
            " [   0 4721  151    1    0    0    0    0    0    1    0]\n",
            " [   1  274 4449    1    0    0    0    0    2    0    0]\n",
            " [   1    0    0 4846    0    0    0    0    0    0    0]\n",
            " [   6    0    1    0    0 4984    0    1    0    0    0]\n",
            " [   3    0    0    0    0 4882    0    0    0    0    0]\n",
            " [   0    0    0    0    0    0    2    0    0 4969    0]\n",
            " [   1    0    0    0    1    0    0 4954    0    0    0]\n",
            " [   0    0    0    0    0    0    0    0 4953    0    0]\n",
            " [   0    0    0    0    0    0    0    0    0 4871    0]\n",
            " [   0    0    0    0    0    0   67    0    0 2979 1830]]\n",
            "Batch 105/237 - Batch Inference Time: 1.2872 seconds\n",
            "Testing Confusion Matrix:\n",
            " [[4852    0    0    0    0    4    0    2    0    0    0]\n",
            " [   0 4762  151    1    0    0    0    0    0    1    0]\n",
            " [   1  276 4494    1    0    0    0    0    2    0    0]\n",
            " [   1    0    0 4882    0    0    0    0    0    0    0]\n",
            " [   6    0    1    0    0 5032    0    1    0    0    0]\n",
            " [   4    0    0    0    0 4939    0    0    0    0    0]\n",
            " [   0    0    0    0    0    0    2    0    0 5022    0]\n",
            " [   1    0    0    0    1    0    0 5009    0    0    0]\n",
            " [   0    0    0    0    0    0    0    0 4995    0    0]\n",
            " [   0    0    0    0    0    0    0    0    0 4922    0]\n",
            " [   0    0    0    0    0    0   67    0    0 2999 1841]]\n",
            "Batch 106/237 - Batch Inference Time: 1.2912 seconds\n",
            "Testing Confusion Matrix:\n",
            " [[4893    0    0    0    0    4    0    2    0    0    0]\n",
            " [   0 4800  152    1    0    0    0    0    0    1    0]\n",
            " [   1  281 4545    1    0    0    0    0    2    0    0]\n",
            " [   1    0    0 4928    0    0    0    0    0    0    0]\n",
            " [   6    0    1    0    0 5084    0    1    0    0    0]\n",
            " [   4    0    0    0    0 4983    0    0    0    0    0]\n",
            " [   0    0    0    0    0    0    2    0    0 5077    0]\n",
            " [   1    0    0    0    1    0    0 5060    0    0    0]\n",
            " [   0    0    0    0    0    0    0    0 5048    0    0]\n",
            " [   0    0    0    0    0    0    0    0    0 4963    0]\n",
            " [   0    0    0    0    0    0   67    0    0 3020 1854]]\n",
            "Batch 107/237 - Batch Inference Time: 1.2917 seconds\n",
            "Testing Confusion Matrix:\n",
            " [[4930    0    0    0    0    4    0    2    0    0    0]\n",
            " [   0 4841  154    1    0    0    0    0    0    1    0]\n",
            " [   1  284 4603    1    0    0    0    0    2    0    0]\n",
            " [   1    0    0 4974    0    0    0    0    0    0    0]\n",
            " [   6    0    1    0    0 5134    0    1    0    0    0]\n",
            " [   4    0    0    0    0 5029    0    0    0    0    0]\n",
            " [   0    0    0    0    0    0    2    0    0 5118    0]\n",
            " [   1    0    0    0    1    0    0 5102    0    0    0]\n",
            " [   0    0    0    0    0    0    0    0 5103    0    0]\n",
            " [   0    0    0    0    0    0    0    0    0 5000    0]\n",
            " [   0    0    0    0    0    0   67    0    0 3051 1877]]\n",
            "Batch 108/237 - Batch Inference Time: 1.3454 seconds\n",
            "Testing Confusion Matrix:\n",
            " [[4965    0    0    0    0    4    0    2    0    0    0]\n",
            " [   0 4887  156    2    0    0    0    0    0    1    0]\n",
            " [   1  286 4653    1    0    0    0    0    2    0    0]\n",
            " [   1    0    0 5026    0    0    0    0    0    0    0]\n",
            " [   6    0    1    0    0 5177    0    1    0    0    0]\n",
            " [   4    0    0    0    0 5067    0    0    0    0    0]\n",
            " [   0    0    0    0    0    0    2    0    0 5167    0]\n",
            " [   1    0    0    0    1    0    0 5156    0    0    0]\n",
            " [   0    0    0    0    0    0    0    0 5143    0    0]\n",
            " [   0    0    0    0    0    0    0    0    0 5051    0]\n",
            " [   0    0    0    0    0    0   67    0    0 3086 1891]]\n",
            "Batch 109/237 - Batch Inference Time: 1.3145 seconds\n",
            "Testing Confusion Matrix:\n",
            " [[5015    0    0    0    0    4    0    2    0    0    0]\n",
            " [   0 4930  158    2    0    0    0    0    0    1    0]\n",
            " [   1  286 4692    1    0    0    0    0    2    0    0]\n",
            " [   1    0    0 5067    0    0    0    0    0    0    0]\n",
            " [   6    0    1    0    0 5211    0    1    0    0    0]\n",
            " [   4    0    0    0    0 5117    0    0    0    0    0]\n",
            " [   0    0    0    0    0    0    2    0    0 5230    0]\n",
            " [   1    0    0    0    1    0    0 5202    0    0    0]\n",
            " [   0    0    0    0    0    0    0    0 5188    0    0]\n",
            " [   0    0    0    0    0    0    0    0    0 5103    0]\n",
            " [   0    0    0    0    0    0   68    0    0 3113 1910]]\n",
            "Batch 110/237 - Batch Inference Time: 1.3708 seconds\n",
            "Testing Confusion Matrix:\n",
            " [[5056    0    0    0    0    4    0    2    0    0    0]\n",
            " [   0 4969  159    2    0    0    0    0    0    1    0]\n",
            " [   1  287 4745    1    0    0    0    0    2    0    0]\n",
            " [   1    0    0 5118    0    0    0    0    0    0    0]\n",
            " [   6    0    1    0    0 5257    0    1    0    0    0]\n",
            " [   4    0    0    0    0 5162    0    0    0    0    0]\n",
            " [   0    0    0    0    0    0    2    0    0 5277    0]\n",
            " [   1    0    0    0    1    0    0 5237    0    0    0]\n",
            " [   0    0    0    0    0    0    0    0 5244    0    0]\n",
            " [   0    0    0    0    0    0    0    0    0 5149    0]\n",
            " [   0    0    0    0    0    0   70    0    0 3138 1934]]\n",
            "Batch 111/237 - Batch Inference Time: 1.3529 seconds\n",
            "Testing Confusion Matrix:\n",
            " [[5112    0    0    0    0    4    0    2    0    0    0]\n",
            " [   0 5028  161    2    0    0    0    0    0    1    0]\n",
            " [   1  291 4784    1    0    0    0    0    2    0    0]\n",
            " [   1    0    0 5163    0    0    0    0    0    0    0]\n",
            " [   6    0    1    0    0 5306    0    1    0    0    0]\n",
            " [   4    0    0    0    0 5207    0    0    0    0    0]\n",
            " [   0    0    0    0    0    0    2    0    0 5312    0]\n",
            " [   1    0    0    0    1    0    0 5282    0    0    0]\n",
            " [   0    0    0    0    0    0    0    0 5289    0    0]\n",
            " [   0    0    0    0    0    0    0    0    0 5192    0]\n",
            " [   0    0    0    0    0    0   71    0    0 3165 1951]]\n",
            "Batch 112/237 - Batch Inference Time: 1.7807 seconds\n",
            "Testing Confusion Matrix:\n",
            " [[5158    0    0    0    0    4    0    2    0    0    0]\n",
            " [   0 5076  161    2    0    0    0    0    0    1    0]\n",
            " [   1  295 4825    1    0    0    0    0    2    0    0]\n",
            " [   1    0    0 5206    0    0    0    0    0    0    0]\n",
            " [   6    0    1    0    0 5360    0    1    0    0    0]\n",
            " [   4    0    0    0    0 5249    0    0    0    0    0]\n",
            " [   0    0    0    0    0    0    2    0    0 5359    0]\n",
            " [   1    0    0    0    1    0    0 5319    0    0    0]\n",
            " [   0    0    0    0    0    0    0    0 5342    0    0]\n",
            " [   0    0    0    0    0    0    0    0    0 5241    0]\n",
            " [   0    0    0    0    0    0   71    0    0 3196 1968]]\n",
            "Batch 113/237 - Batch Inference Time: 2.0674 seconds\n",
            "Testing Confusion Matrix:\n",
            " [[5202    0    0    0    0    4    0    2    0    0    0]\n",
            " [   0 5118  161    2    0    0    0    0    0    1    0]\n",
            " [   1  299 4863    1    0    0    0    0    2    0    0]\n",
            " [   1    0    0 5245    0    0    0    0    0    0    0]\n",
            " [   6    0    1    0    0 5402    0    1    0    0    0]\n",
            " [   4    0    0    0    0 5303    0    0    0    0    0]\n",
            " [   0    0    0    0    0    0    2    0    0 5398    0]\n",
            " [   1    0    0    0    1    0    0 5366    0    0    0]\n",
            " [   0    0    0    0    0    0    0    0 5401    0    0]\n",
            " [   0    0    0    0    0    0    0    0    0 5297    0]\n",
            " [   0    0    0    0    0    0   71    0    0 3229 1983]]\n",
            "Batch 114/237 - Batch Inference Time: 1.2931 seconds\n",
            "Testing Confusion Matrix:\n",
            " [[5252    0    0    0    0    4    0    2    0    0    0]\n",
            " [   0 5177  162    2    0    0    0    0    0    1    0]\n",
            " [   1  302 4900    1    0    0    0    0    2    0    0]\n",
            " [   1    0    0 5290    0    0    0    0    0    0    0]\n",
            " [   6    0    1    0    0 5452    0    1    0    0    0]\n",
            " [   4    0    0    0    0 5348    0    0    0    0    0]\n",
            " [   0    0    0    0    0    0    2    0    0 5442    0]\n",
            " [   1    0    0    0    1    0    0 5409    0    0    0]\n",
            " [   0    0    0    0    0    0    0    0 5443    0    0]\n",
            " [   0    0    0    0    0    0    0    0    0 5344    0]\n",
            " [   0    0    0    0    0    0   71    0    0 3265 1993]]\n",
            "Batch 115/237 - Batch Inference Time: 1.2985 seconds\n",
            "Testing Confusion Matrix:\n",
            " [[5295    0    0    0    0    4    0    2    0    0    0]\n",
            " [   0 5226  162    2    0    0    0    0    0    1    0]\n",
            " [   1  305 4947    1    0    0    0    0    2    0    0]\n",
            " [   1    0    0 5334    0    0    0    0    0    0    0]\n",
            " [   6    0    1    0    0 5500    0    1    0    0    0]\n",
            " [   4    0    0    0    0 5399    0    0    0    0    0]\n",
            " [   0    0    0    0    0    0    2    0    0 5486    0]\n",
            " [   1    0    0    0    1    0    0 5445    0    0    0]\n",
            " [   0    0    0    0    0    0    0    0 5491    0    0]\n",
            " [   0    0    0    0    0    0    0    0    0 5395    0]\n",
            " [   0    0    0    0    0    0   71    0    0 3298 2008]]\n",
            "Batch 116/237 - Batch Inference Time: 1.3829 seconds\n",
            "Testing Confusion Matrix:\n",
            " [[5342    0    0    0    0    4    0    2    0    0    0]\n",
            " [   0 5264  164    2    0    0    0    0    0    1    0]\n",
            " [   1  309 5001    1    0    0    0    0    2    0    0]\n",
            " [   1    0    0 5383    0    0    0    0    0    0    0]\n",
            " [   6    0    1    0    0 5548    0    1    0    0    0]\n",
            " [   4    0    0    0    0 5444    0    0    0    0    0]\n",
            " [   0    0    0    0    0    0    2    0    0 5531    0]\n",
            " [   1    0    0    0    1    0    0 5497    0    0    0]\n",
            " [   0    0    0    0    0    0    0    0 5535    0    0]\n",
            " [   0    0    0    0    0    0    0    0    0 5436    0]\n",
            " [   0    0    0    0    0    0   71    0    0 3326 2023]]\n",
            "Batch 117/237 - Batch Inference Time: 1.3352 seconds\n",
            "Testing Confusion Matrix:\n",
            " [[5385    0    0    0    0    4    0    2    0    0    0]\n",
            " [   0 5303  165    2    0    0    0    0    0    1    0]\n",
            " [   1  310 5062    1    0    0    0    0    2    0    0]\n",
            " [   1    0    0 5425    0    0    0    0    0    0    0]\n",
            " [   6    0    1    0    0 5584    0    1    0    0    0]\n",
            " [   4    0    0    0    0 5481    0    0    0    0    0]\n",
            " [   0    0    0    0    0    0    2    0    0 5592    0]\n",
            " [   1    0    0    0    1    0    0 5542    0    0    0]\n",
            " [   0    0    0    0    0    0    0    0 5595    0    0]\n",
            " [   0    0    0    0    0    0    0    0    0 5483    0]\n",
            " [   0    0    0    0    0    0   71    0    0 3343 2045]]\n",
            "Batch 118/237 - Batch Inference Time: 1.3745 seconds\n",
            "Testing Confusion Matrix:\n",
            " [[5428    0    0    0    0    4    0    2    0    0    0]\n",
            " [   0 5339  166    2    0    0    0    0    0    1    0]\n",
            " [   1  313 5092    1    0    0    0    0    2    0    0]\n",
            " [   1    0    0 5480    0    0    0    0    0    0    0]\n",
            " [   6    0    1    0    0 5627    0    1    0    0    0]\n",
            " [   4    0    0    0    0 5526    0    0    0    0    0]\n",
            " [   0    0    0    0    0    0    2    0    0 5636    0]\n",
            " [   1    0    0    0    1    0    0 5593    0    0    0]\n",
            " [   0    0    0    0    0    0    0    0 5644    0    0]\n",
            " [   0    0    0    0    0    0    0    0    0 5540    0]\n",
            " [   0    1    0    0    0    0   71    0    0 3379 2063]]\n",
            "Batch 119/237 - Batch Inference Time: 1.2959 seconds\n",
            "Testing Confusion Matrix:\n",
            " [[5479    0    0    0    0    4    0    2    0    0    0]\n",
            " [   0 5395  166    2    0    0    0    0    0    1    0]\n",
            " [   1  315 5137    1    0    0    0    0    2    0    0]\n",
            " [   1    0    0 5515    0    0    0    0    0    0    0]\n",
            " [   6    0    1    0    0 5675    0    1    0    0    0]\n",
            " [   4    0    0    0    0 5560    0    0    0    0    0]\n",
            " [   0    0    0    0    0    0    2    0    0 5689    0]\n",
            " [   1    0    0    0    1    0    0 5636    0    0    0]\n",
            " [   0    0    0    0    0    0    0    0 5697    0    0]\n",
            " [   0    0    0    0    0    0    0    0    0 5591    0]\n",
            " [   0    1    0    0    0    0   71    0    0 3406 2077]]\n",
            "Batch 120/237 - Batch Inference Time: 1.3873 seconds\n",
            "Testing Confusion Matrix:\n",
            " [[5517    0    0    0    0    4    0    2    0    0    0]\n",
            " [   0 5430  167    2    0    0    0    0    0    1    0]\n",
            " [   1  317 5184    1    0    0    0    0    2    0    0]\n",
            " [   1    0    0 5569    0    0    0    0    0    0    0]\n",
            " [   7    0    1    0    0 5714    0    1    0    0    0]\n",
            " [   4    0    0    0    0 5603    0    0    0    0    0]\n",
            " [   0    0    0    0    0    0    2    0    0 5739    0]\n",
            " [   1    0    0    0    1    0    0 5691    0    0    0]\n",
            " [   0    0    0    0    0    0    0    0 5749    0    0]\n",
            " [   0    0    0    0    0    0    0    0    0 5637    0]\n",
            " [   0    1    0    0    0    0   73    0    0 3434 2096]]\n",
            "Batch 121/237 - Batch Inference Time: 2.0006 seconds\n",
            "Testing Confusion Matrix:\n",
            " [[5578    0    0    0    0    4    0    2    0    0    0]\n",
            " [   0 5470  169    2    0    0    0    0    0    1    0]\n",
            " [   1  321 5219    1    0    0    0    0    2    0    0]\n",
            " [   1    0    0 5618    0    0    0    0    0    0    0]\n",
            " [   7    0    1    0    0 5756    0    1    0    0    0]\n",
            " [   4    0    0    0    0 5639    0    0    0    0    0]\n",
            " [   0    0    0    0    0    0    2    0    0 5787    0]\n",
            " [   1    0    0    0    1    0    0 5748    0    0    0]\n",
            " [   0    0    0    0    0    0    0    0 5809    0    0]\n",
            " [   0    0    0    0    0    0    0    0    0 5679    0]\n",
            " [   0    1    0    0    0    0   73    0    0 3459 2107]]\n",
            "Batch 122/237 - Batch Inference Time: 1.7580 seconds\n",
            "Testing Confusion Matrix:\n",
            " [[5621    0    0    0    0    4    0    2    0    0    0]\n",
            " [   0 5505  169    2    0    0    0    0    0    1    0]\n",
            " [   1  325 5269    1    0    0    0    0    2    0    0]\n",
            " [   1    0    0 5656    0    0    0    0    0    0    0]\n",
            " [   7    0    1    0    0 5805    0    1    0    0    0]\n",
            " [   4    0    0    0    0 5686    0    0    0    0    0]\n",
            " [   0    0    0    0    0    0    2    0    0 5840    0]\n",
            " [   1    0    0    0    1    0    0 5802    0    0    0]\n",
            " [   0    0    0    0    0    0    0    0 5852    0    0]\n",
            " [   0    0    0    0    0    0    0    0    0 5728    0]\n",
            " [   0    1    0    0    0    0   73    0    0 3483 2130]]\n",
            "Batch 123/237 - Batch Inference Time: 1.5082 seconds\n",
            "Testing Confusion Matrix:\n",
            " [[5660    0    0    0    0    4    0    2    0    0    0]\n",
            " [   0 5548  171    2    0    0    0    0    1    1    0]\n",
            " [   1  331 5303    1    0    0    0    0    2    0    0]\n",
            " [   1    0    0 5711    0    0    0    0    0    0    0]\n",
            " [   8    0    1    0    0 5855    0    1    0    0    0]\n",
            " [   4    0    0    0    0 5748    0    0    0    0    0]\n",
            " [   0    0    0    0    0    0    2    0    0 5874    0]\n",
            " [   1    0    0    0    1    0    0 5847    0    0    0]\n",
            " [   0    0    0    0    0    0    0    0 5890    0    0]\n",
            " [   0    0    0    0    0    0    0    0    0 5776    0]\n",
            " [   0    1    0    0    0    0   73    0    0 3513 2154]]\n",
            "Batch 124/237 - Batch Inference Time: 1.3529 seconds\n",
            "Testing Confusion Matrix:\n",
            " [[5706    0    0    0    0    4    0    2    0    0    0]\n",
            " [   0 5575  171    2    0    0    0    0    1    1    0]\n",
            " [   1  334 5347    1    0    0    0    0    2    0    0]\n",
            " [   1    0    0 5760    0    0    0    0    0    0    0]\n",
            " [   8    0    1    0    0 5893    0    1    0    0    0]\n",
            " [   4    0    0    0    0 5804    0    0    0    0    0]\n",
            " [   0    0    0    0    0    0    2    0    0 5919    0]\n",
            " [   1    0    0    0    1    0    0 5896    0    0    0]\n",
            " [   0    0    0    0    0    0    0    0 5938    0    0]\n",
            " [   0    0    0    0    0    0    0    0    0 5823    0]\n",
            " [   0    1    0    0    0    0   73    0    0 3555 2172]]\n",
            "Batch 125/237 - Batch Inference Time: 1.3637 seconds\n",
            "Testing Confusion Matrix:\n",
            " [[5759    0    0    0    0    4    0    2    0    0    0]\n",
            " [   0 5623  172    2    0    0    0    0    1    1    0]\n",
            " [   1  340 5389    1    0    0    0    0    2    0    0]\n",
            " [   1    0    0 5807    0    0    0    0    0    0    0]\n",
            " [   8    0    1    0    0 5935    0    1    0    0    0]\n",
            " [   4    0    0    0    0 5854    0    0    0    0    0]\n",
            " [   0    0    0    0    0    0    2    0    0 5967    0]\n",
            " [   1    0    0    0    1    0    0 5932    0    0    0]\n",
            " [   0    0    0    0    0    0    0    0 5988    0    0]\n",
            " [   0    0    0    0    0    0    0    0    0 5867    0]\n",
            " [   0    1    0    0    0    0   73    0    0 3584 2188]]\n",
            "Batch 126/237 - Batch Inference Time: 1.3629 seconds\n",
            "Testing Confusion Matrix:\n",
            " [[5816    0    0    0    0    4    0    2    0    0    0]\n",
            " [   0 5657  174    2    0    0    0    0    1    1    0]\n",
            " [   1  341 5440    1    0    0    0    0    2    0    0]\n",
            " [   1    0    0 5854    0    0    0    0    0    0    0]\n",
            " [   8    0    1    0    0 5982    0    1    0    0    0]\n",
            " [   4    0    0    0    0 5897    0    0    0    0    0]\n",
            " [   0    0    0    0    0    0    2    0    0 6010    0]\n",
            " [   1    0    0    0    1    0    0 5982    0    0    0]\n",
            " [   0    0    0    0    0    0    0    0 6027    0    0]\n",
            " [   0    0    0    0    0    0    0    0    0 5914    0]\n",
            " [   0    1    0    0    0    0   75    0    0 3615 2206]]\n",
            "Batch 127/237 - Batch Inference Time: 1.3717 seconds\n",
            "Testing Confusion Matrix:\n",
            " [[5860    0    0    0    0    4    0    2    0    0    0]\n",
            " [   0 5691  176    2    0    0    0    0    1    1    0]\n",
            " [   1  343 5488    1    0    0    0    0    2    0    0]\n",
            " [   1    0    0 5895    0    0    0    0    0    0    0]\n",
            " [   8    0    1    0    0 6024    0    1    0    0    0]\n",
            " [   4    0    0    0    0 5941    0    0    0    0    0]\n",
            " [   0    0    0    0    0    0    2    0    0 6056    0]\n",
            " [   1    0    0    0    1    0    0 6041    0    0    0]\n",
            " [   0    0    0    0    0    0    0    0 6087    0    0]\n",
            " [   0    0    0    0    0    0    0    0    0 5952    0]\n",
            " [   0    1    0    0    0    0   75    0    0 3643 2230]]\n",
            "Batch 128/237 - Batch Inference Time: 1.3155 seconds\n",
            "Testing Confusion Matrix:\n",
            " [[5905    0    0    0    0    4    0    2    0    0    0]\n",
            " [   0 5734  177    2    0    0    0    0    1    1    0]\n",
            " [   1  348 5545    1    0    0    0    0    2    0    0]\n",
            " [   1    0    0 5944    0    0    0    0    0    0    0]\n",
            " [   8    0    1    0    0 6062    0    1    0    0    0]\n",
            " [   4    0    0    0    0 6000    0    0    0    0    0]\n",
            " [   0    0    0    0    0    0    2    0    0 6102    0]\n",
            " [   1    0    0    0    1    0    0 6083    0    0    0]\n",
            " [   0    0    0    0    0    0    0    0 6133    0    0]\n",
            " [   0    0    0    0    0    0    0    0    0 5991    0]\n",
            " [   0    1    0    0    0    0   75    0    0 3672 2243]]\n",
            "Batch 129/237 - Batch Inference Time: 1.2971 seconds\n",
            "Testing Confusion Matrix:\n",
            " [[5961    0    0    0    0    4    0    2    0    0    0]\n",
            " [   0 5769  180    2    0    0    0    0    1    1    0]\n",
            " [   1  350 5585    1    0    0    0    0    2    0    0]\n",
            " [   1    0    0 5992    0    0    0    0    0    0    0]\n",
            " [   8    0    1    0    0 6106    0    1    0    0    0]\n",
            " [   4    0    0    0    0 6046    0    0    0    0    0]\n",
            " [   0    0    0    0    0    0    2    0    0 6140    0]\n",
            " [   1    0    0    0    1    0    0 6146    0    0    0]\n",
            " [   0    0    0    0    0    0    0    0 6172    0    0]\n",
            " [   0    0    0    0    0    0    0    0    0 6039    0]\n",
            " [   0    1    0    0    0    0   78    0    0 3699 2263]]\n",
            "Batch 130/237 - Batch Inference Time: 1.9286 seconds\n",
            "Testing Confusion Matrix:\n",
            " [[6012    0    0    0    0    4    0    2    0    0    0]\n",
            " [   0 5808  182    2    0    0    0    0    1    1    0]\n",
            " [   1  354 5627    1    0    0    0    0    2    0    0]\n",
            " [   1    0    0 6049    0    0    0    0    0    0    0]\n",
            " [   8    0    1    0    0 6149    0    1    0    0    0]\n",
            " [   4    0    0    0    0 6098    0    0    0    0    0]\n",
            " [   0    0    0    0    0    0    2    0    0 6183    0]\n",
            " [   1    0    0    0    1    0    0 6200    0    0    0]\n",
            " [   0    0    0    0    0    0    0    0 6218    0    0]\n",
            " [   0    0    0    0    0    0    0    0    0 6079    0]\n",
            " [   0    1    0    0    0    0   78    0    0 3720 2281]]\n",
            "Batch 131/237 - Batch Inference Time: 1.7949 seconds\n",
            "Testing Confusion Matrix:\n",
            " [[6056    0    0    0    0    4    0    3    0    0    0]\n",
            " [   0 5862  184    2    0    0    0    0    1    1    0]\n",
            " [   1  357 5654    1    0    0    0    0    2    0    0]\n",
            " [   1    0    0 6097    0    0    0    0    0    0    0]\n",
            " [   8    0    1    0    0 6188    0    1    0    0    0]\n",
            " [   4    0    0    0    0 6145    0    0    0    0    0]\n",
            " [   0    0    0    0    0    0    2    0    0 6233    0]\n",
            " [   1    0    0    0    1    0    0 6246    0    0    0]\n",
            " [   0    0    0    0    0    0    0    0 6265    0    0]\n",
            " [   0    0    0    0    0    0    0    0    0 6140    0]\n",
            " [   0    1    0    0    0    0   80    0    0 3746 2296]]\n",
            "Batch 132/237 - Batch Inference Time: 1.6052 seconds\n",
            "Testing Confusion Matrix:\n",
            " [[6109    0    0    0    0    4    0    3    0    0    0]\n",
            " [   0 5912  188    2    0    0    0    0    1    1    0]\n",
            " [   1  362 5697    1    0    0    0    0    2    0    0]\n",
            " [   1    0    0 6135    0    0    0    0    0    0    0]\n",
            " [   8    0    1    0    0 6234    0    1    0    0    0]\n",
            " [   4    0    0    0    0 6185    0    0    0    0    0]\n",
            " [   0    0    0    0    0    0    2    0    0 6286    0]\n",
            " [   1    0    0    0    1    0    0 6285    0    0    0]\n",
            " [   0    0    0    0    0    0    0    0 6309    0    0]\n",
            " [   0    0    0    0    0    0    0    0    0 6190    0]\n",
            " [   0    1    0    0    0    0   80    0    0 3774 2315]]\n",
            "Batch 133/237 - Batch Inference Time: 1.3891 seconds\n",
            "Testing Confusion Matrix:\n",
            " [[6167    0    0    0    0    4    0    3    0    0    0]\n",
            " [   0 5968  189    2    0    0    0    0    1    1    0]\n",
            " [   1  363 5741    1    0    0    0    0    2    0    0]\n",
            " [   1    0    0 6176    0    0    0    0    0    0    0]\n",
            " [   8    0    1    0    0 6288    0    1    0    0    0]\n",
            " [   4    0    0    0    0 6226    0    0    0    0    0]\n",
            " [   0    0    0    0    0    0    2    0    0 6322    0]\n",
            " [   1    0    0    0    1    0    0 6332    0    0    0]\n",
            " [   0    0    0    0    0    0    0    0 6345    0    0]\n",
            " [   0    0    0    0    0    0    0    0    0 6238    0]\n",
            " [   0    1    0    0    0    0   80    0    0 3803 2335]]\n",
            "Batch 134/237 - Batch Inference Time: 1.3004 seconds\n",
            "Testing Confusion Matrix:\n",
            " [[6218    0    0    0    0    4    0    3    0    0    0]\n",
            " [   0 6003  191    2    0    0    0    0    1    1    0]\n",
            " [   1  367 5784    1    0    0    0    0    2    0    0]\n",
            " [   1    0    0 6245    0    0    0    0    0    0    0]\n",
            " [   8    0    1    0    0 6329    0    1    0    0    0]\n",
            " [   4    0    0    0    0 6267    0    0    0    0    0]\n",
            " [   0    0    0    0    0    0    2    0    0 6368    0]\n",
            " [   1    0    0    0    1    0    0 6378    0    0    0]\n",
            " [   0    0    0    0    0    0    0    0 6392    0    0]\n",
            " [   0    0    0    0    0    0    0    0    0 6276    0]\n",
            " [   0    1    0    0    0    0   80    0    0 3830 2357]]\n",
            "Batch 135/237 - Batch Inference Time: 1.2936 seconds\n",
            "Testing Confusion Matrix:\n",
            " [[6268    0    0    0    0    4    0    3    0    0    0]\n",
            " [   0 6041  192    2    0    0    0    0    1    1    0]\n",
            " [   1  368 5842    1    0    0    0    0    2    0    0]\n",
            " [   1    0    0 6299    0    0    0    0    0    0    0]\n",
            " [   8    0    1    0    0 6380    0    1    0    0    0]\n",
            " [   4    0    0    0    0 6308    0    0    0    0    0]\n",
            " [   0    0    0    0    0    0    2    0    0 6419    0]\n",
            " [   1    0    0    0    1    0    0 6425    0    0    0]\n",
            " [   0    0    0    0    0    0    0    0 6433    0    0]\n",
            " [   0    0    0    0    0    0    0    0    0 6314    0]\n",
            " [   0    1    0    0    0    0   80    0    0 3858 2370]]\n",
            "Batch 136/237 - Batch Inference Time: 1.3770 seconds\n",
            "Testing Confusion Matrix:\n",
            " [[6320    0    0    0    0    4    0    3    0    0    0]\n",
            " [   0 6085  192    2    0    0    0    0    1    1    0]\n",
            " [   1  372 5885    1    0    0    0    0    2    0    0]\n",
            " [   1    0    0 6340    0    0    0    0    0    0    0]\n",
            " [   8    0    1    0    0 6434    0    1    0    0    0]\n",
            " [   5    0    0    0    0 6355    0    0    0    0    0]\n",
            " [   0    0    0    0    0    0    2    0    0 6469    0]\n",
            " [   1    0    0    0    1    0    0 6472    0    0    0]\n",
            " [   0    0    0    0    0    0    0    0 6477    0    0]\n",
            " [   0    0    0    0    0    0    0    0    0 6359    0]\n",
            " [   0    1    0    0    0    0   81    0    0 3879 2388]]\n",
            "Batch 137/237 - Batch Inference Time: 1.3322 seconds\n",
            "Testing Confusion Matrix:\n",
            " [[6367    0    0    0    0    4    0    3    0    0    0]\n",
            " [   0 6138  193    2    0    0    0    0    1    1    0]\n",
            " [   1  374 5930    1    0    0    0    0    2    0    0]\n",
            " [   1    0    0 6376    0    0    0    0    0    0    0]\n",
            " [   8    0    1    0    0 6468    0    1    0    0    0]\n",
            " [   5    0    0    0    0 6406    0    0    0    0    0]\n",
            " [   0    0    0    0    0    0    3    0    0 6513    0]\n",
            " [   1    0    0    0    1    0    0 6519    0    0    0]\n",
            " [   0    0    0    0    0    0    0    0 6523    0    0]\n",
            " [   0    0    0    0    0    0    0    0    0 6407    0]\n",
            " [   0    1    0    0    0    0   82    0    0 3912 2411]]\n",
            "Batch 138/237 - Batch Inference Time: 1.5854 seconds\n",
            "Testing Confusion Matrix:\n",
            " [[6410    0    0    0    0    4    0    3    0    0    0]\n",
            " [   0 6171  197    2    0    0    0    0    1    1    0]\n",
            " [   1  376 5970    1    0    0    0    0    2    0    0]\n",
            " [   1    0    0 6425    0    0    0    0    0    0    0]\n",
            " [   8    0    1    0    0 6523    0    1    0    0    0]\n",
            " [   5    0    0    0    0 6448    0    0    0    0    0]\n",
            " [   0    0    0    0    0    0    3    0    0 6570    0]\n",
            " [   1    0    0    0    1    0    0 6563    0    0    0]\n",
            " [   0    0    0    0    0    0    0    0 6568    0    0]\n",
            " [   0    0    0    0    0    0    0    0    0 6456    0]\n",
            " [   0    1    0    0    0    0   84    0    0 3943 2427]]\n",
            "Batch 139/237 - Batch Inference Time: 1.2958 seconds\n",
            "Testing Confusion Matrix:\n",
            " [[6453    0    0    0    0    4    0    3    0    0    0]\n",
            " [   0 6217  201    2    0    0    0    0    1    1    0]\n",
            " [   1  381 6015    1    0    0    0    0    2    0    0]\n",
            " [   1    0    0 6470    0    0    0    0    0    0    0]\n",
            " [   8    0    1    0    0 6570    0    1    0    0    0]\n",
            " [   5    0    0    0    0 6491    0    0    0    0    0]\n",
            " [   0    0    0    0    0    0    3    0    0 6618    0]\n",
            " [   1    0    0    0    1    0    0 6606    0    0    0]\n",
            " [   0    0    0    0    0    0    0    0 6605    0    0]\n",
            " [   0    0    0    0    0    0    0    0    0 6510    0]\n",
            " [   0    1    0    0    0    0   84    0    0 3977 2445]]\n",
            "Batch 140/237 - Batch Inference Time: 1.7865 seconds\n",
            "Testing Confusion Matrix:\n",
            " [[6502    0    0    0    0    4    0    3    0    0    0]\n",
            " [   0 6273  202    2    0    0    0    0    1    1    0]\n",
            " [   1  384 6068    1    0    0    0    0    2    0    0]\n",
            " [   1    0    0 6511    0    0    0    0    0    0    0]\n",
            " [   9    0    1    0    0 6615    0    1    0    0    0]\n",
            " [   5    0    0    0    0 6536    0    0    0    0    0]\n",
            " [   0    0    0    0    0    0    3    0    0 6667    0]\n",
            " [   1    0    0    0    1    0    0 6656    0    0    0]\n",
            " [   0    0    0    0    0    0    0    0 6643    0    0]\n",
            " [   0    0    0    0    0    0    0    0    0 6546    0]\n",
            " [   0    1    0    0    0    0   85    0    0 4003 2463]]\n",
            "Batch 141/237 - Batch Inference Time: 1.8052 seconds\n",
            "Testing Confusion Matrix:\n",
            " [[6541    0    0    0    0    4    0    3    0    0    0]\n",
            " [   0 6322  203    2    0    0    0    0    1    1    0]\n",
            " [   1  385 6102    1    0    0    0    0    2    0    0]\n",
            " [   1    0    0 6546    0    0    0    0    0    0    0]\n",
            " [   9    0    1    0    0 6676    0    1    0    0    0]\n",
            " [   5    0    0    0    0 6587    0    0    0    0    0]\n",
            " [   0    0    0    0    0    0    3    0    0 6712    0]\n",
            " [   1    0    0    0    1    0    0 6710    0    0    0]\n",
            " [   0    0    0    0    0    0    0    0 6692    0    0]\n",
            " [   0    0    0    0    0    0    0    0    0 6594    0]\n",
            " [   0    1    0    0    0    0   85    0    0 4030 2481]]\n",
            "Batch 142/237 - Batch Inference Time: 1.4158 seconds\n",
            "Testing Confusion Matrix:\n",
            " [[6590    0    0    0    0    4    0    3    0    0    0]\n",
            " [   0 6363  205    2    0    0    0    0    1    1    0]\n",
            " [   1  389 6141    1    0    0    0    0    2    0    0]\n",
            " [   1    0    0 6598    0    0    0    0    0    0    0]\n",
            " [   9    0    1    0    0 6720    0    1    0    0    0]\n",
            " [   5    0    0    0    0 6634    0    0    0    0    0]\n",
            " [   0    0    0    0    0    0    3    0    0 6758    0]\n",
            " [   1    0    0    0    1    0    0 6758    0    0    0]\n",
            " [   0    0    0    0    0    0    0    0 6733    0    0]\n",
            " [   0    0    0    0    0    0    0    0    0 6646    0]\n",
            " [   0    1    0    0    0    0   85    0    0 4063 2495]]\n",
            "Batch 143/237 - Batch Inference Time: 1.2997 seconds\n",
            "Testing Confusion Matrix:\n",
            " [[6630    0    0    0    0    4    0    3    0    0    0]\n",
            " [   0 6402  205    2    0    0    0    0    1    1    0]\n",
            " [   1  390 6199    1    0    0    0    0    2    0    0]\n",
            " [   1    0    0 6654    0    0    0    0    0    0    0]\n",
            " [   9    0    1    0    0 6773    0    1    0    0    0]\n",
            " [   5    0    0    0    0 6680    0    0    0    0    0]\n",
            " [   0    0    0    0    0    0    3    0    0 6803    0]\n",
            " [   1    0    0    0    1    0    0 6793    0    0    0]\n",
            " [   0    0    0    0    0    0    0    0 6786    0    0]\n",
            " [   0    0    0    0    0    0    0    0    0 6691    0]\n",
            " [   0    1    0    0    0    0   86    0    0 4084 2514]]\n",
            "Batch 144/237 - Batch Inference Time: 1.3877 seconds\n",
            "Testing Confusion Matrix:\n",
            " [[6675    0    0    0    0    4    0    3    0    0    0]\n",
            " [   0 6443  207    2    0    0    0    0    1    1    0]\n",
            " [   1  396 6240    1    0    0    0    0    2    0    0]\n",
            " [   1    0    0 6697    0    0    0    0    0    0    0]\n",
            " [   9    0    1    0    0 6821    0    1    0    0    0]\n",
            " [   5    0    0    0    0 6721    0    0    0    0    0]\n",
            " [   0    0    0    0    0    0    4    0    0 6843    0]\n",
            " [   1    0    0    0    1    0    0 6854    0    0    0]\n",
            " [   0    0    0    0    0    0    0    0 6843    0    0]\n",
            " [   0    0    0    0    0    0    0    0    0 6733    0]\n",
            " [   0    1    0    0    0    0   86    0    0 4111 2531]]\n",
            "Batch 145/237 - Batch Inference Time: 1.3099 seconds\n",
            "Testing Confusion Matrix:\n",
            " [[6717    0    0    0    0    4    0    3    0    0    0]\n",
            " [   0 6497  207    2    0    0    0    0    1    1    0]\n",
            " [   1  402 6279    1    0    0    0    0    2    0    0]\n",
            " [   1    0    0 6750    0    0    0    0    0    0    0]\n",
            " [   9    0    1    0    0 6869    0    1    0    0    0]\n",
            " [   5    0    0    0    0 6769    0    0    0    0    0]\n",
            " [   0    0    0    0    0    0    5    0    0 6883    0]\n",
            " [   1    0    0    0    1    0    0 6906    0    0    0]\n",
            " [   0    0    0    0    0    0    0    0 6889    0    0]\n",
            " [   0    0    0    0    0    0    0    0    0 6778    0]\n",
            " [   0    1    0    0    0    0   87    0    0 4135 2544]]\n",
            "Batch 146/237 - Batch Inference Time: 1.3732 seconds\n",
            "Testing Confusion Matrix:\n",
            " [[6755    0    0    0    0    4    0    3    0    0    0]\n",
            " [   0 6540  208    2    0    0    0    0    1    1    0]\n",
            " [   1  408 6329    1    0    0    0    0    2    0    0]\n",
            " [   1    0    0 6793    0    0    0    0    0    0    0]\n",
            " [   9    0    1    0    0 6919    0    1    0    0    0]\n",
            " [   5    0    0    0    0 6812    0    0    0    0    0]\n",
            " [   0    0    0    0    0    0    5    0    0 6924    0]\n",
            " [   1    0    0    0    1    0    0 6949    0    0    0]\n",
            " [   0    0    0    0    0    0    0    0 6927    0    0]\n",
            " [   0    0    0    0    0    0    0    0    0 6843    0]\n",
            " [   0    1    0    0    0    0   87    0    0 4169 2561]]\n",
            "Batch 147/237 - Batch Inference Time: 1.6037 seconds\n",
            "Testing Confusion Matrix:\n",
            " [[6802    0    0    0    0    4    0    3    0    0    0]\n",
            " [   0 6584  209    2    0    0    0    0    1    1    0]\n",
            " [   1  412 6379    1    0    0    0    0    2    0    0]\n",
            " [   1    0    0 6836    0    0    0    0    0    0    0]\n",
            " [   9    0    1    0    0 6967    0    1    0    0    0]\n",
            " [   5    0    0    0    0 6859    0    0    0    0    0]\n",
            " [   0    0    0    0    0    0    5    0    0 6959    0]\n",
            " [   1    0    0    0    1    0    0 6996    0    0    0]\n",
            " [   0    0    0    0    0    0    0    0 6988    0    0]\n",
            " [   0    0    0    0    0    0    0    0    0 6879    0]\n",
            " [   0    1    0    0    0    0   87    0    0 4199 2580]]\n",
            "Batch 148/237 - Batch Inference Time: 1.3143 seconds\n",
            "Testing Confusion Matrix:\n",
            " [[6855    0    0    0    0    4    0    3    0    0    0]\n",
            " [   0 6628  210    2    0    0    0    0    1    1    0]\n",
            " [   1  416 6433    1    0    0    0    0    2    0    0]\n",
            " [   1    0    0 6885    0    0    0    0    0    0    0]\n",
            " [   9    0    1    0    0 7017    0    1    0    0    0]\n",
            " [   5    0    0    0    0 6902    0    0    0    0    0]\n",
            " [   0    0    0    0    0    0    5    0    0 7003    0]\n",
            " [   1    0    0    0    1    0    0 7034    0    0    0]\n",
            " [   0    0    0    0    0    0    0    0 7032    0    0]\n",
            " [   0    0    0    0    0    0    0    0    0 6915    0]\n",
            " [   0    1    0    0    0    0   88    0    0 4229 2601]]\n",
            "Batch 149/237 - Batch Inference Time: 1.6119 seconds\n",
            "Testing Confusion Matrix:\n",
            " [[6905    0    0    0    0    4    0    3    0    0    0]\n",
            " [   0 6686  212    2    0    0    0    0    1    1    0]\n",
            " [   1  418 6478    1    0    0    0    0    2    0    0]\n",
            " [   1    0    0 6928    0    0    0    0    0    0    0]\n",
            " [  10    0    1    0    0 7055    0    1    0    0    0]\n",
            " [   5    0    0    0    0 6942    0    0    0    0    0]\n",
            " [   0    0    0    0    0    0    5    0    0 7051    0]\n",
            " [   1    0    0    0    1    0    0 7088    0    0    0]\n",
            " [   0    0    0    0    0    0    0    0 7079    0    0]\n",
            " [   0    0    0    0    0    0    0    0    0 6954    0]\n",
            " [   0    1    0    0    0    0   89    0    0 4251 2623]]\n",
            "Batch 150/237 - Batch Inference Time: 1.8200 seconds\n",
            "Testing Confusion Matrix:\n",
            " [[6945    0    0    0    0    4    0    3    0    0    0]\n",
            " [   0 6735  212    2    0    0    0    0    1    1    0]\n",
            " [   1  419 6528    1    0    0    0    0    2    0    0]\n",
            " [   1    0    0 6978    0    0    0    0    0    0    0]\n",
            " [  10    0    1    0    0 7100    0    1    0    0    0]\n",
            " [   5    0    0    0    0 6988    0    0    0    0    0]\n",
            " [   0    0    0    0    0    0    5    0    0 7097    0]\n",
            " [   1    0    0    0    1    0    0 7126    0    0    0]\n",
            " [   0    0    0    0    0    0    0    0 7119    0    0]\n",
            " [   0    0    0    0    0    0    0    0    0 7012    0]\n",
            " [   0    1    0    0    0    0   89    0    0 4280 2643]]\n",
            "Batch 151/237 - Batch Inference Time: 1.5620 seconds\n",
            "Testing Confusion Matrix:\n",
            " [[6994    0    0    0    0    4    0    3    0    0    0]\n",
            " [   0 6777  214    2    0    0    0    0    1    1    0]\n",
            " [   1  420 6559    1    0    0    0    0    2    0    0]\n",
            " [   1    0    0 7030    0    0    0    0    0    0    0]\n",
            " [  10    0    1    0    0 7151    0    1    0    0    0]\n",
            " [   5    0    0    0    0 7046    0    0    0    0    0]\n",
            " [   0    0    0    0    0    0    5    0    0 7141    0]\n",
            " [   1    0    0    0    1    0    0 7167    0    0    0]\n",
            " [   0    0    0    0    0    0    0    0 7163    0    0]\n",
            " [   0    0    0    0    0    0    0    0    0 7064    0]\n",
            " [   0    1    0    0    0    0   89    0    0 4312 2656]]\n",
            "Batch 152/237 - Batch Inference Time: 1.3364 seconds\n",
            "Testing Confusion Matrix:\n",
            " [[7041    0    0    0    0    4    0    3    0    0    0]\n",
            " [   0 6820  215    2    0    0    0    0    1    1    0]\n",
            " [   1  425 6611    1    0    0    0    0    2    0    0]\n",
            " [   1    0    0 7082    0    0    0    0    0    0    0]\n",
            " [  10    0    1    0    0 7195    0    1    0    0    0]\n",
            " [   5    0    0    0    0 7092    0    0    0    0    0]\n",
            " [   0    0    0    0    0    0    5    0    0 7175    0]\n",
            " [   1    0    0    0    1    0    0 7220    0    0    0]\n",
            " [   0    0    0    0    0    0    0    0 7209    0    0]\n",
            " [   0    0    0    0    0    0    0    0    0 7108    0]\n",
            " [   0    1    0    0    0    0   89    0    0 4336 2677]]\n",
            "Batch 153/237 - Batch Inference Time: 1.3148 seconds\n",
            "Testing Confusion Matrix:\n",
            " [[7104    0    0    0    0    4    0    3    0    0    0]\n",
            " [   0 6865  215    2    0    0    0    0    1    1    0]\n",
            " [   1  427 6662    1    0    0    0    0    2    0    0]\n",
            " [   1    0    0 7123    0    0    0    0    0    0    0]\n",
            " [  10    0    1    0    0 7238    0    1    0    0    0]\n",
            " [   5    0    0    0    0 7136    0    0    0    0    0]\n",
            " [   0    0    0    0    0    0    5    0    0 7211    0]\n",
            " [   1    0    0    0    1    0    0 7270    0    0    0]\n",
            " [   0    0    0    0    0    0    0    0 7258    0    0]\n",
            " [   0    0    0    0    0    0    0    0    0 7140    0]\n",
            " [   0    1    0    0    0    0   89    0    0 4371 2698]]\n",
            "Batch 154/237 - Batch Inference Time: 1.4176 seconds\n",
            "Testing Confusion Matrix:\n",
            " [[7162    0    0    0    0    4    0    3    0    0    0]\n",
            " [   0 6904  216    2    0    0    0    0    1    1    0]\n",
            " [   1  430 6710    1    0    0    0    0    2    0    0]\n",
            " [   1    0    0 7174    0    0    0    0    0    0    0]\n",
            " [  10    0    1    0    0 7275    0    1    0    0    0]\n",
            " [   5    0    0    0    0 7189    0    0    0    0    0]\n",
            " [   0    0    0    0    0    0    5    0    0 7260    0]\n",
            " [   1    0    0    0    1    0    0 7311    0    0    0]\n",
            " [   0    0    0    0    0    0    0    0 7290    0    0]\n",
            " [   0    0    0    0    0    0    0    0    0 7197    0]\n",
            " [   0    1    0    0    0    0   89    0    0 4402 2710]]\n",
            "Batch 155/237 - Batch Inference Time: 1.3169 seconds\n",
            "Testing Confusion Matrix:\n",
            " [[7201    0    0    0    0    4    0    3    0    0    0]\n",
            " [   0 6969  216    2    0    0    0    0    1    1    0]\n",
            " [   1  430 6742    1    0    0    0    0    2    0    0]\n",
            " [   1    0    0 7226    0    0    0    0    0    0    0]\n",
            " [  10    0    1    0    0 7328    0    1    0    0    0]\n",
            " [   5    0    0    0    0 7229    0    0    0    0    0]\n",
            " [   0    0    0    0    0    0    5    0    0 7307    0]\n",
            " [   1    0    0    0    1    0    0 7360    0    0    0]\n",
            " [   0    0    0    0    0    0    0    0 7339    0    0]\n",
            " [   0    0    0    0    0    0    0    0    0 7242    0]\n",
            " [   0    1    0    0    0    0   90    0    0 4427 2725]]\n",
            "Batch 156/237 - Batch Inference Time: 1.6505 seconds\n",
            "Testing Confusion Matrix:\n",
            " [[7241    0    0    0    0    4    0    3    0    0    0]\n",
            " [   0 7005  216    2    0    0    0    0    1    1    0]\n",
            " [   1  432 6783    1    0    0    0    0    2    0    0]\n",
            " [   1    0    0 7276    0    0    0    0    0    0    0]\n",
            " [  10    0    1    0    0 7366    0    1    0    0    0]\n",
            " [   6    0    0    0    0 7277    0    0    0    0    0]\n",
            " [   0    0    0    0    0    0    5    0    0 7353    0]\n",
            " [   1    0    0    0    1    0    0 7412    0    0    0]\n",
            " [   0    0    0    0    0    0    0    0 7385    0    0]\n",
            " [   0    0    0    0    0    0    0    0    0 7294    0]\n",
            " [   0    1    0    0    0    0   90    0    0 4470 2742]]\n",
            "Batch 157/237 - Batch Inference Time: 1.3112 seconds\n",
            "Testing Confusion Matrix:\n",
            " [[7285    0    0    0    0    4    0    3    0    0    0]\n",
            " [   0 7052  217    2    0    0    0    0    1    1    0]\n",
            " [   1  437 6828    1    0    0    0    0    2    0    0]\n",
            " [   1    0    0 7321    0    0    0    0    0    0    0]\n",
            " [  10    0    1    0    0 7414    0    1    0    0    0]\n",
            " [   6    0    0    0    0 7321    0    0    0    0    0]\n",
            " [   0    0    0    0    0    0    5    0    0 7388    0]\n",
            " [   1    0    0    0    1    0    0 7466    0    0    0]\n",
            " [   0    0    0    0    0    0    0    0 7432    0    0]\n",
            " [   0    0    0    0    0    0    0    0    0 7338    0]\n",
            " [   0    1    0    0    0    0   90    0    0 4499 2766]]\n",
            "Batch 158/237 - Batch Inference Time: 1.3717 seconds\n",
            "Testing Confusion Matrix:\n",
            " [[7328    0    0    0    0    4    0    3    0    0    0]\n",
            " [   0 7091  218    2    0    0    0    0    1    1    0]\n",
            " [   1  437 6871    1    0    0    0    0    2    0    0]\n",
            " [   1    0    0 7372    0    0    0    0    0    0    0]\n",
            " [  10    0    1    0    0 7461    0    1    0    0    0]\n",
            " [   6    0    0    0    0 7373    0    0    0    0    0]\n",
            " [   0    0    0    0    0    0    5    0    0 7429    0]\n",
            " [   1    0    0    0    1    0    0 7521    0    0    0]\n",
            " [   0    0    0    0    0    0    0    0 7471    0    0]\n",
            " [   0    0    0    0    0    0    0    0    0 7393    0]\n",
            " [   0    1    0    0    0    0   91    0    0 4528 2782]]\n",
            "Batch 159/237 - Batch Inference Time: 1.7638 seconds\n",
            "Testing Confusion Matrix:\n",
            " [[7383    0    0    0    0    4    0    3    0    0    0]\n",
            " [   0 7135  220    2    0    0    0    0    1    1    0]\n",
            " [   1  441 6910    1    0    0    0    0    2    0    0]\n",
            " [   1    0    0 7413    0    0    0    0    0    0    0]\n",
            " [  10    0    1    0    0 7512    0    1    0    0    0]\n",
            " [   6    0    0    0    0 7415    0    0    0    0    0]\n",
            " [   0    0    0    0    0    0    5    0    0 7484    0]\n",
            " [   1    0    0    0    1    0    0 7561    0    0    0]\n",
            " [   0    0    0    0    0    0    0    0 7515    0    0]\n",
            " [   0    0    0    0    0    0    0    0    0 7433    0]\n",
            " [   0    1    0    0    0    0   92    0    0 4563 2801]]\n",
            "Batch 160/237 - Batch Inference Time: 1.7648 seconds\n",
            "Testing Confusion Matrix:\n",
            " [[7432    0    0    0    0    4    0    3    0    0    0]\n",
            " [   0 7166  223    2    0    0    0    0    1    1    0]\n",
            " [   1  444 6951    1    0    0    0    0    2    0    0]\n",
            " [   1    0    0 7455    0    0    0    0    0    0    0]\n",
            " [  10    0    1    0    0 7554    0    1    0    0    0]\n",
            " [   6    0    0    0    0 7466    0    0    0    0    0]\n",
            " [   0    0    0    0    0    0    5    0    0 7532    0]\n",
            " [   1    0    0    0    1    0    0 7614    0    0    0]\n",
            " [   0    0    0    0    0    0    0    0 7562    0    0]\n",
            " [   0    0    0    0    0    0    0    0    0 7480    0]\n",
            " [   0    1    0    0    0    0   92    0    0 4603 2816]]\n",
            "Batch 161/237 - Batch Inference Time: 1.4074 seconds\n",
            "Testing Confusion Matrix:\n",
            " [[7485    0    0    0    0    4    0    3    0    0    0]\n",
            " [   0 7213  223    2    0    0    0    0    1    1    0]\n",
            " [   1  448 6987    2    0    0    0    0    2    0    0]\n",
            " [   1    0    0 7507    0    0    0    0    0    0    0]\n",
            " [  10    0    1    0    0 7600    0    1    0    0    0]\n",
            " [   7    0    0    0    0 7514    0    0    0    0    0]\n",
            " [   0    0    0    0    0    0    5    0    0 7582    0]\n",
            " [   1    0    0    0    1    0    0 7653    0    0    0]\n",
            " [   0    0    0    0    0    0    0    0 7616    0    0]\n",
            " [   0    0    0    0    0    0    0    0    0 7524    0]\n",
            " [   0    1    0    0    0    0   94    0    0 4631 2823]]\n",
            "Batch 162/237 - Batch Inference Time: 1.2809 seconds\n",
            "Testing Confusion Matrix:\n",
            " [[7529    0    0    0    0    4    0    3    0    0    0]\n",
            " [   0 7252  223    2    0    0    0    0    1    1    0]\n",
            " [   1  452 7034    2    0    0    0    0    2    0    0]\n",
            " [   1    0    0 7560    0    0    0    0    0    0    0]\n",
            " [  10    0    1    0    0 7645    0    1    0    0    0]\n",
            " [   7    0    0    0    0 7562    0    0    0    0    0]\n",
            " [   0    0    0    0    0    0    5    0    0 7626    0]\n",
            " [   1    0    0    0    1    0    0 7709    0    0    0]\n",
            " [   0    0    0    0    0    0    0    0 7665    0    0]\n",
            " [   0    0    0    0    0    0    0    0    0 7572    0]\n",
            " [   0    1    0    0    0    0   94    0    0 4644 2845]]\n",
            "Batch 163/237 - Batch Inference Time: 1.3482 seconds\n",
            "Testing Confusion Matrix:\n",
            " [[7579    0    0    0    0    4    0    3    0    0    0]\n",
            " [   0 7293  224    2    0    0    0    0    1    1    0]\n",
            " [   1  454 7083    2    0    0    0    0    2    0    0]\n",
            " [   1    0    0 7602    0    0    0    0    0    0    0]\n",
            " [  10    0    1    0    0 7690    0    1    0    0    0]\n",
            " [   7    0    0    0    0 7608    0    0    0    0    0]\n",
            " [   0    0    0    0    0    0    5    0    0 7663    0]\n",
            " [   1    0    0    0    1    0    0 7757    0    0    0]\n",
            " [   0    0    0    0    0    0    0    0 7710    0    0]\n",
            " [   0    0    0    0    0    0    0    0    0 7630    0]\n",
            " [   0    1    0    0    0    0   95    0    0 4673 2863]]\n",
            "Batch 164/237 - Batch Inference Time: 1.3841 seconds\n",
            "Testing Confusion Matrix:\n",
            " [[7625    0    0    0    0    4    0    3    0    0    0]\n",
            " [   0 7331  224    2    0    0    0    0    1    1    0]\n",
            " [   1  456 7127    2    0    0    0    0    2    0    0]\n",
            " [   1    0    0 7661    0    0    0    0    0    0    0]\n",
            " [  10    0    1    0    0 7728    0    1    0    0    0]\n",
            " [   7    0    0    0    0 7658    0    0    0    0    0]\n",
            " [   0    0    0    0    0    0    5    0    0 7708    0]\n",
            " [   1    0    0    0    1    0    0 7804    0    0    0]\n",
            " [   0    0    0    0    0    0    0    0 7765    0    0]\n",
            " [   0    0    0    0    0    0    0    0    0 7683    0]\n",
            " [   0    1    0    0    0    0   95    0    0 4693 2878]]\n",
            "Batch 165/237 - Batch Inference Time: 1.3283 seconds\n",
            "Testing Confusion Matrix:\n",
            " [[7664    0    0    0    0    4    0    3    0    0    0]\n",
            " [   0 7364  225    2    0    0    0    0    1    1    0]\n",
            " [   1  459 7175    2    0    0    0    0    2    0    0]\n",
            " [   1    0    0 7700    0    0    0    0    0    0    0]\n",
            " [  10    0    1    0    0 7770    0    1    0    0    0]\n",
            " [   7    0    0    0    0 7709    0    0    0    0    0]\n",
            " [   0    0    0    0    0    0    5    0    0 7770    0]\n",
            " [   1    0    0    0    1    0    0 7852    0    0    0]\n",
            " [   0    0    0    0    0    0    0    0 7809    0    0]\n",
            " [   0    0    0    0    0    0    1    0    0 7735    0]\n",
            " [   0    1    0    0    0    0   95    0    0 4723 2897]]\n",
            "Batch 166/237 - Batch Inference Time: 1.3572 seconds\n",
            "Testing Confusion Matrix:\n",
            " [[7718    0    0    0    0    4    0    3    0    0    0]\n",
            " [   0 7406  227    3    0    0    0    0    1    1    0]\n",
            " [   1  462 7212    2    0    0    0    0    2    0    0]\n",
            " [   1    0    0 7749    0    0    0    0    0    0    0]\n",
            " [  10    0    1    0    0 7812    0    1    0    0    0]\n",
            " [   7    0    0    0    0 7752    0    0    0    0    0]\n",
            " [   0    0    0    0    0    0    5    0    0 7816    0]\n",
            " [   1    0    0    0    1    0    0 7900    0    0    0]\n",
            " [   0    0    0    0    0    0    0    0 7847    0    0]\n",
            " [   0    0    0    0    0    0    1    0    0 7795    0]\n",
            " [   0    1    0    0    0    0   95    0    0 4754 2913]]\n",
            "Batch 167/237 - Batch Inference Time: 1.3930 seconds\n",
            "Testing Confusion Matrix:\n",
            " [[7762    0    0    0    0    4    0    3    0    0    0]\n",
            " [   0 7451  230    3    0    0    0    0    1    1    0]\n",
            " [   1  464 7253    2    0    0    0    0    2    0    0]\n",
            " [   1    0    0 7800    0    0    0    0    0    0    0]\n",
            " [  10    0    1    0    0 7856    0    1    0    0    0]\n",
            " [   7    0    0    0    0 7795    0    0    0    0    0]\n",
            " [   0    0    0    0    0    0    5    0    0 7868    0]\n",
            " [   1    0    0    0    1    0    0 7945    0    0    0]\n",
            " [   0    0    0    0    0    0    0    0 7898    0    0]\n",
            " [   0    0    0    0    0    0    1    0    0 7839    0]\n",
            " [   0    1    0    0    0    0   95    0    0 4783 2931]]\n",
            "Batch 168/237 - Batch Inference Time: 1.9980 seconds\n",
            "Testing Confusion Matrix:\n",
            " [[7805    0    0    0    0    4    0    3    0    0    0]\n",
            " [   0 7500  230    3    0    0    0    0    1    1    0]\n",
            " [   1  466 7305    2    0    0    0    0    2    0    0]\n",
            " [   1    0    0 7842    0    0    0    0    0    0    0]\n",
            " [  10    0    1    0    0 7893    0    1    0    0    0]\n",
            " [   7    0    0    0    0 7846    0    0    0    0    0]\n",
            " [   0    0    0    0    0    0    5    0    0 7926    0]\n",
            " [   1    0    0    0    1    0    0 7993    0    0    0]\n",
            " [   0    0    0    0    0    0    0    0 7941    0    0]\n",
            " [   0    0    0    0    0    0    1    0    0 7883    0]\n",
            " [   0    1    0    0    0    0   95    0    0 4808 2949]]\n",
            "Batch 169/237 - Batch Inference Time: 1.9311 seconds\n",
            "Testing Confusion Matrix:\n",
            " [[7850    0    0    0    0    4    0    3    0    0    0]\n",
            " [   0 7538  231    3    0    0    0    0    1    1    0]\n",
            " [   1  469 7355    2    0    0    0    0    2    0    0]\n",
            " [   1    0    0 7897    0    0    0    0    0    0    0]\n",
            " [  10    0    1    0    0 7930    0    1    0    0    0]\n",
            " [   7    0    0    0    0 7886    0    0    0    0    0]\n",
            " [   0    0    0    0    0    0    5    0    0 7971    0]\n",
            " [   1    0    0    0    1    0    0 8044    0    0    0]\n",
            " [   0    0    0    0    0    0    0    0 8000    0    0]\n",
            " [   0    0    0    0    0    0    1    0    0 7934    0]\n",
            " [   0    1    0    0    0    0   96    0    0 4829 2964]]\n",
            "Batch 170/237 - Batch Inference Time: 1.5204 seconds\n",
            "Testing Confusion Matrix:\n",
            " [[7898    0    0    0    0    4    0    3    0    0    0]\n",
            " [   0 7580  231    3    0    0    0    0    1    1    0]\n",
            " [   1  471 7397    2    0    0    0    0    2    0    0]\n",
            " [   1    0    0 7939    0    0    0    0    0    0    0]\n",
            " [  10    0    1    0    0 7971    0    1    0    0    0]\n",
            " [   7    0    0    0    0 7936    0    0    0    0    0]\n",
            " [   0    0    0    0    0    0    5    0    0 8028    0]\n",
            " [   1    0    0    0    1    0    0 8094    0    0    0]\n",
            " [   0    0    0    0    0    0    0    0 8045    0    0]\n",
            " [   0    0    0    0    0    0    1    0    0 7974    0]\n",
            " [   0    1    0    0    0    0   97    0    0 4859 2986]]\n",
            "Batch 171/237 - Batch Inference Time: 1.3651 seconds\n",
            "Testing Confusion Matrix:\n",
            " [[7947    0    0    0    0    4    0    3    0    0    0]\n",
            " [   0 7622  231    3    0    0    0    0    1    1    0]\n",
            " [   1  474 7442    2    0    0    0    0    2    0    0]\n",
            " [   1    0    0 7994    0    0    0    0    0    0    0]\n",
            " [  10    0    1    0    0 8014    0    1    0    0    0]\n",
            " [   7    0    0    0    0 7978    0    0    0    0    0]\n",
            " [   0    0    0    0    0    0    5    0    0 8063    0]\n",
            " [   1    0    0    0    1    0    0 8144    0    0    0]\n",
            " [   0    0    0    0    0    0    0    0 8091    0    0]\n",
            " [   0    0    0    0    0    0    1    0    0 8027    0]\n",
            " [   0    1    0    0    0    0   97    0    0 4897 2997]]\n",
            "Batch 172/237 - Batch Inference Time: 1.3845 seconds\n",
            "Testing Confusion Matrix:\n",
            " [[8001    0    0    0    0    4    0    3    0    0    0]\n",
            " [   0 7668  233    3    0    0    0    0    1    1    0]\n",
            " [   1  474 7495    2    0    0    0    0    2    0    0]\n",
            " [   1    0    0 8043    0    0    0    0    0    0    0]\n",
            " [  10    0    1    0    0 8064    0    1    0    0    0]\n",
            " [   7    0    0    0    0 8011    0    0    0    0    0]\n",
            " [   0    0    0    0    0    0    5    0    0 8104    0]\n",
            " [   1    0    0    0    1    0    0 8199    0    0    0]\n",
            " [   0    0    0    0    0    0    0    0 8135    0    0]\n",
            " [   0    0    0    0    0    0    1    0    0 8061    0]\n",
            " [   0    1    0    0    0    0   97    0    0 4932 3013]]\n",
            "Batch 173/237 - Batch Inference Time: 1.3984 seconds\n",
            "Testing Confusion Matrix:\n",
            " [[8041    0    0    0    0    4    0    3    0    0    0]\n",
            " [   0 7714  233    3    0    0    0    0    1    1    0]\n",
            " [   1  478 7534    2    0    0    0    0    2    0    0]\n",
            " [   1    0    0 8090    0    0    0    0    0    0    0]\n",
            " [  10    0    1    0    0 8120    0    1    0    0    0]\n",
            " [   7    0    0    0    0 8054    0    0    0    0    0]\n",
            " [   0    0    0    0    0    0    5    0    0 8137    0]\n",
            " [   1    0    0    0    1    0    0 8256    0    0    0]\n",
            " [   0    0    0    0    0    0    0    0 8191    0    0]\n",
            " [   0    0    0    0    0    0    1    0    0 8105    0]\n",
            " [   0    1    0    0    0    0   97    0    0 4962 3030]]\n",
            "Batch 174/237 - Batch Inference Time: 1.3889 seconds\n",
            "Testing Confusion Matrix:\n",
            " [[8079    0    0    0    0    4    0    3    0    0    0]\n",
            " [   0 7762  235    3    0    0    0    0    1    1    0]\n",
            " [   1  481 7578    2    0    0    0    0    2    0    0]\n",
            " [   1    0    0 8131    0    0    0    0    0    0    0]\n",
            " [  10    0    1    0    0 8163    0    1    0    0    0]\n",
            " [   7    0    0    0    0 8096    0    0    0    0    0]\n",
            " [   0    0    0    0    0    0    5    0    0 8198    0]\n",
            " [   1    0    0    0    1    0    0 8292    0    0    0]\n",
            " [   0    0    0    0    0    0    0    0 8241    0    0]\n",
            " [   0    0    0    0    0    0    1    0    0 8154    0]\n",
            " [   0    1    0    0    0    0  100    0    0 4996 3048]]\n",
            "Batch 175/237 - Batch Inference Time: 1.3598 seconds\n",
            "Testing Confusion Matrix:\n",
            " [[8116    0    0    0    0    4    0    3    0    0    0]\n",
            " [   0 7801  237    3    0    0    0    0    1    1    0]\n",
            " [   1  484 7630    2    0    0    0    0    2    0    0]\n",
            " [   1    0    0 8186    0    0    0    0    0    0    0]\n",
            " [  10    0    1    0    0 8213    0    1    0    0    0]\n",
            " [   7    0    0    0    0 8130    0    0    0    0    0]\n",
            " [   0    0    0    0    0    0    5    0    0 8245    0]\n",
            " [   1    0    0    0    1    0    0 8341    0    0    0]\n",
            " [   0    0    0    0    0    0    0    0 8289    0    0]\n",
            " [   0    0    0    0    0    0    1    0    0 8201    0]\n",
            " [   0    1    0    0    0    0  100    0    0 5026 3067]]\n",
            "Batch 176/237 - Batch Inference Time: 1.3764 seconds\n",
            "Testing Confusion Matrix:\n",
            " [[8156    0    0    0    0    4    0    3    0    0    0]\n",
            " [   0 7838  237    3    0    0    0    0    1    1    0]\n",
            " [   1  485 7682    2    0    0    0    0    2    0    0]\n",
            " [   1    0    0 8232    0    0    0    0    0    0    0]\n",
            " [  10    0    1    0    0 8253    0    1    0    0    0]\n",
            " [   7    0    0    0    0 8181    0    0    0    0    0]\n",
            " [   0    0    0    0    0    0    5    0    0 8294    0]\n",
            " [   1    0    0    0    1    0    0 8396    0    0    0]\n",
            " [   0    0    0    0    0    0    0    0 8332    0    0]\n",
            " [   0    0    0    0    0    0    1    0    0 8248    0]\n",
            " [   0    1    0    0    0    0  100    0    0 5054 3090]]\n",
            "Batch 177/237 - Batch Inference Time: 2.0159 seconds\n",
            "Testing Confusion Matrix:\n",
            " [[8196    0    0    0    0    4    0    3    0    0    0]\n",
            " [   0 7884  237    3    0    0    0    0    1    1    0]\n",
            " [   1  487 7717    2    0    0    0    0    2    0    0]\n",
            " [   1    0    0 8284    0    0    0    0    0    0    0]\n",
            " [  10    0    1    0    0 8300    0    1    0    0    0]\n",
            " [   7    0    0    0    0 8229    0    0    0    0    0]\n",
            " [   0    0    0    0    0    0    5    0    0 8349    0]\n",
            " [   1    0    0    0    1    0    0 8436    0    0    0]\n",
            " [   0    0    0    0    0    0    0    0 8383    0    0]\n",
            " [   0    0    0    0    0    0    1    0    0 8295    0]\n",
            " [   0    1    0    0    0    0  100    0    0 5082 3111]]\n",
            "Batch 178/237 - Batch Inference Time: 1.8010 seconds\n",
            "Testing Confusion Matrix:\n",
            " [[8242    0    0    0    0    4    0    3    0    0    0]\n",
            " [   0 7939  239    3    0    0    0    0    1    1    0]\n",
            " [   1  490 7762    2    0    0    0    0    2    0    0]\n",
            " [   1    0    0 8332    0    0    0    0    0    0    0]\n",
            " [  10    0    1    0    0 8345    0    1    0    0    0]\n",
            " [   7    0    0    0    0 8284    0    0    0    0    0]\n",
            " [   0    0    0    0    0    0    5    0    0 8392    0]\n",
            " [   1    0    0    0    1    0    0 8472    0    0    0]\n",
            " [   0    0    0    0    0    0    0    0 8427    0    0]\n",
            " [   0    0    0    0    0    0    1    0    0 8343    0]\n",
            " [   0    1    0    0    0    0  100    0    0 5106 3129]]\n",
            "Batch 179/237 - Batch Inference Time: 1.6416 seconds\n",
            "Testing Confusion Matrix:\n",
            " [[8292    0    0    0    0    4    0    3    0    0    0]\n",
            " [   0 7987  239    3    0    0    0    0    1    1    0]\n",
            " [   1  494 7809    2    0    0    0    0    2    0    0]\n",
            " [   1    0    0 8369    0    0    0    0    0    0    0]\n",
            " [  10    0    1    0    0 8382    0    1    0    0    0]\n",
            " [   7    0    0    0    0 8334    0    0    0    0    0]\n",
            " [   0    0    0    0    0    0    5    0    0 8452    0]\n",
            " [   1    0    0    0    1    0    0 8515    0    0    0]\n",
            " [   0    0    0    0    0    0    0    0 8467    0    0]\n",
            " [   0    0    0    0    0    0    1    0    0 8387    0]\n",
            " [   0    1    0    0    0    0  100    0    0 5143 3144]]\n",
            "Batch 180/237 - Batch Inference Time: 1.3113 seconds\n",
            "Testing Confusion Matrix:\n",
            " [[8352    0    0    0    0    4    0    3    0    0    0]\n",
            " [   0 8024  241    3    0    0    0    0    1    1    0]\n",
            " [   1  499 7851    2    0    0    0    0    2    0    0]\n",
            " [   1    0    0 8406    0    0    0    0    0    0    0]\n",
            " [  10    0    1    0    0 8423    0    1    0    0    0]\n",
            " [   7    0    0    0    0 8396    0    0    0    0    0]\n",
            " [   0    0    0    0    0    0    5    0    0 8495    0]\n",
            " [   1    0    0    0    1    0    0 8556    0    0    0]\n",
            " [   0    0    0    0    0    0    0    0 8507    0    0]\n",
            " [   0    0    0    0    0    0    1    0    0 8439    0]\n",
            " [   0    1    0    0    0    0  100    0    0 5178 3159]]\n",
            "Batch 181/237 - Batch Inference Time: 1.3175 seconds\n",
            "Testing Confusion Matrix:\n",
            " [[8405    0    0    0    0    4    0    3    0    0    0]\n",
            " [   0 8061  242    3    0    0    0    0    1    1    0]\n",
            " [   1  503 7895    2    0    0    0    0    2    0    0]\n",
            " [   1    0    0 8455    0    0    0    0    0    0    0]\n",
            " [  10    0    1    0    0 8458    0    1    0    0    0]\n",
            " [   7    0    0    0    0 8446    0    0    0    0    0]\n",
            " [   0    0    0    0    0    0    5    0    0 8544    0]\n",
            " [   1    0    0    0    1    0    0 8605    0    0    0]\n",
            " [   0    0    0    0    0    0    0    0 8553    0    0]\n",
            " [   0    0    0    0    0    0    1    0    0 8486    0]\n",
            " [   0    1    0    0    0    0  101    0    0 5207 3177]]\n",
            "Batch 182/237 - Batch Inference Time: 1.3974 seconds\n",
            "Testing Confusion Matrix:\n",
            " [[8459    0    0    0    0    4    0    3    0    0    0]\n",
            " [   0 8101  242    3    0    0    0    0    1    1    0]\n",
            " [   1  506 7944    2    0    0    0    0    2    0    0]\n",
            " [   1    0    0 8491    0    0    0    0    0    0    0]\n",
            " [  10    0    1    0    0 8523    0    1    0    0    0]\n",
            " [   7    0    0    0    0 8485    0    0    0    0    0]\n",
            " [   0    0    0    0    0    0    5    0    0 8591    0]\n",
            " [   1    0    0    0    1    0    0 8650    0    0    0]\n",
            " [   0    0    0    0    0    0    0    0 8596    0    0]\n",
            " [   0    0    0    0    0    0    1    0    0 8528    0]\n",
            " [   0    1    0    0    0    0  101    0    0 5236 3197]]\n",
            "Batch 183/237 - Batch Inference Time: 1.2945 seconds\n",
            "Testing Confusion Matrix:\n",
            " [[8513    0    0    0    0    4    0    3    0    0    0]\n",
            " [   0 8152  242    3    0    0    0    0    1    1    0]\n",
            " [   1  509 7991    2    0    0    0    0    2    0    0]\n",
            " [   1    0    0 8536    0    0    0    0    0    0    0]\n",
            " [  10    0    1    0    0 8565    0    1    0    0    0]\n",
            " [   7    0    0    0    0 8528    0    0    0    0    0]\n",
            " [   0    0    0    0    0    0    5    0    0 8634    0]\n",
            " [   1    0    0    0    1    0    0 8695    0    0    0]\n",
            " [   0    0    0    0    0    0    0    0 8633    0    0]\n",
            " [   0    0    0    0    0    0    1    0    0 8581    0]\n",
            " [   0    1    0    0    0    0  102    0    0 5268 3213]]\n",
            "Batch 184/237 - Batch Inference Time: 1.3404 seconds\n",
            "Testing Confusion Matrix:\n",
            " [[8567    0    0    0    0    4    0    3    0    0    0]\n",
            " [   0 8201  244    3    0    0    0    0    1    1    0]\n",
            " [   1  511 8027    2    0    0    0    0    2    0    0]\n",
            " [   1    0    0 8585    0    0    0    0    0    0    0]\n",
            " [  10    0    1    0    0 8606    0    1    0    0    0]\n",
            " [   7    0    0    0    0 8555    0    0    0    0    0]\n",
            " [   0    0    0    0    0    0    5    0    0 8685    0]\n",
            " [   1    0    0    0    1    0    0 8746    0    0    0]\n",
            " [   0    0    0    0    0    0    0    0 8686    0    0]\n",
            " [   0    0    0    0    0    0    1    0    0 8625    0]\n",
            " [   0    1    0    0    0    0  102    0    0 5303 3231]]\n",
            "Batch 185/237 - Batch Inference Time: 1.4389 seconds\n",
            "Testing Confusion Matrix:\n",
            " [[8610    0    0    0    0    4    0    3    0    0    0]\n",
            " [   0 8255  246    3    0    0    0    0    1    1    0]\n",
            " [   1  513 8074    2    0    0    0    0    2    0    0]\n",
            " [   1    0    0 8630    0    0    0    0    0    0    0]\n",
            " [  10    0    1    0    0 8648    0    1    0    0    0]\n",
            " [   7    0    0    0    0 8605    0    0    0    0    0]\n",
            " [   0    0    0    0    0    0    5    0    0 8726    0]\n",
            " [   1    0    0    0    1    0    0 8780    0    0    0]\n",
            " [   0    0    0    0    0    0    0    0 8735    0    0]\n",
            " [   0    0    0    0    0    0    1    0    0 8680    0]\n",
            " [   0    1    0    0    0    0  102    0    0 5332 3250]]\n",
            "Batch 186/237 - Batch Inference Time: 1.5314 seconds\n",
            "Testing Confusion Matrix:\n",
            " [[8659    0    0    0    0    4    0    3    0    0    0]\n",
            " [   0 8295  246    3    0    0    0    0    1    1    0]\n",
            " [   1  516 8127    2    0    0    0    0    2    0    0]\n",
            " [   1    0    0 8678    0    0    0    0    0    0    0]\n",
            " [  10    0    1    0    0 8682    0    1    0    0    0]\n",
            " [   7    0    0    0    0 8644    0    0    0    0    0]\n",
            " [   0    0    0    0    0    0    5    0    0 8774    0]\n",
            " [   1    0    0    0    1    0    0 8830    0    0    0]\n",
            " [   0    0    0    0    0    0    0    0 8779    0    0]\n",
            " [   0    0    0    0    0    0    1    0    0 8729    0]\n",
            " [   0    1    0    0    0    0  102    0    0 5367 3270]]\n",
            "Batch 187/237 - Batch Inference Time: 2.0253 seconds\n",
            "Testing Confusion Matrix:\n",
            " [[8717    0    0    0    0    4    0    3    0    0    0]\n",
            " [   0 8343  246    3    0    0    0    0    1    1    0]\n",
            " [   1  520 8181    2    0    0    0    0    2    0    0]\n",
            " [   1    0    0 8711    0    0    0    0    0    0    0]\n",
            " [  10    0    1    0    0 8728    0    1    0    0    0]\n",
            " [   7    0    0    0    0 8691    0    0    0    0    0]\n",
            " [   0    0    0    0    0    0    5    0    0 8818    0]\n",
            " [   1    0    0    0    1    0    0 8880    0    0    0]\n",
            " [   0    0    0    0    0    0    0    0 8811    0    0]\n",
            " [   0    0    0    0    0    0    1    0    0 8779    0]\n",
            " [   0    1    0    0    0    0  103    0    0 5393 3289]]\n",
            "Batch 188/237 - Batch Inference Time: 1.8912 seconds\n",
            "Testing Confusion Matrix:\n",
            " [[8760    0    0    0    0    4    0    3    0    0    0]\n",
            " [   0 8395  248    3    0    0    0    0    1    1    0]\n",
            " [   1  522 8230    2    0    0    0    0    2    0    0]\n",
            " [   1    0    0 8747    0    0    0    0    0    0    0]\n",
            " [  10    0    1    0    0 8767    0    1    0    0    0]\n",
            " [   7    0    0    0    0 8738    0    0    0    0    0]\n",
            " [   0    0    0    0    0    0    5    0    0 8866    0]\n",
            " [   1    0    0    0    1    0    0 8933    0    0    0]\n",
            " [   0    0    0    0    0    0    0    0 8854    0    0]\n",
            " [   0    0    0    0    0    0    1    0    0 8828    0]\n",
            " [   0    1    0    0    0    0  103    0    0 5420 3311]]\n",
            "Batch 189/237 - Batch Inference Time: 1.3772 seconds\n",
            "Testing Confusion Matrix:\n",
            " [[8805    0    0    0    0    4    0    3    0    0    0]\n",
            " [   0 8439  248    3    0    0    0    0    1    1    0]\n",
            " [   1  524 8287    2    0    0    0    0    2    0    0]\n",
            " [   1    0    0 8793    0    0    0    0    0    0    0]\n",
            " [  10    0    1    0    0 8807    0    1    0    0    0]\n",
            " [   7    0    0    0    0 8774    0    0    0    0    0]\n",
            " [   0    0    0    0    0    0    5    0    0 8903    0]\n",
            " [   1    0    0    0    1    0    0 8984    0    0    0]\n",
            " [   0    0    0    0    0    0    0    0 8911    0    0]\n",
            " [   0    0    0    0    0    0    1    0    0 8876    0]\n",
            " [   0    1    0    0    0    0  103    0    0 5447 3333]]\n",
            "Batch 190/237 - Batch Inference Time: 1.4001 seconds\n",
            "Testing Confusion Matrix:\n",
            " [[8851    0    0    0    0    4    0    3    0    0    0]\n",
            " [   0 8489  249    3    0    0    0    0    1    1    0]\n",
            " [   1  525 8341    2    0    0    0    0    2    0    0]\n",
            " [   1    0    0 8831    0    0    0    0    0    0    0]\n",
            " [  10    0    1    0    0 8853    0    1    0    0    0]\n",
            " [   7    0    0    0    0 8826    0    0    0    0    0]\n",
            " [   0    0    0    0    0    0    5    0    0 8957    0]\n",
            " [   1    0    0    0    1    0    0 9041    0    0    0]\n",
            " [   0    0    0    0    0    0    0    0 8944    0    0]\n",
            " [   0    0    0    0    0    0    1    0    0 8916    0]\n",
            " [   0    1    0    0    0    0  104    0    0 5477 3342]]\n",
            "Batch 191/237 - Batch Inference Time: 1.3786 seconds\n",
            "Testing Confusion Matrix:\n",
            " [[8901    0    0    0    0    4    0    3    0    0    0]\n",
            " [   0 8542  252    3    0    0    0    0    1    1    0]\n",
            " [   1  531 8390    2    0    0    0    0    2    0    0]\n",
            " [   1    0    0 8873    0    0    0    0    0    0    0]\n",
            " [  10    0    1    0    0 8893    0    1    0    0    0]\n",
            " [   7    0    0    0    0 8874    0    0    0    0    0]\n",
            " [   0    0    0    0    0    0    5    0    0 9010    0]\n",
            " [   1    0    0    0    1    0    0 9081    0    0    0]\n",
            " [   0    0    0    0    0    0    0    0 8987    0    0]\n",
            " [   0    0    0    0    0    0    1    0    0 8960    0]\n",
            " [   0    1    0    0    0    0  106    0    0 5500 3358]]\n",
            "Batch 192/237 - Batch Inference Time: 1.3696 seconds\n",
            "Testing Confusion Matrix:\n",
            " [[8945    0    0    0    0    4    0    3    0    0    0]\n",
            " [   0 8587  254    3    0    0    0    0    1    1    0]\n",
            " [   1  533 8420    2    0    0    0    0    2    0    0]\n",
            " [   1    0    0 8915    0    0    0    0    0    0    0]\n",
            " [  10    0    1    0    0 8947    0    1    0    0    0]\n",
            " [   7    0    0    0    0 8916    0    0    0    0    0]\n",
            " [   0    0    0    0    0    0    5    0    0 9062    0]\n",
            " [   1    0    0    0    1    0    0 9128    0    0    0]\n",
            " [   0    0    0    0    0    0    0    0 9033    0    0]\n",
            " [   0    0    0    0    0    0    1    0    0 9009    0]\n",
            " [   0    1    0    0    0    0  107    0    0 5535 3379]]\n",
            "Batch 193/237 - Batch Inference Time: 1.2914 seconds\n",
            "Testing Confusion Matrix:\n",
            " [[8985    0    0    0    0    4    0    3    0    0    0]\n",
            " [   0 8626  257    3    0    0    0    0    1    1    0]\n",
            " [   1  533 8467    2    0    0    0    0    2    0    0]\n",
            " [   1    0    0 8966    0    0    0    0    0    0    0]\n",
            " [  10    0    1    0    0 9000    0    1    0    0    0]\n",
            " [   7    0    0    0    0 8958    0    0    0    0    0]\n",
            " [   0    0    0    0    0    0    5    0    0 9116    0]\n",
            " [   1    0    0    0    1    0    0 9179    0    0    0]\n",
            " [   0    0    0    0    0    0    0    0 9075    0    0]\n",
            " [   0    0    0    0    0    0    1    0    0 9056    0]\n",
            " [   0    1    0    0    0    0  107    0    0 5564 3393]]\n",
            "Batch 194/237 - Batch Inference Time: 1.3841 seconds\n",
            "Testing Confusion Matrix:\n",
            " [[9032    0    0    0    0    4    0    3    0    0    0]\n",
            " [   0 8666  260    3    0    0    0    0    1    1    0]\n",
            " [   1  538 8510    2    0    0    0    0    2    0    0]\n",
            " [   1    0    0 9011    0    0    0    0    0    0    0]\n",
            " [  10    0    1    0    0 9041    0    1    0    0    0]\n",
            " [   7    0    0    0    0 9006    0    0    0    0    0]\n",
            " [   0    0    0    0    0    0    5    0    0 9164    0]\n",
            " [   1    0    0    0    1    0    0 9224    0    0    0]\n",
            " [   0    0    0    0    0    0    0    0 9116    0    0]\n",
            " [   0    0    0    0    0    0    1    0    0 9106    0]\n",
            " [   0    1    0    0    0    0  107    0    0 5596 3417]]\n",
            "Batch 195/237 - Batch Inference Time: 1.4887 seconds\n",
            "Testing Confusion Matrix:\n",
            " [[9069    0    0    0    0    4    0    3    0    0    0]\n",
            " [   0 8717  264    3    0    0    0    0    1    1    0]\n",
            " [   1  541 8548    2    0    0    0    0    2    0    0]\n",
            " [   1    0    0 9058    0    0    0    0    0    0    0]\n",
            " [  10    0    1    0    0 9080    0    1    0    0    0]\n",
            " [   7    0    0    0    0 9057    0    0    0    0    0]\n",
            " [   0    0    0    0    0    0    5    0    0 9210    0]\n",
            " [   1    0    0    0    1    0    0 9276    0    0    0]\n",
            " [   0    0    0    0    0    0    0    0 9170    0    0]\n",
            " [   0    0    0    0    0    0    1    0    0 9156    0]\n",
            " [   0    1    0    0    0    0  107    0    0 5619 3434]]\n",
            "Batch 196/237 - Batch Inference Time: 1.8060 seconds\n",
            "Testing Confusion Matrix:\n",
            " [[9123    0    0    0    0    4    0    3    0    0    0]\n",
            " [   0 8765  264    3    0    0    0    0    1    1    0]\n",
            " [   1  541 8603    2    0    0    0    0    2    0    0]\n",
            " [   1    0    0 9104    0    0    0    0    0    0    0]\n",
            " [  10    0    1    0    0 9126    0    1    0    0    0]\n",
            " [   7    0    0    0    0 9096    0    0    0    0    0]\n",
            " [   0    0    0    0    0    0    6    0    0 9254    0]\n",
            " [   1    0    0    0    1    0    0 9322    0    0    0]\n",
            " [   0    0    0    0    0    0    0    0 9217    0    0]\n",
            " [   0    0    0    0    0    0    1    0    0 9200    0]\n",
            " [   0    1    0    0    0    0  107    0    0 5645 3450]]\n",
            "Batch 197/237 - Batch Inference Time: 1.9676 seconds\n",
            "Testing Confusion Matrix:\n",
            " [[9170    0    0    0    0    4    0    3    0    0    0]\n",
            " [   0 8800  266    3    0    0    0    0    1    1    0]\n",
            " [   1  546 8649    2    0    0    0    0    2    0    0]\n",
            " [   1    0    0 9157    0    0    0    0    0    0    0]\n",
            " [  10    0    1    0    0 9155    0    1    0    0    0]\n",
            " [   7    0    0    0    0 9132    0    0    0    0    0]\n",
            " [   0    0    0    0    0    0    6    0    0 9298    0]\n",
            " [   1    0    0    0    1    0    0 9378    0    0    0]\n",
            " [   0    0    0    0    0    0    0    0 9280    0    0]\n",
            " [   0    0    0    0    0    0    1    0    0 9256    0]\n",
            " [   0    1    0    0    0    0  107    0    0 5671 3464]]\n",
            "Batch 198/237 - Batch Inference Time: 1.3479 seconds\n",
            "Testing Confusion Matrix:\n",
            " [[9222    0    0    0    0    4    0    3    0    0    0]\n",
            " [   0 8838  266    3    0    0    0    0    1    1    0]\n",
            " [   1  550 8688    2    0    0    0    0    2    0    0]\n",
            " [   1    0    0 9206    0    0    0    0    0    0    0]\n",
            " [  10    0    1    0    0 9201    0    1    0    0    0]\n",
            " [   7    0    0    0    0 9171    0    0    0    0    0]\n",
            " [   0    0    0    0    0    0    6    0    0 9334    0]\n",
            " [   1    0    0    0    1    0    0 9431    0    0    0]\n",
            " [   0    0    0    0    0    0    0    0 9334    0    0]\n",
            " [   0    0    0    0    0    0    1    0    0 9309    0]\n",
            " [   0    1    0    0    0    0  107    0    0 5705 3479]]\n",
            "Batch 199/237 - Batch Inference Time: 1.3276 seconds\n",
            "Testing Confusion Matrix:\n",
            " [[9275    0    0    0    0    4    0    3    0    0    0]\n",
            " [   0 8878  270    3    0    0    0    0    1    1    0]\n",
            " [   1  551 8732    2    0    0    0    0    2    0    0]\n",
            " [   1    0    0 9249    0    0    0    0    0    0    0]\n",
            " [  10    0    1    0    0 9244    0    1    0    0    0]\n",
            " [   7    0    0    0    0 9208    0    0    0    0    0]\n",
            " [   0    0    0    0    0    0    6    0    0 9386    0]\n",
            " [   1    0    0    0    1    0    0 9481    0    0    0]\n",
            " [   0    0    0    0    0    0    0    0 9377    0    0]\n",
            " [   0    0    0    0    0    0    1    0    0 9361    0]\n",
            " [   0    1    0    0    0    0  107    0    0 5738 3496]]\n",
            "Batch 200/237 - Batch Inference Time: 1.3873 seconds\n",
            "Testing Confusion Matrix:\n",
            " [[9326    0    0    0    0    4    0    3    0    0    0]\n",
            " [   0 8918  272    3    0    0    0    0    1    1    0]\n",
            " [   1  553 8766    2    0    0    0    0    2    0    0]\n",
            " [   1    0    0 9293    0    0    0    0    0    0    0]\n",
            " [  10    0    1    0    0 9291    0    1    0    0    0]\n",
            " [   7    0    0    0    0 9255    0    0    0    0    0]\n",
            " [   0    0    0    0    0    0    6    0    0 9431    0]\n",
            " [   1    0    0    0    1    0    0 9535    0    0    0]\n",
            " [   0    0    0    0    0    0    0    0 9434    0    0]\n",
            " [   0    0    0    0    0    0    1    0    0 9405    0]\n",
            " [   0    1    0    0    0    0  107    0    0 5765 3514]]\n",
            "Batch 201/237 - Batch Inference Time: 1.3955 seconds\n",
            "Testing Confusion Matrix:\n",
            " [[9381    0    0    0    0    4    0    3    0    0    0]\n",
            " [   0 8980  273    3    0    0    0    0    1    1    0]\n",
            " [   1  556 8804    2    0    0    0    0    2    0    0]\n",
            " [   1    0    0 9343    0    0    0    0    0    0    0]\n",
            " [  10    0    1    0    0 9332    0    1    0    0    0]\n",
            " [   7    0    0    0    0 9310    0    0    0    0    0]\n",
            " [   0    0    0    0    0    0    6    0    0 9469    0]\n",
            " [   1    0    0    0    1    0    0 9579    0    0    0]\n",
            " [   0    0    0    0    0    0    0    0 9471    0    0]\n",
            " [   0    0    0    0    0    0    1    0    0 9447    0]\n",
            " [   0    1    0    0    0    0  108    0    0 5790 3534]]\n",
            "Batch 202/237 - Batch Inference Time: 1.3013 seconds\n",
            "Testing Confusion Matrix:\n",
            " [[9429    0    0    0    0    4    0    3    0    0    0]\n",
            " [   0 9027  274    3    0    0    0    0    1    1    0]\n",
            " [   1  561 8854    2    0    0    0    0    2    0    0]\n",
            " [   1    0    0 9382    0    0    0    0    0    0    0]\n",
            " [  10    0    1    0    0 9385    0    1    0    0    0]\n",
            " [   7    0    0    0    0 9355    0    0    0    0    0]\n",
            " [   0    0    0    0    0    0    6    0    0 9511    0]\n",
            " [   1    0    0    0    1    0    0 9627    0    0    0]\n",
            " [   0    0    0    0    0    0    0    0 9519    0    0]\n",
            " [   0    0    0    0    0    0    1    0    0 9489    0]\n",
            " [   0    1    0    0    0    0  108    0    0 5818 3550]]\n",
            "Batch 203/237 - Batch Inference Time: 1.3561 seconds\n",
            "Testing Confusion Matrix:\n",
            " [[9478    0    0    0    0    4    0    3    0    0    0]\n",
            " [   0 9063  274    3    0    0    0    0    1    1    0]\n",
            " [   1  565 8888    2    0    0    0    0    2    0    0]\n",
            " [   1    0    0 9430    0    0    0    0    0    0    0]\n",
            " [  10    0    1    0    0 9438    0    1    0    0    0]\n",
            " [   7    0    0    0    0 9401    0    0    0    0    0]\n",
            " [   0    0    0    0    0    0    6    0    0 9558    0]\n",
            " [   1    0    0    0    1    0    0 9675    0    0    0]\n",
            " [   0    0    0    0    0    0    0    0 9567    0    0]\n",
            " [   0    0    0    0    0    0    1    0    0 9537    0]\n",
            " [   0    1    0    0    0    0  109    0    0 5851 3567]]\n",
            "Batch 204/237 - Batch Inference Time: 1.3198 seconds\n",
            "Testing Confusion Matrix:\n",
            " [[9526    0    0    0    0    4    0    3    0    0    0]\n",
            " [   0 9105  274    3    0    0    0    0    1    1    0]\n",
            " [   1  565 8934    2    0    0    0    0    2    0    0]\n",
            " [   1    0    0 9472    0    0    0    0    0    0    0]\n",
            " [  10    0    1    0    0 9490    0    1    0    0    0]\n",
            " [   7    0    0    0    0 9459    0    0    0    0    0]\n",
            " [   0    0    0    0    0    0    6    0    0 9604    0]\n",
            " [   1    0    0    0    1    0    0 9721    0    0    0]\n",
            " [   0    0    0    0    0    0    0    0 9605    0    0]\n",
            " [   0    0    0    0    0    0    1    0    0 9585    0]\n",
            " [   0    1    0    0    0    0  109    0    0 5887 3577]]\n",
            "Batch 205/237 - Batch Inference Time: 1.9971 seconds\n",
            "Testing Confusion Matrix:\n",
            " [[9578    0    0    0    0    4    0    3    0    0    0]\n",
            " [   0 9156  276    3    0    0    0    0    1    1    0]\n",
            " [   1  567 8986    2    0    0    0    0    2    0    0]\n",
            " [   1    0    0 9509    0    0    0    0    0    0    0]\n",
            " [  10    0    1    0    0 9529    0    1    0    0    0]\n",
            " [   7    0    0    0    0 9512    0    0    0    0    0]\n",
            " [   0    0    0    0    0    0    6    0    0 9647    0]\n",
            " [   1    0    0    0    1    0    0 9774    0    0    0]\n",
            " [   0    0    0    0    0    0    0    0 9647    0    0]\n",
            " [   0    0    0    0    0    0    1    0    0 9637    0]\n",
            " [   0    1    0    0    0    0  109    0    0 5911 3587]]\n",
            "Batch 206/237 - Batch Inference Time: 1.8267 seconds\n",
            "Testing Confusion Matrix:\n",
            " [[9619    0    0    0    0    4    0    3    0    0    0]\n",
            " [   0 9215  277    3    0    0    0    0    1    1    0]\n",
            " [   1  568 9023    2    0    0    0    0    2    0    0]\n",
            " [   1    0    0 9553    0    0    0    0    0    0    0]\n",
            " [  10    0    1    0    0 9575    0    1    0    0    0]\n",
            " [   7    0    0    0    0 9564    0    0    0    0    0]\n",
            " [   0    0    0    0    0    0    6    0    0 9690    0]\n",
            " [   1    0    0    0    1    0    0 9811    0    0    0]\n",
            " [   0    0    0    0    0    0    0    0 9691    0    0]\n",
            " [   0    0    0    0    0    0    1    0    0 9690    0]\n",
            " [   0    1    0    0    0    0  109    0    0 5941 3611]]\n",
            "Batch 207/237 - Batch Inference Time: 1.6022 seconds\n",
            "Testing Confusion Matrix:\n",
            " [[9677    0    0    0    0    4    0    3    0    0    0]\n",
            " [   0 9257  277    3    0    0    0    0    1    1    0]\n",
            " [   1  571 9060    2    0    0    0    0    2    0    0]\n",
            " [   1    0    0 9591    0    0    0    0    0    0    0]\n",
            " [  10    0    1    0    0 9613    0    1    0    0    0]\n",
            " [   7    0    0    0    0 9613    0    0    0    0    0]\n",
            " [   0    0    0    0    0    0    6    0    0 9738    0]\n",
            " [   1    0    0    0    1    0    0 9859    0    0    0]\n",
            " [   0    0    0    0    0    0    0    0 9741    0    0]\n",
            " [   0    0    0    0    0    0    1    0    0 9739    0]\n",
            " [   0    1    0    0    0    0  111    0    0 5976 3626]]\n",
            "Batch 208/237 - Batch Inference Time: 1.3721 seconds\n",
            "Testing Confusion Matrix:\n",
            " [[9722    0    0    0    0    4    0    3    0    0    0]\n",
            " [   0 9309  280    3    0    0    0    0    1    1    0]\n",
            " [   1  574 9108    2    0    0    0    0    2    0    0]\n",
            " [   1    0    0 9632    0    0    0    0    0    0    0]\n",
            " [  10    0    1    0    0 9658    0    1    0    0    0]\n",
            " [   7    0    0    0    0 9662    0    0    0    0    0]\n",
            " [   0    0    0    0    0    0    6    0    0 9775    0]\n",
            " [   1    0    0    0    1    0    0 9907    0    0    0]\n",
            " [   0    0    0    0    0    0    0    0 9780    0    0]\n",
            " [   0    0    0    0    0    0    1    0    0 9791    0]\n",
            " [   0    1    0    0    0    0  111    0    0 6006 3646]]\n",
            "Batch 209/237 - Batch Inference Time: 1.3125 seconds\n",
            "Testing Confusion Matrix:\n",
            " [[9761    0    0    0    0    4    0    3    0    0    0]\n",
            " [   0 9361  281    3    0    0    0    0    1    1    0]\n",
            " [   1  575 9156    3    0    0    0    0    2    0    0]\n",
            " [   1    0    0 9683    0    0    0    0    0    0    0]\n",
            " [  10    0    1    0    0 9705    0    1    0    0    0]\n",
            " [   7    0    0    0    0 9709    0    0    0    0    0]\n",
            " [   0    0    0    0    0    0    6    0    0 9819    0]\n",
            " [   1    0    0    0    1    0    0 9956    0    0    0]\n",
            " [   0    0    0    0    0    0    0    0 9823    0    0]\n",
            " [   0    0    0    0    0    0    1    0    0 9833    0]\n",
            " [   0    1    0    0    0    0  112    0    0 6038 3660]]\n",
            "Batch 210/237 - Batch Inference Time: 1.3328 seconds\n",
            "Testing Confusion Matrix:\n",
            " [[ 9807     0     0     0     0     4     0     3     0     0     0]\n",
            " [    0  9411   281     3     0     0     0     0     1     1     0]\n",
            " [    1   580  9197     3     0     0     0     0     2     0     0]\n",
            " [    1     0     0  9726     0     0     0     0     0     0     0]\n",
            " [   10     0     1     0     0  9748     0     1     0     0     0]\n",
            " [    7     0     0     0     0  9759     0     0     0     0     0]\n",
            " [    0     0     0     0     0     0     6     0     0  9873     0]\n",
            " [    1     0     0     0     1     0     0 10007     0     0     0]\n",
            " [    0     0     0     0     0     0     0     0  9873     0     0]\n",
            " [    0     0     0     0     0     0     1     0     0  9876     0]\n",
            " [    0     1     0     0     0     0   113     0     0  6062  3671]]\n",
            "Batch 211/237 - Batch Inference Time: 1.3003 seconds\n",
            "Testing Confusion Matrix:\n",
            " [[ 9850     0     0     0     0     4     0     3     0     0     0]\n",
            " [    0  9453   284     3     0     0     0     0     1     1     0]\n",
            " [    1   584  9239     3     0     0     0     0     2     0     0]\n",
            " [    1     0     0  9772     0     0     0     0     0     0     0]\n",
            " [   10     0     1     0     0  9813     0     1     0     0     0]\n",
            " [    7     0     0     0     0  9808     0     0     0     0     0]\n",
            " [    0     0     0     0     0     0     6     0     0  9920     0]\n",
            " [    1     0     0     0     1     0     0 10045     0     0     0]\n",
            " [    0     0     0     0     0     0     0     0  9919     0     0]\n",
            " [    0     0     0     0     0     0     1     0     0  9921     0]\n",
            " [    0     1     0     0     0     0   113     0     0  6087  3688]]\n",
            "Batch 212/237 - Batch Inference Time: 1.3032 seconds\n",
            "Testing Confusion Matrix:\n",
            " [[ 9899     0     0     0     0     4     0     3     0     0     0]\n",
            " [    0  9484   285     3     0     0     0     0     1     1     0]\n",
            " [    1   585  9286     3     0     0     0     0     2     0     0]\n",
            " [    1     0     0  9811     0     0     0     0     0     0     0]\n",
            " [   10     0     1     0     0  9870     0     1     0     0     0]\n",
            " [    7     0     0     0     0  9846     0     0     0     0     0]\n",
            " [    0     0     0     0     0     0     6     0     0  9967     0]\n",
            " [    1     0     0     0     1     0     0 10088     0     0     0]\n",
            " [    0     0     0     0     0     0     0     0  9972     0     0]\n",
            " [    0     0     0     0     0     0     1     0     0  9979     0]\n",
            " [    0     1     0     0     0     0   113     0     0  6118  3705]]\n",
            "Batch 213/237 - Batch Inference Time: 1.3846 seconds\n",
            "Testing Confusion Matrix:\n",
            " [[ 9939     0     0     0     0     4     0     3     0     0     0]\n",
            " [    0  9528   286     3     0     0     0     0     1     1     0]\n",
            " [    1   587  9334     3     0     0     0     0     2     0     0]\n",
            " [    1     0     0  9865     0     0     0     0     0     0     0]\n",
            " [   10     0     1     0     0  9916     0     1     0     0     0]\n",
            " [    7     0     0     0     0  9894     0     0     0     0     0]\n",
            " [    0     0     0     0     0     0     6     0     0 10001     0]\n",
            " [    1     0     0     0     1     0     0 10143     0     0     0]\n",
            " [    0     0     0     0     0     0     0     0 10019     0     0]\n",
            " [    0     0     0     0     0     0     1     0     0 10025     0]\n",
            " [    0     1     0     0     0     0   115     0     0  6149  3719]]\n",
            "Batch 214/237 - Batch Inference Time: 1.9917 seconds\n",
            "Testing Confusion Matrix:\n",
            " [[ 9989     0     0     0     0     4     0     3     0     0     0]\n",
            " [    0  9569   291     3     0     0     0     0     1     1     0]\n",
            " [    1   591  9379     3     0     0     0     0     2     0     0]\n",
            " [    1     0     0  9923     0     0     0     0     0     0     0]\n",
            " [   10     0     1     0     0  9953     0     1     0     0     0]\n",
            " [    7     0     0     0     0  9937     0     0     0     0     0]\n",
            " [    0     0     0     0     0     0     6     0     0 10052     0]\n",
            " [    1     0     0     0     1     0     0 10176     0     0     0]\n",
            " [    0     0     0     0     0     0     0     0 10060     0     0]\n",
            " [    0     0     0     0     0     0     1     0     0 10075     0]\n",
            " [    0     1     0     0     0     0   115     0     0  6180  3742]]\n",
            "Batch 215/237 - Batch Inference Time: 2.0185 seconds\n",
            "Testing Confusion Matrix:\n",
            " [[10030     0     0     0     0     4     0     3     0     0     0]\n",
            " [    0  9618   291     3     0     0     0     0     1     1     0]\n",
            " [    1   592  9416     3     0     0     0     0     2     0     0]\n",
            " [    1     0     0  9978     0     0     0     0     0     0     0]\n",
            " [   10     0     1     0     0  9996     0     1     0     0     0]\n",
            " [    7     0     0     0     0 10003     0     0     0     0     0]\n",
            " [    0     0     0     0     0     0     6     0     0 10096     0]\n",
            " [    1     0     0     0     1     0     0 10218     0     0     0]\n",
            " [    0     0     0     0     0     0     0     0 10103     0     0]\n",
            " [    0     0     0     0     0     0     1     0     0 10116     0]\n",
            " [    0     1     0     0     0     0   116     0     0  6207  3764]]\n",
            "Batch 216/237 - Batch Inference Time: 1.4909 seconds\n",
            "Testing Confusion Matrix:\n",
            " [[10071     0     0     0     0     4     0     3     0     0     0]\n",
            " [    0  9661   292     4     0     0     0     0     1     1     0]\n",
            " [    1   592  9464     3     0     0     0     0     2     0     0]\n",
            " [    1     0     0 10025     0     0     0     0     0     0     0]\n",
            " [   10     0     1     0     0 10045     0     1     0     0     0]\n",
            " [    7     0     0     0     0 10052     0     0     0     0     0]\n",
            " [    0     0     0     0     0     0     6     0     0 10135     0]\n",
            " [    1     0     0     0     1     0     0 10274     0     0     0]\n",
            " [    0     0     0     0     0     0     0     0 10155     0     0]\n",
            " [    0     0     0     0     0     0     1     0     0 10164     0]\n",
            " [    0     1     0     0     0     0   116     0     0  6229  3780]]\n",
            "Batch 217/237 - Batch Inference Time: 1.3675 seconds\n",
            "Testing Confusion Matrix:\n",
            " [[10125     0     0     0     0     4     0     3     0     0     0]\n",
            " [    0  9706   294     4     0     0     0     0     1     1     0]\n",
            " [    1   595  9499     3     0     0     0     0     2     0     0]\n",
            " [    1     0     0 10080     0     0     0     0     0     0     0]\n",
            " [   10     0     1     0     0 10086     0     1     0     0     0]\n",
            " [    7     0     0     0     0 10096     0     0     0     0     0]\n",
            " [    0     0     0     0     0     0     6     0     0 10179     0]\n",
            " [    1     0     0     0     1     0     0 10329     0     0     0]\n",
            " [    0     0     0     0     0     0     0     0 10205     0     0]\n",
            " [    0     0     0     0     0     0     1     0     0 10199     0]\n",
            " [    0     1     0     0     0     0   116     0     0  6258  3800]]\n",
            "Batch 218/237 - Batch Inference Time: 1.4119 seconds\n",
            "Testing Confusion Matrix:\n",
            " [[10165     0     0     0     0     4     0     3     0     0     0]\n",
            " [    0  9750   295     4     0     0     0     0     1     1     0]\n",
            " [    1   600  9553     3     0     0     0     0     2     0     0]\n",
            " [    1     0     0 10130     0     0     0     0     0     0     0]\n",
            " [   10     0     1     0     0 10127     0     1     0     0     0]\n",
            " [    7     0     0     0     0 10131     0     0     0     0     0]\n",
            " [    0     0     0     0     0     0     6     0     0 10221     0]\n",
            " [    1     0     0     0     1     0     0 10371     0     0     0]\n",
            " [    0     0     0     0     0     0     0     0 10272     0     0]\n",
            " [    0     0     0     0     0     0     1     0     0 10247     0]\n",
            " [    0     1     0     0     0     0   117     0     0  6287  3813]]\n",
            "Batch 219/237 - Batch Inference Time: 1.4194 seconds\n",
            "Testing Confusion Matrix:\n",
            " [[10206     0     0     0     0     4     0     3     0     0     0]\n",
            " [    0  9795   297     4     0     0     0     0     1     1     0]\n",
            " [    1   601  9605     3     0     0     0     0     2     0     0]\n",
            " [    1     0     0 10168     0     0     0     0     0     0     0]\n",
            " [   10     0     1     0     0 10167     0     1     0     0     0]\n",
            " [    7     0     0     0     0 10172     0     0     0     0     0]\n",
            " [    0     0     0     0     0     0     6     0     0 10277     0]\n",
            " [    1     0     0     0     1     0     0 10422     0     0     0]\n",
            " [    0     0     0     0     0     0     0     0 10318     0     0]\n",
            " [    0     0     0     0     0     0     1     0     0 10290     0]\n",
            " [    0     1     0     0     0     0   117     0     0  6320  3836]]\n",
            "Batch 220/237 - Batch Inference Time: 1.3426 seconds\n",
            "Testing Confusion Matrix:\n",
            " [[10257     0     0     0     0     4     0     3     0     0     0]\n",
            " [    0  9832   299     4     0     0     0     0     1     1     0]\n",
            " [    1   607  9657     3     0     0     0     0     2     0     0]\n",
            " [    1     0     0 10221     0     0     0     0     0     0     0]\n",
            " [   11     0     1     0     0 10216     0     1     0     0     0]\n",
            " [    7     0     0     0     0 10212     0     0     0     0     0]\n",
            " [    0     0     0     0     0     0     6     0     0 10312     0]\n",
            " [    1     0     0     0     1     0     0 10467     0     0     0]\n",
            " [    0     0     0     0     0     0     0     0 10365     0     0]\n",
            " [    0     0     0     0     0     0     1     0     0 10325     0]\n",
            " [    0     1     0     0     0     0   117     0     0  6351  3864]]\n",
            "Batch 221/237 - Batch Inference Time: 1.3843 seconds\n",
            "Testing Confusion Matrix:\n",
            " [[10303     0     0     0     0     4     0     3     0     0     0]\n",
            " [    0  9877   301     4     0     0     0     0     1     1     0]\n",
            " [    1   609  9700     3     0     0     0     0     2     0     0]\n",
            " [    1     0     0 10279     0     0     0     0     0     0     0]\n",
            " [   12     0     1     0     0 10268     0     1     0     0     0]\n",
            " [    7     0     0     0     0 10252     0     0     0     0     0]\n",
            " [    0     0     0     0     0     0     6     0     0 10347     0]\n",
            " [    1     0     0     0     1     0     0 10514     0     0     0]\n",
            " [    0     0     0     0     0     0     0     0 10406     0     0]\n",
            " [    0     0     0     0     0     0     1     0     0 10380     0]\n",
            " [    0     1     0     0     0     0   117     0     0  6378  3882]]\n",
            "Batch 222/237 - Batch Inference Time: 1.6831 seconds\n",
            "Testing Confusion Matrix:\n",
            " [[10340     0     0     0     0     4     0     3     0     0     0]\n",
            " [    0  9925   302     4     0     0     0     0     1     1     0]\n",
            " [    1   616  9746     3     0     0     0     0     2     0     0]\n",
            " [    1     0     0 10322     0     0     0     0     0     0     0]\n",
            " [   12     0     1     0     0 10324     0     1     0     0     0]\n",
            " [    7     0     0     0     0 10293     0     0     0     0     0]\n",
            " [    0     0     0     0     0     0     6     0     0 10399     0]\n",
            " [    1     0     0     0     1     0     0 10569     0     0     0]\n",
            " [    0     0     0     0     0     0     0     0 10443     0     0]\n",
            " [    0     0     0     0     0     0     1     0     0 10433     0]\n",
            " [    0     1     0     0     0     0   117     0     0  6406  3890]]\n",
            "Batch 223/237 - Batch Inference Time: 1.6568 seconds\n",
            "Testing Confusion Matrix:\n",
            " [[10386     0     0     0     0     4     0     3     0     0     0]\n",
            " [    0  9967   305     4     0     0     0     0     1     1     0]\n",
            " [    1   618  9787     3     0     0     0     0     2     0     0]\n",
            " [    1     0     0 10357     0     0     0     0     0     0     0]\n",
            " [   13     0     1     0     0 10383     0     1     0     0     0]\n",
            " [    7     0     0     0     0 10334     0     0     0     0     0]\n",
            " [    0     0     0     0     0     0     6     0     0 10449     0]\n",
            " [    1     0     0     0     1     0     0 10620     0     0     0]\n",
            " [    0     0     0     0     0     0     0     0 10490     0     0]\n",
            " [    0     0     0     0     0     0     1     0     0 10478     0]\n",
            " [    0     1     0     0     0     0   120     0     0  6436  3906]]\n",
            "Batch 224/237 - Batch Inference Time: 1.9737 seconds\n",
            "Testing Confusion Matrix:\n",
            " [[10433     0     0     0     0     4     0     3     0     0     0]\n",
            " [    0 10012   305     4     0     0     0     0     1     1     0]\n",
            " [    1   620  9841     3     0     0     0     0     2     0     0]\n",
            " [    1     0     0 10406     0     0     0     0     0     0     0]\n",
            " [   13     0     1     0     0 10432     0     1     0     0     0]\n",
            " [    7     0     0     0     0 10383     0     0     0     0     0]\n",
            " [    0     0     0     0     0     0     6     0     0 10486     0]\n",
            " [    1     0     0     0     1     0     0 10656     0     0     0]\n",
            " [    0     0     0     0     0     0     0     0 10539     0     0]\n",
            " [    0     0     0     0     0     0     1     0     0 10525     0]\n",
            " [    0     1     0     0     0     0   121     0     0  6463  3926]]\n",
            "Batch 225/237 - Batch Inference Time: 1.5079 seconds\n",
            "Testing Confusion Matrix:\n",
            " [[10479     0     0     0     0     4     0     3     0     0     0]\n",
            " [    0 10059   308     4     0     0     0     0     1     1     0]\n",
            " [    1   622  9881     3     0     0     0     0     2     0     0]\n",
            " [    1     0     0 10459     0     0     0     0     0     0     0]\n",
            " [   13     0     1     0     0 10480     0     1     0     0     0]\n",
            " [    7     0     0     0     0 10438     0     0     0     0     0]\n",
            " [    0     0     0     0     0     0     6     0     0 10537     0]\n",
            " [    1     0     0     0     1     0     0 10695     0     0     0]\n",
            " [    0     0     0     0     0     0     0     0 10585     0     0]\n",
            " [    0     0     0     0     0     0     1     0     0 10570     0]\n",
            " [    0     1     0     0     0     0   122     0     0  6481  3944]]\n",
            "Batch 226/237 - Batch Inference Time: 1.3101 seconds\n",
            "Testing Confusion Matrix:\n",
            " [[10522     0     0     0     0     4     0     3     0     0     0]\n",
            " [    0 10098   309     4     0     0     0     0     1     1     0]\n",
            " [    1   625  9925     3     0     0     0     0     2     0     0]\n",
            " [    1     0     0 10501     0     0     0     0     0     0     0]\n",
            " [   13     0     1     0     0 10527     0     1     0     0     0]\n",
            " [    7     0     0     0     0 10480     0     0     0     0     0]\n",
            " [    0     0     0     0     0     0     6     0     0 10595     0]\n",
            " [    1     0     0     0     1     0     0 10744     0     0     0]\n",
            " [    0     0     0     0     0     0     0     0 10634     0     0]\n",
            " [    0     0     0     0     0     0     1     0     0 10612     0]\n",
            " [    0     1     0     0     0     0   122     0     0  6509  3969]]\n",
            "Batch 227/237 - Batch Inference Time: 1.3432 seconds\n",
            "Testing Confusion Matrix:\n",
            " [[10556     0     0     0     0     4     0     3     0     0     0]\n",
            " [    0 10143   311     4     0     0     0     0     1     1     0]\n",
            " [    1   627  9972     3     0     0     0     0     2     0     0]\n",
            " [    1     0     0 10537     0     0     0     0     0     0     0]\n",
            " [   13     0     1     0     0 10588     0     1     0     0     0]\n",
            " [    7     0     0     0     0 10526     0     0     0     0     0]\n",
            " [    0     0     0     0     0     0     6     0     0 10644     0]\n",
            " [    1     0     0     0     1     0     0 10783     0     0     0]\n",
            " [    0     0     0     0     0     0     0     0 10683     0     0]\n",
            " [    0     0     0     0     0     0     1     0     0 10663     0]\n",
            " [    0     1     0     0     0     0   122     0     0  6544  3985]]\n",
            "Batch 228/237 - Batch Inference Time: 1.3082 seconds\n",
            "Testing Confusion Matrix:\n",
            " [[10603     0     0     0     0     4     0     3     0     0     0]\n",
            " [    0 10191   311     4     0     0     0     0     1     1     0]\n",
            " [    1   630 10023     3     0     0     0     0     2     0     0]\n",
            " [    1     0     0 10579     0     0     0     0     0     0     0]\n",
            " [   13     0     1     0     0 10625     0     1     0     0     0]\n",
            " [    8     0     0     0     0 10581     0     0     0     0     0]\n",
            " [    0     0     0     0     0     0     6     0     0 10704     0]\n",
            " [    1     0     0     0     1     0     0 10822     0     0     0]\n",
            " [    0     0     0     0     0     0     0     0 10735     0     0]\n",
            " [    0     0     0     0     0     0     1     0     0 10695     0]\n",
            " [    0     1     0     0     0     0   123     0     0  6572  4001]]\n",
            "Batch 229/237 - Batch Inference Time: 2.1269 seconds\n",
            "Testing Confusion Matrix:\n",
            " [[10642     0     0     0     0     4     0     3     0     0     0]\n",
            " [    0 10253   312     4     0     0     0     0     1     1     0]\n",
            " [    1   636 10063     3     0     0     0     0     2     0     0]\n",
            " [    1     0     0 10620     0     0     0     0     0     0     0]\n",
            " [   13     0     1     0     0 10657     0     1     0     0     0]\n",
            " [    8     0     0     0     0 10614     0     0     0     0     0]\n",
            " [    0     0     0     0     0     0     6     0     0 10758     0]\n",
            " [    1     0     0     0     1     0     0 10871     0     0     0]\n",
            " [    0     0     0     0     0     0     0     0 10784     0     0]\n",
            " [    0     0     0     0     0     0     1     0     0 10746     0]\n",
            " [    0     1     0     0     0     0   124     0     0  6605  4022]]\n",
            "Batch 230/237 - Batch Inference Time: 1.5778 seconds\n",
            "Testing Confusion Matrix:\n",
            " [[10684     0     0     0     0     4     0     3     0     0     0]\n",
            " [    0 10306   314     4     0     0     0     0     1     1     0]\n",
            " [    1   637 10111     3     0     0     0     0     2     0     0]\n",
            " [    1     0     0 10672     0     0     0     0     0     0     0]\n",
            " [   13     0     1     0     0 10698     0     1     0     0     0]\n",
            " [    8     0     0     0     0 10649     0     0     0     0     0]\n",
            " [    0     0     0     0     0     0     6     0     0 10808     0]\n",
            " [    1     0     0     0     1     0     0 10914     0     0     0]\n",
            " [    0     0     0     0     0     0     0     0 10838     0     0]\n",
            " [    0     0     0     0     0     0     1     0     0 10786     0]\n",
            " [    0     1     0     0     0     0   126     0     0  6634  4042]]\n",
            "Batch 231/237 - Batch Inference Time: 2.3377 seconds\n",
            "Testing Confusion Matrix:\n",
            " [[10726     0     0     0     0     4     0     3     0     0     0]\n",
            " [    0 10359   315     4     0     0     0     0     1     1     0]\n",
            " [    1   639 10157     3     0     0     0     0     2     0     0]\n",
            " [    1     0     0 10725     0     0     0     0     0     0     0]\n",
            " [   13     0     1     0     0 10750     0     1     0     0     0]\n",
            " [    8     0     0     0     0 10699     0     0     0     0     0]\n",
            " [    0     0     0     0     0     0     6     0     0 10851     0]\n",
            " [    1     0     0     0     1     0     0 10962     0     0     0]\n",
            " [    0     0     0     0     0     0     0     0 10880     0     0]\n",
            " [    0     0     0     0     0     0     1     0     0 10824     0]\n",
            " [    0     1     0     0     0     0   127     0     0  6662  4055]]\n",
            "Batch 232/237 - Batch Inference Time: 2.4116 seconds\n",
            "Testing Confusion Matrix:\n",
            " [[10772     0     0     0     0     4     0     3     0     0     0]\n",
            " [    0 10401   317     4     0     0     0     0     1     1     0]\n",
            " [    1   642 10198     3     0     0     0     0     2     0     0]\n",
            " [    1     0     0 10772     0     0     0     0     0     0     0]\n",
            " [   13     0     1     0     0 10797     0     1     0     0     0]\n",
            " [    8     0     0     0     0 10756     0     0     0     0     0]\n",
            " [    0     0     0     0     0     0     6     0     0 10898     0]\n",
            " [    1     0     0     0     1     0     0 11005     0     0     0]\n",
            " [    0     0     0     0     0     0     0     0 10933     0     0]\n",
            " [    0     0     0     0     0     0     1     0     0 10869     0]\n",
            " [    0     1     0     0     0     0   128     0     0  6685  4070]]\n",
            "Batch 233/237 - Batch Inference Time: 1.8196 seconds\n",
            "Testing Confusion Matrix:\n",
            " [[10814     0     0     0     0     4     0     3     0     0     0]\n",
            " [    0 10442   321     4     0     0     0     0     1     1     0]\n",
            " [    1   648 10232     3     0     0     0     0     2     0     0]\n",
            " [    1     0     0 10818     0     0     0     0     0     0     0]\n",
            " [   13     0     1     0     0 10852     0     1     0     0     0]\n",
            " [    8     0     0     0     0 10799     0     0     0     0     0]\n",
            " [    0     0     0     0     0     0     6     0     0 10947     0]\n",
            " [    1     0     0     0     1     0     0 11051     0     0     0]\n",
            " [    0     0     0     0     0     0     0     0 10985     0     0]\n",
            " [    0     0     0     0     0     0     1     0     0 10916     0]\n",
            " [    0     1     0     0     0     0   128     0     0  6716  4086]]\n",
            "Batch 234/237 - Batch Inference Time: 1.5769 seconds\n",
            "Testing Confusion Matrix:\n",
            " [[10869     0     0     0     0     4     0     3     0     0     0]\n",
            " [    0 10492   322     4     0     0     0     0     1     1     0]\n",
            " [    1   649 10272     3     0     0     0     0     2     0     0]\n",
            " [    1     0     0 10865     0     0     0     0     0     0     0]\n",
            " [   13     0     1     0     0 10891     0     1     0     0     0]\n",
            " [    8     0     0     0     0 10845     0     0     0     0     0]\n",
            " [    0     0     0     0     0     0     6     0     0 10992     0]\n",
            " [    1     0     0     0     1     0     0 11105     0     0     0]\n",
            " [    0     0     0     0     0     0     0     0 11025     0     0]\n",
            " [    0     0     0     0     0     0     1     0     0 10955     0]\n",
            " [    0     1     0     0     0     0   128     0     0  6750  4107]]\n",
            "Batch 235/237 - Batch Inference Time: 1.3639 seconds\n",
            "Testing Confusion Matrix:\n",
            " [[10915     0     0     0     0     4     0     3     0     0     0]\n",
            " [    0 10527   324     4     0     0     0     0     1     1     0]\n",
            " [    1   652 10318     3     0     0     0     0     2     0     0]\n",
            " [    1     0     0 10913     0     0     0     0     0     0     0]\n",
            " [   13     0     1     0     0 10941     0     1     0     0     0]\n",
            " [    8     0     0     0     0 10904     0     0     0     0     0]\n",
            " [    0     0     0     0     0     0     6     0     0 11024     0]\n",
            " [    1     0     0     0     1     0     0 11153     0     0     0]\n",
            " [    0     0     0     0     0     0     0     0 11054     0     0]\n",
            " [    0     0     0     0     0     0     1     0     0 11012     0]\n",
            " [    0     1     0     0     0     0   129     0     0  6787  4126]]\n",
            "Batch 236/237 - Batch Inference Time: 1.3281 seconds\n",
            "Testing Confusion Matrix:\n",
            " [[10945     0     0     0     0     4     0     3     0     0     0]\n",
            " [    0 10574   326     4     0     0     0     0     1     1     0]\n",
            " [    1   654 10359     3     0     0     0     0     2     0     0]\n",
            " [    1     0     0 10957     0     0     0     0     0     0     0]\n",
            " [   13     0     1     0     0 10991     0     1     0     0     0]\n",
            " [    8     0     0     0     0 10944     0     0     0     0     0]\n",
            " [    0     0     0     0     0     0     6     0     0 11069     0]\n",
            " [    1     0     0     0     1     0     0 11187     0     0     0]\n",
            " [    0     0     0     0     0     0     0     0 11102     0     0]\n",
            " [    0     0     0     0     0     0     1     0     0 11055     0]\n",
            " [    0     1     0     0     0     0   129     0     0  6813  4144]]\n",
            "Batch 237/237 - Batch Inference Time: 1.4089 seconds\n",
            "\n",
            "Testing completed: Testing Accuracy = 0.7524\n",
            "Average Inference Time per Batch: 1.4891 seconds\n",
            "Total Inference Time: 352.91 seconds\n",
            "Total Communication Overhead:\n",
            "  Bytes Sent: 564243939 bytes\n",
            "  Bytes Received: 2607 bytes\n",
            "  Total: 564246546 bytes\n",
            "\n",
            "Client connection closed.\n"
          ]
        }
      ],
      "source": [
        "import socket\n",
        "import pickle\n",
        "import zlib\n",
        "import time\n",
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "from tensorflow.keras import Sequential\n",
        "from tensorflow.keras.layers import Conv1D, MaxPooling1D, BatchNormalization\n",
        "from sklearn.model_selection import train_test_split\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "\n",
        "# Client-side model\n",
        "def create_client_model():\n",
        "    model = Sequential([\n",
        "        Conv1D(16, kernel_size=3, activation='relu', input_shape=(40, 1),padding='same'),\n",
        "        BatchNormalization(),\n",
        "        Conv1D(32, kernel_size=3, activation='relu',padding='same'),\n",
        "        BatchNormalization(),\n",
        "        #MaxPooling1D(pool_size=2),\n",
        "        Conv1D(32, kernel_size=3, activation='relu',padding='same'),\n",
        "        BatchNormalization(),\n",
        "        #MaxPooling1D(pool_size=2),\n",
        "        Conv1D(64, kernel_size=3, activation='relu',padding='same'),\n",
        "        BatchNormalization(),\n",
        "        Conv1D(64, kernel_size=3, activation='relu',padding='same'),\n",
        "        BatchNormalization(),\n",
        "        MaxPooling1D(pool_size=2),\n",
        "\n",
        "    ])\n",
        "    return model\n",
        "\n",
        "# Serialize and compress data using pickle\n",
        "def serialize_data(data):\n",
        "    return zlib.compress(pickle.dumps(data))\n",
        "\n",
        "# Client function\n",
        "def start_client(host='127.0.0.1', port=65436):\n",
        "    client_model = create_client_model()\n",
        "    client_socket = socket.socket(socket.AF_INET, socket.SOCK_STREAM)\n",
        "    client_socket.connect((host, port))\n",
        "    print(\"Connected to server!\")\n",
        "\n",
        "    batch_size = 512\n",
        "    epochs =  1\n",
        "    total_batches = int(np.ceil(X_train_scaled.shape[0] / batch_size))\n",
        "\n",
        "    print(\"\\nStarting Training...\")\n",
        "    start_time = time.time()\n",
        "\n",
        "    for epoch in range(epochs):\n",
        "        print(f\"\\nEpoch {epoch + 1}/{epochs}\")\n",
        "        epoch_loss = 0\n",
        "        correct_predictions = 0\n",
        "        total_samples = 0\n",
        "\n",
        "        for batch_index, i in enumerate(range(0, X_train_scaled.shape[0], batch_size), start=1):\n",
        "            x_batch = X_train_scaled[i:min(i + batch_size, X_train_scaled.shape[0])]\n",
        "            y_batch = y_train[i:min(i + batch_size, y_train.shape[0])]\n",
        "\n",
        "            # Forward pass to get intermediate activations\n",
        "            intermediate_output = client_model(x_batch, training=True).numpy()\n",
        "\n",
        "            # Serialize and send data\n",
        "            data = serialize_data((intermediate_output.tolist(), y_batch.tolist()))\n",
        "            client_socket.sendall(f\"{len(data):08}\".encode('utf-8'))\n",
        "            client_socket.sendall(data)\n",
        "\n",
        "            # Receive server response\n",
        "            response_header = client_socket.recv(8)\n",
        "            response_size = int(response_header.decode('utf-8').strip())\n",
        "            response = client_socket.recv(response_size)\n",
        "            server_loss, batch_correct = map(float, response.decode('utf-8').split(','))\n",
        "\n",
        "            # Update statistics\n",
        "            epoch_loss += server_loss\n",
        "            correct_predictions += batch_correct\n",
        "            total_samples += x_batch.shape[0]\n",
        "\n",
        "            # Display batch progress\n",
        "            progress = (batch_index / total_batches) * 100\n",
        "            print(f\"\\rBatch {batch_index}/{total_batches} - Progress: {progress:.2f}% - Loss: {server_loss:.4f}\", end=\"\")\n",
        "\n",
        "        training_accuracy = correct_predictions / total_samples\n",
        "        print(f\"\\nEpoch {epoch + 1} completed: Avg Loss = {epoch_loss / total_batches:.4f}, \"\n",
        "              f\"Training Accuracy = {training_accuracy:.4f}\")\n",
        "\n",
        "    total_training_time = time.time() - start_time\n",
        "    print(f\"\\nTraining completed in {total_training_time:.2f} seconds.\")\n",
        "\n",
        "    # Signal the server to switch to evaluation mode\n",
        "    client_socket.sendall(f\"{-1:08}\".encode('utf-8'))\n",
        "    print(\"Training complete. Signaled server to start evaluation.\")\n",
        "\n",
        "        # Evaluate testing accuracy in batches\n",
        "    print(\"\\nEvaluating on test data...\")\n",
        "    test_batch_size = 512  # Larger batch size for efficient testing\n",
        "    total_test_batches = int(np.ceil(X_test_scaled.shape[0] / test_batch_size))\n",
        "    correct_predictions = 0\n",
        "    total_samples = 0\n",
        "    total_inference_time = 0\n",
        "    total_bytes_sent = 0\n",
        "    total_bytes_received = 0\n",
        "\n",
        "    for batch_num, i in enumerate(range(0, X_test_scaled.shape[0], test_batch_size), start=1):\n",
        "        x_test_batch = X_test_scaled[i:min(i + test_batch_size, X_test_scaled.shape[0])]\n",
        "        y_test_batch = y_test[i:min(i + test_batch_size, y_test.shape[0])]\n",
        "\n",
        "        # Start timing the inference\n",
        "        start_infer_time = time.time()\n",
        "\n",
        "        test_intermediate = client_model.predict(x_test_batch, verbose=0)\n",
        "        # Stop timing and accumulate\n",
        "        end_infer_time = time.time()\n",
        "\n",
        "        test_data = serialize_data((test_intermediate.tolist(), y_test_batch.tolist()))\n",
        "        data_length = len(test_data)\n",
        "        client_socket.sendall(f\"{len(test_data):08}\".encode('utf-8'))\n",
        "        client_socket.sendall(test_data)\n",
        "        total_bytes_sent += 8 + data_length\n",
        "\n",
        "        test_accuracy_response = client_socket.recv(8)\n",
        "        test_accuracy_size = int(test_accuracy_response.decode('utf-8').strip())\n",
        "        test_accuracy_data = client_socket.recv(test_accuracy_size)\n",
        "        batch_correct = int(test_accuracy_data.decode('utf-8'))\n",
        "        total_bytes_received += 8 + test_accuracy_size  # 8 bytes for header + actual data\n",
        "\n",
        "        # Stop timing and accumulate\n",
        "        end_infer_time = time.time()\n",
        "        batch_inference_time = end_infer_time - start_infer_time\n",
        "        total_inference_time += batch_inference_time\n",
        "\n",
        "        print(f\"Batch {batch_num}/{total_test_batches} - Batch Inference Time: {batch_inference_time:.4f} seconds\")\n",
        "\n",
        "        correct_predictions += batch_correct\n",
        "        total_samples += x_test_batch.shape[0]\n",
        "\n",
        "    test_accuracy = correct_predictions / total_samples\n",
        "    avg_inference_time = total_inference_time / total_test_batches\n",
        "    print(f\"\\nTesting completed: Testing Accuracy = {test_accuracy:.4f}\")\n",
        "    print(f\"Average Inference Time per Batch: {avg_inference_time:.4f} seconds\")\n",
        "    print(f\"Total Inference Time: {total_inference_time:.2f} seconds\")\n",
        "    print(f\"Total Communication Overhead:\")\n",
        "    print(f\"  Bytes Sent: {total_bytes_sent} bytes\")\n",
        "    print(f\"  Bytes Received: {total_bytes_received} bytes\")\n",
        "    print(f\"  Total: {total_bytes_sent + total_bytes_received} bytes\")\n",
        "\n",
        "    client_socket.close()\n",
        "    print(\"\\nClient connection closed.\")\n",
        "\n",
        "# Start the client\n",
        "start_client()\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "5TeYmy0hmNHA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "TAO2oqZFmNKN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Ofa42p9imNNw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "0UHnhWpNmNRT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "OKsSb1iJmNUs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "vHYIjYHQmNYX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "mbKRqNBFmNbb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "LyDWIQI2mNez"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "-NIsE7VVmNhq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vcoTa9T1id1G",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7221fc4b-aacf-4bc5-e05a-9369652529e7"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/keras/src/layers/pooling/base_pooling.py:23: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(name=name, **kwargs)\n"
          ]
        }
      ],
      "source": [
        "import socket\n",
        "import pickle\n",
        "import zlib\n",
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "from tensorflow.keras import Sequential\n",
        "from tensorflow.keras.layers import MaxPooling1D, Flatten, Dense, BatchNormalization\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "import threading\n",
        "from sklearn.metrics import precision_score, recall_score, f1_score\n",
        "from tensorflow.keras.layers import Dropout\n",
        "from sklearn.metrics import confusion_matrix\n",
        "# Server-side model\n",
        "def create_server_model():\n",
        "    model = Sequential([\n",
        "        MaxPooling1D(pool_size=2,input_shape=(20, 64)),\n",
        "        Conv1D(128, kernel_size=3, activation='relu',padding='same'),\n",
        "        BatchNormalization(),\n",
        "        Conv1D(128, kernel_size=3, activation='relu',padding='same'),\n",
        "        BatchNormalization(),\n",
        "        MaxPooling1D(pool_size=2),\n",
        "        Conv1D(256, kernel_size=3, activation='relu',padding='same'),\n",
        "        BatchNormalization(),\n",
        "        Conv1D(256, kernel_size=3, activation='relu',padding='same'),\n",
        "        BatchNormalization(),\n",
        "        MaxPooling1D(pool_size=2),\n",
        "        Flatten(),\n",
        "        Dense(256, activation='relu'),\n",
        "        Dropout(0.3),\n",
        "        Dense(128, activation='relu'),\n",
        "        Dropout(0.2),\n",
        "        Dense(11, activation='softmax')\n",
        "    ])\n",
        "    model.compile(optimizer=Adam(learning_rate=0.001),\n",
        "                  loss='categorical_crossentropy',\n",
        "                  metrics=['accuracy'])\n",
        "    return model\n",
        "\n",
        "# Deserialize and decompress data\n",
        "def deserialize_data(data):\n",
        "    return pickle.loads(zlib.decompress(data))\n",
        "\n",
        "# Server function\n",
        "def start_server(host='127.0.0.1', port=65437):\n",
        "    server_model = create_server_model()\n",
        "    server_socket = socket.socket(socket.AF_INET, socket.SOCK_STREAM)\n",
        "    server_socket.bind((host, port))\n",
        "    server_socket.listen(1)\n",
        "    print(\"Server waiting for connection...\")\n",
        "    conn, addr = server_socket.accept()\n",
        "    print(f\"Connected to client: {addr}\")\n",
        "    lr_schedule = tf.keras.optimizers.schedules.ExponentialDecay(\n",
        "    initial_learning_rate=0.001,\n",
        "    decay_steps=10000,\n",
        "    decay_rate=0.9\n",
        "    )\n",
        "    optimizer = tf.keras.optimizers.Adam(learning_rate=lr_schedule)\n",
        "\n",
        "    all_true_labels = []\n",
        "    all_pred_labels = []\n",
        "\n",
        "\n",
        "    while True:\n",
        "        try:\n",
        "            # Receive header indicating batch size\n",
        "            header = conn.recv(8)\n",
        "            if not header:\n",
        "                break\n",
        "            data_size = int(header.decode('utf-8').strip())\n",
        "\n",
        "\n",
        "            # If a special flag (e.g., -1) is sent, switch to evaluation\n",
        "            if data_size == -1:\n",
        "              print(\"Switching to evaluation phase...\")\n",
        "              break\n",
        "\n",
        "            # Receive the batch data\n",
        "            data = b\"\"\n",
        "            while len(data) < data_size:\n",
        "                packet = conn.recv(4096)\n",
        "                if not packet:\n",
        "                    break\n",
        "                data += packet\n",
        "\n",
        "            # Deserialize the data\n",
        "            intermediate_output, labels = deserialize_data(data)\n",
        "\n",
        "            # Perform forward pass and backpropagation on batch\n",
        "            with tf.GradientTape() as tape:\n",
        "                logits = server_model(np.array(intermediate_output), training=True)\n",
        "                loss = tf.reduce_mean(\n",
        "                    tf.keras.losses.categorical_crossentropy(np.array(labels), logits)\n",
        "                )\n",
        "            gradients = tape.gradient(loss, server_model.trainable_variables)\n",
        "            optimizer.apply_gradients(zip(gradients, server_model.trainable_variables))\n",
        "\n",
        "            pred_classes = np.argmax(logits.numpy(), axis=1)\n",
        "            true_classes = np.argmax(labels, axis=1)\n",
        "\n",
        "            all_pred_labels.extend(pred_classes)\n",
        "            all_true_labels.extend(true_classes)\n",
        "\n",
        "            correct_predictions = int(np.sum(\n",
        "                np.argmax(logits.numpy(), axis=1) == np.argmax(labels, axis=1)\n",
        "            ))\n",
        "            response = f\"{loss.numpy():.4f},{correct_predictions}\"\n",
        "            conn.sendall(f\"{len(response):08}\".encode('utf-8'))\n",
        "            conn.sendall(response.encode('utf-8'))\n",
        "\n",
        "        except Exception as e:\n",
        "            print(f\"Error: {e}\")\n",
        "            break\n",
        "\n",
        "    # At the end of training\n",
        "    precision = precision_score(all_true_labels, all_pred_labels, average='macro')\n",
        "    recall = recall_score(all_true_labels, all_pred_labels, average='macro')\n",
        "    f1 = f1_score(all_true_labels, all_pred_labels, average='macro')\n",
        "    print(f\"\\nTraining Metrics → Precision: {precision:.4f}, Recall: {recall:.4f}, F1 Score: {f1:.4f}\")\n",
        "\n",
        "    # Handle test evaluation\n",
        "    print(\"Evaluating test data...\")\n",
        "\n",
        "    all_test_true = []\n",
        "    all_test_pred = []\n",
        "\n",
        "    while True:\n",
        "        header = conn.recv(8)\n",
        "        if not header:\n",
        "            break\n",
        "        test_data_size = int(header.decode('utf-8').strip())\n",
        "        test_data = b\"\"\n",
        "        while len(test_data) < test_data_size:\n",
        "            packet = conn.recv(4096)\n",
        "            if not packet:\n",
        "                break\n",
        "            test_data += packet\n",
        "\n",
        "        test_intermediate, test_labels = deserialize_data(test_data)\n",
        "        logits = server_model(np.array(test_intermediate), training=False)\n",
        "\n",
        "        test_intermediate = np.array(test_intermediate)\n",
        "        test_labels = np.array(test_labels)\n",
        "\n",
        "        logits = server_model(test_intermediate, training=False)\n",
        "        pred_classes = np.argmax(logits.numpy(), axis=1)\n",
        "        true_classes = np.argmax(test_labels, axis=1)\n",
        "\n",
        "        all_test_pred.extend(pred_classes)\n",
        "        all_test_true.extend(true_classes)\n",
        "\n",
        "        correct_predictions = int(np.sum(\n",
        "            np.argmax(logits.numpy(), axis=1) == np.argmax(test_labels, axis=1)\n",
        "        ))\n",
        "        response = f\"{correct_predictions}\"\n",
        "        conn.sendall(f\"{len(response):08}\".encode('utf-8'))\n",
        "        conn.sendall(response.encode('utf-8'))\n",
        "\n",
        "    # Final test metrics\n",
        "    precision = precision_score(all_test_true, all_test_pred, average='macro')\n",
        "    recall = recall_score(all_test_true, all_test_pred, average='macro')\n",
        "    f1 = f1_score(all_test_true, all_test_pred, average='macro')\n",
        "    conf_matrix_test = confusion_matrix(all_test_true, all_test_pred)\n",
        "    print(f\"\\nTesting Metrics → Precision: {precision:.4f}, Recall: {recall:.4f}, F1 Score: {f1:.4f}\")\n",
        "    print(\"Testing Confusion Matrix:\\n\", conf_matrix_test)\n",
        "\n",
        "\n",
        "    conn.close()\n",
        "    server_socket.close()\n",
        "    print(\"Server connection closed.\")\n",
        "\n",
        "server_thread = threading.Thread(target=start_server)\n",
        "server_thread.start()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ba223a07-b2e2-4a97-b6e6-1228a453f225",
        "id": "FW9eWkeYikLG",
        "collapsed": true
      },
      "outputs": [
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/keras/src/layers/convolutional/base_conv.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Connected to server!Connected to client: ('127.0.0.1', 43332)\n",
            "\n",
            "\n",
            "Starting Training...\n",
            "\n",
            "Epoch 1/10\n",
            "Batch 553/553 - Progress: 100.00% - Loss: 0.1899\n",
            "Epoch 1 completed: Avg Loss = 0.2570, Training Accuracy = 0.8554\n",
            "\n",
            "Epoch 2/10\n",
            "Batch 553/553 - Progress: 100.00% - Loss: 0.1707\n",
            "Epoch 2 completed: Avg Loss = 0.1780, Training Accuracy = 0.8879\n",
            "\n",
            "Epoch 3/10\n",
            "Batch 553/553 - Progress: 100.00% - Loss: 0.1427\n",
            "Epoch 3 completed: Avg Loss = 0.1582, Training Accuracy = 0.8971\n",
            "\n",
            "Epoch 4/10\n",
            "Batch 553/553 - Progress: 100.00% - Loss: 0.1426\n",
            "Epoch 4 completed: Avg Loss = 0.1486, Training Accuracy = 0.9018\n",
            "\n",
            "Epoch 5/10\n",
            "Batch 553/553 - Progress: 100.00% - Loss: 0.1246\n",
            "Epoch 5 completed: Avg Loss = 0.1446, Training Accuracy = 0.9035\n",
            "\n",
            "Epoch 6/10\n",
            "Batch 553/553 - Progress: 100.00% - Loss: 0.1259\n",
            "Epoch 6 completed: Avg Loss = 0.1442, Training Accuracy = 0.9036\n",
            "\n",
            "Epoch 7/10\n",
            "Batch 553/553 - Progress: 100.00% - Loss: 0.1341\n",
            "Epoch 7 completed: Avg Loss = 0.1407, Training Accuracy = 0.9046\n",
            "\n",
            "Epoch 8/10\n",
            "Batch 553/553 - Progress: 100.00% - Loss: 0.1302\n",
            "Epoch 8 completed: Avg Loss = 0.1392, Training Accuracy = 0.9051\n",
            "\n",
            "Epoch 9/10\n",
            "Batch 553/553 - Progress: 100.00% - Loss: 0.1205\n",
            "Epoch 9 completed: Avg Loss = 0.1377, Training Accuracy = 0.9058\n",
            "\n",
            "Epoch 10/10\n",
            "Batch 553/553 - Progress: 100.00% - Loss: 0.1232\n",
            "Epoch 10 completed: Avg Loss = 0.1380, Training Accuracy = 0.9060\n",
            "\n",
            "Training completed in 9463.02 seconds.\n",
            "Training complete. Signaled server to start evaluation.\n",
            "\n",
            "Evaluating on test data...\n",
            "Switching to evaluation phase...\n",
            "\n",
            "Training Metrics → Precision: 0.8973, Recall: 0.8973, F1 Score: 0.8972\n",
            "Evaluating test data...\n",
            "Batch 1/237 - Batch Inference Time: 11.8354 seconds\n",
            "Batch 2/237 - Batch Inference Time: 1.6974 seconds\n",
            "Batch 3/237 - Batch Inference Time: 1.3901 seconds\n",
            "Batch 4/237 - Batch Inference Time: 1.2620 seconds\n",
            "Batch 5/237 - Batch Inference Time: 1.3159 seconds\n",
            "Batch 6/237 - Batch Inference Time: 1.3110 seconds\n",
            "Batch 7/237 - Batch Inference Time: 1.5733 seconds\n",
            "Batch 8/237 - Batch Inference Time: 1.3034 seconds\n",
            "Batch 9/237 - Batch Inference Time: 1.2651 seconds\n",
            "Batch 10/237 - Batch Inference Time: 1.4868 seconds\n",
            "Batch 11/237 - Batch Inference Time: 1.7344 seconds\n",
            "Batch 12/237 - Batch Inference Time: 1.6441 seconds\n",
            "Batch 13/237 - Batch Inference Time: 1.3388 seconds\n",
            "Batch 14/237 - Batch Inference Time: 1.2678 seconds\n",
            "Batch 15/237 - Batch Inference Time: 1.2566 seconds\n",
            "Batch 16/237 - Batch Inference Time: 1.3303 seconds\n",
            "Batch 17/237 - Batch Inference Time: 1.6210 seconds\n",
            "Batch 18/237 - Batch Inference Time: 1.2569 seconds\n",
            "Batch 19/237 - Batch Inference Time: 1.3328 seconds\n",
            "Batch 20/237 - Batch Inference Time: 1.5696 seconds\n",
            "Batch 21/237 - Batch Inference Time: 1.7352 seconds\n",
            "Batch 22/237 - Batch Inference Time: 1.5048 seconds\n",
            "Batch 23/237 - Batch Inference Time: 1.3161 seconds\n",
            "Batch 24/237 - Batch Inference Time: 1.2687 seconds\n",
            "Batch 25/237 - Batch Inference Time: 1.3410 seconds\n",
            "Batch 26/237 - Batch Inference Time: 1.2476 seconds\n",
            "Batch 27/237 - Batch Inference Time: 1.2495 seconds\n",
            "Batch 28/237 - Batch Inference Time: 1.6056 seconds\n",
            "Batch 29/237 - Batch Inference Time: 1.3124 seconds\n",
            "Batch 30/237 - Batch Inference Time: 1.7512 seconds\n",
            "Batch 31/237 - Batch Inference Time: 1.7145 seconds\n",
            "Batch 32/237 - Batch Inference Time: 1.4377 seconds\n",
            "Batch 33/237 - Batch Inference Time: 1.2733 seconds\n",
            "Batch 34/237 - Batch Inference Time: 1.2445 seconds\n",
            "Batch 35/237 - Batch Inference Time: 1.2642 seconds\n",
            "Batch 36/237 - Batch Inference Time: 1.3156 seconds\n",
            "Batch 37/237 - Batch Inference Time: 1.6514 seconds\n",
            "Batch 38/237 - Batch Inference Time: 1.2780 seconds\n",
            "Batch 39/237 - Batch Inference Time: 1.4948 seconds\n",
            "Batch 40/237 - Batch Inference Time: 1.7159 seconds\n",
            "Batch 41/237 - Batch Inference Time: 1.7239 seconds\n",
            "Batch 42/237 - Batch Inference Time: 1.3061 seconds\n",
            "Batch 43/237 - Batch Inference Time: 1.2882 seconds\n",
            "Batch 44/237 - Batch Inference Time: 1.3302 seconds\n",
            "Batch 45/237 - Batch Inference Time: 1.2684 seconds\n",
            "Batch 46/237 - Batch Inference Time: 1.6198 seconds\n",
            "Batch 47/237 - Batch Inference Time: 1.2697 seconds\n",
            "Batch 48/237 - Batch Inference Time: 1.2703 seconds\n",
            "Batch 49/237 - Batch Inference Time: 1.5565 seconds\n",
            "Batch 50/237 - Batch Inference Time: 1.7072 seconds\n",
            "Batch 51/237 - Batch Inference Time: 1.5000 seconds\n",
            "Batch 52/237 - Batch Inference Time: 1.2857 seconds\n",
            "Batch 53/237 - Batch Inference Time: 1.2813 seconds\n",
            "Batch 54/237 - Batch Inference Time: 1.2825 seconds\n",
            "Batch 55/237 - Batch Inference Time: 1.2580 seconds\n",
            "Batch 56/237 - Batch Inference Time: 1.2369 seconds\n",
            "Batch 57/237 - Batch Inference Time: 1.6263 seconds\n",
            "Batch 58/237 - Batch Inference Time: 1.2508 seconds\n",
            "Batch 59/237 - Batch Inference Time: 1.6702 seconds\n",
            "Batch 60/237 - Batch Inference Time: 1.6986 seconds\n",
            "Batch 61/237 - Batch Inference Time: 1.5813 seconds\n",
            "Batch 62/237 - Batch Inference Time: 1.3327 seconds\n",
            "Batch 63/237 - Batch Inference Time: 1.2871 seconds\n",
            "Batch 64/237 - Batch Inference Time: 1.2770 seconds\n",
            "Batch 65/237 - Batch Inference Time: 1.3350 seconds\n",
            "Batch 66/237 - Batch Inference Time: 1.2756 seconds\n",
            "Batch 67/237 - Batch Inference Time: 1.3507 seconds\n",
            "Batch 68/237 - Batch Inference Time: 1.8052 seconds\n",
            "Batch 69/237 - Batch Inference Time: 1.7219 seconds\n",
            "Batch 70/237 - Batch Inference Time: 1.6321 seconds\n",
            "Batch 71/237 - Batch Inference Time: 1.2579 seconds\n",
            "Batch 72/237 - Batch Inference Time: 1.3002 seconds\n",
            "Batch 73/237 - Batch Inference Time: 1.3277 seconds\n",
            "Batch 74/237 - Batch Inference Time: 1.2966 seconds\n",
            "Batch 75/237 - Batch Inference Time: 1.2760 seconds\n",
            "Batch 76/237 - Batch Inference Time: 1.3322 seconds\n",
            "Batch 77/237 - Batch Inference Time: 1.2589 seconds\n",
            "Batch 78/237 - Batch Inference Time: 1.9698 seconds\n",
            "Batch 79/237 - Batch Inference Time: 1.7120 seconds\n",
            "Batch 80/237 - Batch Inference Time: 1.6042 seconds\n",
            "Batch 81/237 - Batch Inference Time: 1.3287 seconds\n",
            "Batch 82/237 - Batch Inference Time: 1.2671 seconds\n",
            "Batch 83/237 - Batch Inference Time: 1.3535 seconds\n",
            "Batch 84/237 - Batch Inference Time: 1.2722 seconds\n",
            "Batch 85/237 - Batch Inference Time: 1.3204 seconds\n",
            "Batch 86/237 - Batch Inference Time: 1.2975 seconds\n",
            "Batch 87/237 - Batch Inference Time: 1.3093 seconds\n",
            "Batch 88/237 - Batch Inference Time: 2.1141 seconds\n",
            "Batch 89/237 - Batch Inference Time: 1.7226 seconds\n",
            "Batch 90/237 - Batch Inference Time: 1.3405 seconds\n",
            "Batch 91/237 - Batch Inference Time: 1.2874 seconds\n",
            "Batch 92/237 - Batch Inference Time: 1.3269 seconds\n",
            "Batch 93/237 - Batch Inference Time: 1.2543 seconds\n",
            "Batch 94/237 - Batch Inference Time: 1.2956 seconds\n",
            "Batch 95/237 - Batch Inference Time: 1.3219 seconds\n",
            "Batch 96/237 - Batch Inference Time: 1.5955 seconds\n",
            "Batch 97/237 - Batch Inference Time: 1.6091 seconds\n",
            "Batch 98/237 - Batch Inference Time: 1.7274 seconds\n",
            "Batch 99/237 - Batch Inference Time: 1.5067 seconds\n",
            "Batch 100/237 - Batch Inference Time: 1.2903 seconds\n",
            "Batch 101/237 - Batch Inference Time: 1.2673 seconds\n",
            "Batch 102/237 - Batch Inference Time: 1.3596 seconds\n",
            "Batch 103/237 - Batch Inference Time: 1.2549 seconds\n",
            "Batch 104/237 - Batch Inference Time: 1.2818 seconds\n",
            "Batch 105/237 - Batch Inference Time: 1.3091 seconds\n",
            "Batch 106/237 - Batch Inference Time: 1.3226 seconds\n",
            "Batch 107/237 - Batch Inference Time: 1.5690 seconds\n",
            "Batch 108/237 - Batch Inference Time: 2.1267 seconds\n",
            "Batch 109/237 - Batch Inference Time: 1.4353 seconds\n",
            "Batch 110/237 - Batch Inference Time: 1.3063 seconds\n",
            "Batch 111/237 - Batch Inference Time: 1.3359 seconds\n",
            "Batch 112/237 - Batch Inference Time: 1.3260 seconds\n",
            "Batch 113/237 - Batch Inference Time: 1.2918 seconds\n",
            "Batch 114/237 - Batch Inference Time: 1.2769 seconds\n",
            "Batch 115/237 - Batch Inference Time: 1.3407 seconds\n",
            "Batch 116/237 - Batch Inference Time: 1.3663 seconds\n",
            "Batch 117/237 - Batch Inference Time: 1.7121 seconds\n",
            "Batch 118/237 - Batch Inference Time: 2.0652 seconds\n",
            "Batch 119/237 - Batch Inference Time: 1.2945 seconds\n",
            "Batch 120/237 - Batch Inference Time: 1.3510 seconds\n",
            "Batch 121/237 - Batch Inference Time: 1.3911 seconds\n",
            "Batch 122/237 - Batch Inference Time: 1.2923 seconds\n",
            "Batch 123/237 - Batch Inference Time: 1.2649 seconds\n",
            "Batch 124/237 - Batch Inference Time: 1.2958 seconds\n",
            "Batch 125/237 - Batch Inference Time: 1.3023 seconds\n",
            "Batch 126/237 - Batch Inference Time: 1.5561 seconds\n",
            "Batch 127/237 - Batch Inference Time: 2.1519 seconds\n",
            "Batch 128/237 - Batch Inference Time: 1.4808 seconds\n",
            "Batch 129/237 - Batch Inference Time: 1.3183 seconds\n",
            "Batch 130/237 - Batch Inference Time: 1.2672 seconds\n",
            "Batch 131/237 - Batch Inference Time: 1.2641 seconds\n",
            "Batch 132/237 - Batch Inference Time: 1.2973 seconds\n",
            "Batch 133/237 - Batch Inference Time: 1.3456 seconds\n",
            "Batch 134/237 - Batch Inference Time: 1.2693 seconds\n",
            "Batch 135/237 - Batch Inference Time: 1.2800 seconds\n",
            "Batch 136/237 - Batch Inference Time: 2.1333 seconds\n",
            "Batch 137/237 - Batch Inference Time: 1.6911 seconds\n",
            "Batch 138/237 - Batch Inference Time: 1.3442 seconds\n",
            "Batch 139/237 - Batch Inference Time: 1.3186 seconds\n",
            "Batch 140/237 - Batch Inference Time: 1.3481 seconds\n",
            "Batch 141/237 - Batch Inference Time: 1.2682 seconds\n",
            "Batch 142/237 - Batch Inference Time: 1.3441 seconds\n",
            "Batch 143/237 - Batch Inference Time: 1.3323 seconds\n",
            "Batch 144/237 - Batch Inference Time: 1.2600 seconds\n",
            "Batch 145/237 - Batch Inference Time: 1.5182 seconds\n",
            "Batch 146/237 - Batch Inference Time: 1.7625 seconds\n",
            "Batch 147/237 - Batch Inference Time: 1.9070 seconds\n",
            "Batch 148/237 - Batch Inference Time: 1.3506 seconds\n",
            "Batch 149/237 - Batch Inference Time: 1.3319 seconds\n",
            "Batch 150/237 - Batch Inference Time: 1.3086 seconds\n",
            "Batch 151/237 - Batch Inference Time: 1.3281 seconds\n",
            "Batch 152/237 - Batch Inference Time: 1.2597 seconds\n",
            "Batch 153/237 - Batch Inference Time: 1.2723 seconds\n",
            "Batch 154/237 - Batch Inference Time: 1.3796 seconds\n",
            "Batch 155/237 - Batch Inference Time: 1.6932 seconds\n",
            "Batch 156/237 - Batch Inference Time: 1.7221 seconds\n",
            "Batch 157/237 - Batch Inference Time: 1.8040 seconds\n",
            "Batch 158/237 - Batch Inference Time: 1.2818 seconds\n",
            "Batch 159/237 - Batch Inference Time: 1.2526 seconds\n",
            "Batch 160/237 - Batch Inference Time: 1.3196 seconds\n",
            "Batch 161/237 - Batch Inference Time: 1.3538 seconds\n",
            "Batch 162/237 - Batch Inference Time: 1.2671 seconds\n",
            "Batch 163/237 - Batch Inference Time: 1.2745 seconds\n",
            "Batch 164/237 - Batch Inference Time: 1.4549 seconds\n",
            "Batch 165/237 - Batch Inference Time: 1.7542 seconds\n",
            "Batch 166/237 - Batch Inference Time: 1.7378 seconds\n",
            "Batch 167/237 - Batch Inference Time: 1.6852 seconds\n",
            "Batch 168/237 - Batch Inference Time: 1.3045 seconds\n",
            "Batch 169/237 - Batch Inference Time: 1.2812 seconds\n",
            "Batch 170/237 - Batch Inference Time: 1.2849 seconds\n",
            "Batch 171/237 - Batch Inference Time: 1.2593 seconds\n",
            "Batch 172/237 - Batch Inference Time: 1.3632 seconds\n",
            "Batch 173/237 - Batch Inference Time: 1.2871 seconds\n",
            "Batch 174/237 - Batch Inference Time: 1.6198 seconds\n",
            "Batch 175/237 - Batch Inference Time: 2.1720 seconds\n",
            "Batch 176/237 - Batch Inference Time: 1.4736 seconds\n",
            "Batch 177/237 - Batch Inference Time: 1.3585 seconds\n",
            "Batch 178/237 - Batch Inference Time: 1.2732 seconds\n",
            "Batch 179/237 - Batch Inference Time: 1.2816 seconds\n",
            "Batch 180/237 - Batch Inference Time: 1.3232 seconds\n",
            "Batch 181/237 - Batch Inference Time: 1.3204 seconds\n",
            "Batch 182/237 - Batch Inference Time: 1.3411 seconds\n",
            "Batch 183/237 - Batch Inference Time: 1.4219 seconds\n",
            "Batch 184/237 - Batch Inference Time: 1.7471 seconds\n",
            "Batch 185/237 - Batch Inference Time: 1.7394 seconds\n",
            "Batch 186/237 - Batch Inference Time: 1.3578 seconds\n",
            "Batch 187/237 - Batch Inference Time: 1.6917 seconds\n",
            "Batch 188/237 - Batch Inference Time: 1.2680 seconds\n",
            "Batch 189/237 - Batch Inference Time: 1.2819 seconds\n",
            "Batch 190/237 - Batch Inference Time: 1.3630 seconds\n",
            "Batch 191/237 - Batch Inference Time: 1.3321 seconds\n",
            "Batch 192/237 - Batch Inference Time: 1.2879 seconds\n",
            "Batch 193/237 - Batch Inference Time: 1.5429 seconds\n",
            "Batch 194/237 - Batch Inference Time: 1.6931 seconds\n",
            "Batch 195/237 - Batch Inference Time: 1.5597 seconds\n",
            "Batch 196/237 - Batch Inference Time: 1.2712 seconds\n",
            "Batch 197/237 - Batch Inference Time: 1.6221 seconds\n",
            "Batch 198/237 - Batch Inference Time: 1.3019 seconds\n",
            "Batch 199/237 - Batch Inference Time: 1.2800 seconds\n",
            "Batch 200/237 - Batch Inference Time: 1.3610 seconds\n",
            "Batch 201/237 - Batch Inference Time: 1.3046 seconds\n",
            "Batch 202/237 - Batch Inference Time: 1.2777 seconds\n",
            "Batch 203/237 - Batch Inference Time: 1.5837 seconds\n",
            "Batch 204/237 - Batch Inference Time: 1.7136 seconds\n",
            "Batch 205/237 - Batch Inference Time: 1.4738 seconds\n",
            "Batch 206/237 - Batch Inference Time: 1.6169 seconds\n",
            "Batch 207/237 - Batch Inference Time: 1.2746 seconds\n",
            "Batch 208/237 - Batch Inference Time: 1.2698 seconds\n",
            "Batch 209/237 - Batch Inference Time: 1.3530 seconds\n",
            "Batch 210/237 - Batch Inference Time: 1.3426 seconds\n",
            "Batch 211/237 - Batch Inference Time: 1.2652 seconds\n",
            "Batch 212/237 - Batch Inference Time: 1.4141 seconds\n",
            "Batch 213/237 - Batch Inference Time: 1.7392 seconds\n",
            "Batch 214/237 - Batch Inference Time: 1.7415 seconds\n",
            "Batch 215/237 - Batch Inference Time: 1.7108 seconds\n",
            "Batch 216/237 - Batch Inference Time: 1.2476 seconds\n",
            "Batch 217/237 - Batch Inference Time: 1.3192 seconds\n",
            "Batch 218/237 - Batch Inference Time: 1.2853 seconds\n",
            "Batch 219/237 - Batch Inference Time: 1.3298 seconds\n",
            "Batch 220/237 - Batch Inference Time: 1.3409 seconds\n",
            "Batch 221/237 - Batch Inference Time: 1.2851 seconds\n",
            "Batch 222/237 - Batch Inference Time: 1.5889 seconds\n",
            "Batch 223/237 - Batch Inference Time: 1.7219 seconds\n",
            "Batch 224/237 - Batch Inference Time: 1.5246 seconds\n",
            "Batch 225/237 - Batch Inference Time: 1.2571 seconds\n",
            "Batch 226/237 - Batch Inference Time: 1.6514 seconds\n",
            "Batch 227/237 - Batch Inference Time: 1.3411 seconds\n",
            "Batch 228/237 - Batch Inference Time: 1.3007 seconds\n",
            "Batch 229/237 - Batch Inference Time: 1.3295 seconds\n",
            "Batch 230/237 - Batch Inference Time: 1.3508 seconds\n",
            "Batch 231/237 - Batch Inference Time: 1.2801 seconds\n",
            "Batch 232/237 - Batch Inference Time: 1.6789 seconds\n",
            "Batch 233/237 - Batch Inference Time: 1.6997 seconds\n",
            "Batch 234/237 - Batch Inference Time: 1.5442 seconds\n",
            "Batch 235/237 - Batch Inference Time: 1.2444 seconds\n",
            "Batch 236/237 - Batch Inference Time: 1.5746 seconds\n",
            "Batch 237/237 - Batch Inference Time: 1.3302 seconds\n",
            "\n",
            "Testing completed: Testing Accuracy = 0.8487\n",
            "Average Inference Time per Batch: 1.4777 seconds\n",
            "Total Inference Time: 350.22 seconds\n",
            "Total Communication Overhead:\n",
            "  Bytes Sent: 577387120 bytes\n",
            "  Bytes Received: 2607 bytes\n",
            "  Total: 577389727 bytes\n",
            "\n",
            "Client connection closed.\n"
          ]
        }
      ],
      "source": [
        "import socket\n",
        "import pickle\n",
        "import zlib\n",
        "import time\n",
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "from tensorflow.keras import Sequential\n",
        "from tensorflow.keras.layers import Conv1D, MaxPooling1D, BatchNormalization\n",
        "from sklearn.model_selection import train_test_split\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "\n",
        "# Client-side model\n",
        "def create_client_model():\n",
        "    model = Sequential([\n",
        "        Conv1D(16, kernel_size=3, activation='relu', input_shape=(40, 1),padding='same'),\n",
        "        BatchNormalization(),\n",
        "        Conv1D(32, kernel_size=3, activation='relu',padding='same'),\n",
        "        BatchNormalization(),\n",
        "        #MaxPooling1D(pool_size=2),\n",
        "        Conv1D(32, kernel_size=3, activation='relu',padding='same'),\n",
        "        BatchNormalization(),\n",
        "        #MaxPooling1D(pool_size=2),\n",
        "        Conv1D(64, kernel_size=3, activation='relu',padding='same'),\n",
        "        BatchNormalization(),\n",
        "        Conv1D(64, kernel_size=3, activation='relu',padding='same'),\n",
        "        BatchNormalization(),\n",
        "        MaxPooling1D(pool_size=2),\n",
        "\n",
        "    ])\n",
        "    return model\n",
        "\n",
        "# Serialize and compress data using pickle\n",
        "def serialize_data(data):\n",
        "    return zlib.compress(pickle.dumps(data))\n",
        "\n",
        "# Client function\n",
        "def start_client(host='127.0.0.1', port=65437):\n",
        "    client_model = create_client_model()\n",
        "    client_socket = socket.socket(socket.AF_INET, socket.SOCK_STREAM)\n",
        "    client_socket.connect((host, port))\n",
        "    print(\"Connected to server!\")\n",
        "\n",
        "    batch_size = 512\n",
        "    epochs =  10\n",
        "    total_batches = int(np.ceil(X_train_scaled.shape[0] / batch_size))\n",
        "\n",
        "    print(\"\\nStarting Training...\")\n",
        "    start_time = time.time()\n",
        "\n",
        "    for epoch in range(epochs):\n",
        "        print(f\"\\nEpoch {epoch + 1}/{epochs}\")\n",
        "        epoch_loss = 0\n",
        "        correct_predictions = 0\n",
        "        total_samples = 0\n",
        "\n",
        "        for batch_index, i in enumerate(range(0, X_train_scaled.shape[0], batch_size), start=1):\n",
        "            x_batch = X_train_scaled[i:min(i + batch_size, X_train_scaled.shape[0])]\n",
        "            y_batch = y_train[i:min(i + batch_size, y_train.shape[0])]\n",
        "\n",
        "            # Forward pass to get intermediate activations\n",
        "            intermediate_output = client_model(x_batch, training=True).numpy()\n",
        "\n",
        "            # Serialize and send data\n",
        "            data = serialize_data((intermediate_output.tolist(), y_batch.tolist()))\n",
        "            client_socket.sendall(f\"{len(data):08}\".encode('utf-8'))\n",
        "            client_socket.sendall(data)\n",
        "\n",
        "            # Receive server response\n",
        "            response_header = client_socket.recv(8)\n",
        "            response_size = int(response_header.decode('utf-8').strip())\n",
        "            response = client_socket.recv(response_size)\n",
        "            server_loss, batch_correct = map(float, response.decode('utf-8').split(','))\n",
        "\n",
        "            # Update statistics\n",
        "            epoch_loss += server_loss\n",
        "            correct_predictions += batch_correct\n",
        "            total_samples += x_batch.shape[0]\n",
        "\n",
        "            # Display batch progress\n",
        "            progress = (batch_index / total_batches) * 100\n",
        "            print(f\"\\rBatch {batch_index}/{total_batches} - Progress: {progress:.2f}% - Loss: {server_loss:.4f}\", end=\"\")\n",
        "\n",
        "        training_accuracy = correct_predictions / total_samples\n",
        "        print(f\"\\nEpoch {epoch + 1} completed: Avg Loss = {epoch_loss / total_batches:.4f}, \"\n",
        "              f\"Training Accuracy = {training_accuracy:.4f}\")\n",
        "\n",
        "    total_training_time = time.time() - start_time\n",
        "    print(f\"\\nTraining completed in {total_training_time:.2f} seconds.\")\n",
        "\n",
        "    # Signal the server to switch to evaluation mode\n",
        "    client_socket.sendall(f\"{-1:08}\".encode('utf-8'))\n",
        "    print(\"Training complete. Signaled server to start evaluation.\")\n",
        "\n",
        "        # Evaluate testing accuracy in batches\n",
        "    print(\"\\nEvaluating on test data...\")\n",
        "    test_batch_size = 512  # Larger batch size for efficient testing\n",
        "    total_test_batches = int(np.ceil(X_test_scaled.shape[0] / test_batch_size))\n",
        "    correct_predictions = 0\n",
        "    total_samples = 0\n",
        "    total_inference_time = 0\n",
        "    total_bytes_sent = 0\n",
        "    total_bytes_received = 0\n",
        "\n",
        "    for batch_num, i in enumerate(range(0, X_test_scaled.shape[0], test_batch_size), start=1):\n",
        "        x_test_batch = X_test_scaled[i:min(i + test_batch_size, X_test_scaled.shape[0])]\n",
        "        y_test_batch = y_test[i:min(i + test_batch_size, y_test.shape[0])]\n",
        "\n",
        "        # Start timing the inference\n",
        "        start_infer_time = time.time()\n",
        "\n",
        "        test_intermediate = client_model.predict(x_test_batch, verbose=0)\n",
        "        test_data = serialize_data((test_intermediate.tolist(), y_test_batch.tolist()))\n",
        "        data_length = len(test_data)\n",
        "        client_socket.sendall(f\"{len(test_data):08}\".encode('utf-8'))\n",
        "        client_socket.sendall(test_data)\n",
        "        total_bytes_sent += 8 + data_length\n",
        "        test_accuracy_response = client_socket.recv(8)\n",
        "        test_accuracy_size = int(test_accuracy_response.decode('utf-8').strip())\n",
        "        test_accuracy_data = client_socket.recv(test_accuracy_size)\n",
        "        batch_correct = int(test_accuracy_data.decode('utf-8'))\n",
        "        total_bytes_received += 8 + test_accuracy_size  # 8 bytes for header + actual data\n",
        "\n",
        "        # Stop timing and accumulate\n",
        "        end_infer_time = time.time()\n",
        "        batch_inference_time = end_infer_time - start_infer_time\n",
        "        total_inference_time += batch_inference_time\n",
        "\n",
        "        print(f\"Batch {batch_num}/{total_test_batches} - Batch Inference Time: {batch_inference_time:.4f} seconds\")\n",
        "\n",
        "        correct_predictions += batch_correct\n",
        "        total_samples += x_test_batch.shape[0]\n",
        "\n",
        "    test_accuracy = correct_predictions / total_samples\n",
        "    avg_inference_time = total_inference_time / total_test_batches\n",
        "    print(f\"\\nTesting completed: Testing Accuracy = {test_accuracy:.4f}\")\n",
        "    print(f\"Average Inference Time per Batch: {avg_inference_time:.4f} seconds\")\n",
        "    print(f\"Total Inference Time: {total_inference_time:.2f} seconds\")\n",
        "    print(f\"Total Communication Overhead:\")\n",
        "    print(f\"  Bytes Sent: {total_bytes_sent} bytes\")\n",
        "    print(f\"  Bytes Received: {total_bytes_received} bytes\")\n",
        "    print(f\"  Total: {total_bytes_sent + total_bytes_received} bytes\")\n",
        "\n",
        "    client_socket.close()\n",
        "    print(\"\\nClient connection closed.\")\n",
        "\n",
        "# Start the client\n",
        "start_client()\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "o3XXk8UyifsG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "rVp9HzT-if2g"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "hWDM5LFcif5r"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "_vzkpsf4if8w"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "BPEoDRh-igAZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gG2zHtgtdW_I"
      },
      "outputs": [],
      "source": [
        "import socket\n",
        "import pickle\n",
        "import zlib\n",
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "from tensorflow.keras import Sequential\n",
        "from tensorflow.keras.layers import MaxPooling1D, Flatten, Dense, BatchNormalization\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "import threading\n",
        "from sklearn.metrics import precision_score, recall_score, f1_score\n",
        "from tensorflow.keras.layers import Dropout\n",
        "\n",
        "# Server-side model\n",
        "def create_server_model():\n",
        "    model = Sequential([\n",
        "        MaxPooling1D(pool_size=2,input_shape=(20, 64)),\n",
        "        Conv1D(128, kernel_size=3, activation='relu',padding='same'),\n",
        "        BatchNormalization(),\n",
        "        Conv1D(128, kernel_size=3, activation='relu',padding='same'),\n",
        "        BatchNormalization(),\n",
        "        MaxPooling1D(pool_size=2),\n",
        "        Conv1D(256, kernel_size=3, activation='relu',padding='same'),\n",
        "        BatchNormalization(),\n",
        "        Conv1D(256, kernel_size=3, activation='relu',padding='same'),\n",
        "        BatchNormalization(),\n",
        "        MaxPooling1D(pool_size=2),\n",
        "        Flatten(),\n",
        "        Dense(256, activation='relu'),\n",
        "        Dropout(0.3),\n",
        "        Dense(128, activation='relu'),\n",
        "        Dropout(0.2),\n",
        "        Dense(11, activation='softmax')\n",
        "    ])\n",
        "    model.compile(optimizer=Adam(learning_rate=0.001),\n",
        "                  loss='categorical_crossentropy',\n",
        "                  metrics=['accuracy'])\n",
        "    return model\n",
        "\n",
        "# Deserialize and decompress data\n",
        "def deserialize_data(data):\n",
        "    return pickle.loads(zlib.decompress(data))\n",
        "\n",
        "# Server function\n",
        "def start_server(host='127.0.0.1', port=65437):\n",
        "    server_model = create_server_model()\n",
        "    server_socket = socket.socket(socket.AF_INET, socket.SOCK_STREAM)\n",
        "    server_socket.bind((host, port))\n",
        "    server_socket.listen(1)\n",
        "    print(\"Server waiting for connection...\")\n",
        "    conn, addr = server_socket.accept()\n",
        "    print(f\"Connected to client: {addr}\")\n",
        "    lr_schedule = tf.keras.optimizers.schedules.ExponentialDecay(\n",
        "    initial_learning_rate=0.001,\n",
        "    decay_steps=10000,\n",
        "    decay_rate=0.9\n",
        "    )\n",
        "    optimizer = tf.keras.optimizers.Adam(learning_rate=lr_schedule)\n",
        "\n",
        "    all_true_labels = []\n",
        "    all_pred_labels = []\n",
        "\n",
        "\n",
        "    while True:\n",
        "        try:\n",
        "            # Receive header indicating batch size\n",
        "            header = conn.recv(8)\n",
        "            if not header:\n",
        "                break\n",
        "            data_size = int(header.decode('utf-8').strip())\n",
        "\n",
        "\n",
        "            # If a special flag (e.g., -1) is sent, switch to evaluation\n",
        "            if data_size == -1:\n",
        "              print(\"Switching to evaluation phase...\")\n",
        "              break\n",
        "\n",
        "            # Receive the batch data\n",
        "            data = b\"\"\n",
        "            while len(data) < data_size:\n",
        "                packet = conn.recv(4096)\n",
        "                if not packet:\n",
        "                    break\n",
        "                data += packet\n",
        "\n",
        "            # Deserialize the data\n",
        "            intermediate_output, labels = deserialize_data(data)\n",
        "\n",
        "            # Perform forward pass and backpropagation on batch\n",
        "            with tf.GradientTape() as tape:\n",
        "                logits = server_model(np.array(intermediate_output), training=True)\n",
        "                loss = tf.reduce_mean(\n",
        "                    tf.keras.losses.categorical_crossentropy(np.array(labels), logits)\n",
        "                )\n",
        "            gradients = tape.gradient(loss, server_model.trainable_variables)\n",
        "            optimizer.apply_gradients(zip(gradients, server_model.trainable_variables))\n",
        "\n",
        "            pred_classes = np.argmax(logits.numpy(), axis=1)\n",
        "            true_classes = np.argmax(labels, axis=1)\n",
        "\n",
        "            all_pred_labels.extend(pred_classes)\n",
        "            all_true_labels.extend(true_classes)\n",
        "\n",
        "            correct_predictions = int(np.sum(\n",
        "                np.argmax(logits.numpy(), axis=1) == np.argmax(labels, axis=1)\n",
        "            ))\n",
        "            response = f\"{loss.numpy():.4f},{correct_predictions}\"\n",
        "            conn.sendall(f\"{len(response):08}\".encode('utf-8'))\n",
        "            conn.sendall(response.encode('utf-8'))\n",
        "\n",
        "        except Exception as e:\n",
        "            print(f\"Error: {e}\")\n",
        "            break\n",
        "\n",
        "    # At the end of training\n",
        "    precision = precision_score(all_true_labels, all_pred_labels, average='macro')\n",
        "    recall = recall_score(all_true_labels, all_pred_labels, average='macro')\n",
        "    f1 = f1_score(all_true_labels, all_pred_labels, average='macro')\n",
        "    print(f\"\\nTraining Metrics → Precision: {precision:.4f}, Recall: {recall:.4f}, F1 Score: {f1:.4f}\")\n",
        "\n",
        "    # Handle test evaluation\n",
        "    print(\"Evaluating test data...\")\n",
        "\n",
        "    all_test_true = []\n",
        "    all_test_pred = []\n",
        "\n",
        "    while True:\n",
        "        header = conn.recv(8)\n",
        "        if not header:\n",
        "            break\n",
        "        test_data_size = int(header.decode('utf-8').strip())\n",
        "        test_data = b\"\"\n",
        "        while len(test_data) < test_data_size:\n",
        "            packet = conn.recv(4096)\n",
        "            if not packet:\n",
        "                break\n",
        "            test_data += packet\n",
        "\n",
        "        test_intermediate, test_labels = deserialize_data(test_data)\n",
        "        logits = server_model(np.array(test_intermediate), training=False)\n",
        "\n",
        "        test_intermediate = np.array(test_intermediate)\n",
        "        test_labels = np.array(test_labels)\n",
        "\n",
        "        logits = server_model(test_intermediate, training=False)\n",
        "        pred_classes = np.argmax(logits.numpy(), axis=1)\n",
        "        true_classes = np.argmax(test_labels, axis=1)\n",
        "\n",
        "        all_test_pred.extend(pred_classes)\n",
        "        all_test_true.extend(true_classes)\n",
        "\n",
        "        correct_predictions = int(np.sum(\n",
        "            np.argmax(logits.numpy(), axis=1) == np.argmax(test_labels, axis=1)\n",
        "        ))\n",
        "        response = f\"{correct_predictions}\"\n",
        "        conn.sendall(f\"{len(response):08}\".encode('utf-8'))\n",
        "        conn.sendall(response.encode('utf-8'))\n",
        "\n",
        "    # Final test metrics\n",
        "    precision = precision_score(all_test_true, all_test_pred, average='macro')\n",
        "    recall = recall_score(all_test_true, all_test_pred, average='macro')\n",
        "    f1 = f1_score(all_test_true, all_test_pred, average='macro')\n",
        "    conf_matrix_test = confusion_matrix(all_test_true, all_test_pred)\n",
        "    print(f\"\\nTesting Metrics → Precision: {precision:.4f}, Recall: {recall:.4f}, F1 Score: {f1:.4f}\")\n",
        "    print(\"Testing Confusion Matrix:\\n\", conf_matrix_test)\n",
        "\n",
        "\n",
        "    conn.close()\n",
        "    server_socket.close()\n",
        "    print(\"Server connection closed.\")\n",
        "\n",
        "server_thread = threading.Thread(target=start_server)\n",
        "server_thread.start()\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "GAjSknDvJ4xo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "04435bda-dcd8-4010-f421-10f979fb2cbd",
        "id": "3UjmKGLpda-M"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Connected to server!\n",
            "\n",
            "Starting Training...\n",
            "\n",
            "Epoch 1/10\n",
            "Connected to client: ('127.0.0.1', 60986)\n",
            "Batch 553/553 - Progress: 100.00% - Loss: 0.1958\n",
            "Epoch 1 completed: Avg Loss = 0.2466, Training Accuracy = 0.8594\n",
            "\n",
            "Epoch 2/10\n",
            "Batch 553/553 - Progress: 100.00% - Loss: 0.1815\n",
            "Epoch 2 completed: Avg Loss = 0.1716, Training Accuracy = 0.8909\n",
            "\n",
            "Epoch 3/10\n",
            "Batch 553/553 - Progress: 100.00% - Loss: 0.1636\n",
            "Epoch 3 completed: Avg Loss = 0.1571, Training Accuracy = 0.8976\n",
            "\n",
            "Epoch 4/10\n",
            "Batch 553/553 - Progress: 100.00% - Loss: 0.1509\n",
            "Epoch 4 completed: Avg Loss = 0.1497, Training Accuracy = 0.9012\n",
            "\n",
            "Epoch 5/10\n",
            "Batch 553/553 - Progress: 100.00% - Loss: 0.1345\n",
            "Epoch 5 completed: Avg Loss = 0.1457, Training Accuracy = 0.9023\n",
            "\n",
            "Epoch 6/10\n",
            "Batch 553/553 - Progress: 100.00% - Loss: 0.1583\n",
            "Epoch 6 completed: Avg Loss = 0.1413, Training Accuracy = 0.9042\n",
            "\n",
            "Epoch 7/10\n",
            "Batch 553/553 - Progress: 100.00% - Loss: 0.1431\n",
            "Epoch 7 completed: Avg Loss = 0.1419, Training Accuracy = 0.9033\n",
            "\n",
            "Epoch 8/10\n",
            "Batch 553/553 - Progress: 100.00% - Loss: 0.1252\n",
            "Epoch 8 completed: Avg Loss = 0.1396, Training Accuracy = 0.9046\n",
            "\n",
            "Epoch 9/10\n",
            "Batch 553/553 - Progress: 100.00% - Loss: 0.1532\n",
            "Epoch 9 completed: Avg Loss = 0.1391, Training Accuracy = 0.9051\n",
            "\n",
            "Epoch 10/10\n",
            "Batch 553/553 - Progress: 100.00% - Loss: 0.1398\n",
            "Epoch 10 completed: Avg Loss = 0.1375, Training Accuracy = 0.9049\n",
            "\n",
            "Training completed in 5487.16 seconds.\n",
            "Switching to evaluation phase...\n",
            "Training complete. Signaled server to start evaluation.\n",
            "\n",
            "Evaluating on test data...\n",
            "\n",
            "Training Metrics → Precision: 0.8974, Recall: 0.8974, F1 Score: 0.8974\n",
            "Evaluating test data...\n",
            "Batch 1/237 - Batch Inference Time: 8.6377 seconds\n",
            "Batch 2/237 - Batch Inference Time: 0.9491 seconds\n",
            "Batch 3/237 - Batch Inference Time: 0.9259 seconds\n",
            "Batch 4/237 - Batch Inference Time: 0.9530 seconds\n",
            "Batch 5/237 - Batch Inference Time: 1.1943 seconds\n",
            "Batch 6/237 - Batch Inference Time: 0.9520 seconds\n",
            "Batch 7/237 - Batch Inference Time: 0.9188 seconds\n",
            "Batch 8/237 - Batch Inference Time: 0.9406 seconds\n",
            "Batch 9/237 - Batch Inference Time: 0.9657 seconds\n",
            "Batch 10/237 - Batch Inference Time: 0.9648 seconds\n",
            "Batch 11/237 - Batch Inference Time: 0.9180 seconds\n",
            "Batch 12/237 - Batch Inference Time: 0.9517 seconds\n",
            "Batch 13/237 - Batch Inference Time: 0.9279 seconds\n",
            "Batch 14/237 - Batch Inference Time: 1.2281 seconds\n",
            "Batch 15/237 - Batch Inference Time: 0.9156 seconds\n",
            "Batch 16/237 - Batch Inference Time: 0.9215 seconds\n",
            "Batch 17/237 - Batch Inference Time: 0.9260 seconds\n",
            "Batch 18/237 - Batch Inference Time: 0.9422 seconds\n",
            "Batch 19/237 - Batch Inference Time: 0.9517 seconds\n",
            "Batch 20/237 - Batch Inference Time: 0.9604 seconds\n",
            "Batch 21/237 - Batch Inference Time: 0.9180 seconds\n",
            "Batch 22/237 - Batch Inference Time: 0.9524 seconds\n",
            "Batch 23/237 - Batch Inference Time: 0.9144 seconds\n",
            "Batch 24/237 - Batch Inference Time: 0.9727 seconds\n",
            "Batch 25/237 - Batch Inference Time: 1.2487 seconds\n",
            "Batch 26/237 - Batch Inference Time: 0.9423 seconds\n",
            "Batch 27/237 - Batch Inference Time: 0.9337 seconds\n",
            "Batch 28/237 - Batch Inference Time: 0.9443 seconds\n",
            "Batch 29/237 - Batch Inference Time: 0.9491 seconds\n",
            "Batch 30/237 - Batch Inference Time: 0.9329 seconds\n",
            "Batch 31/237 - Batch Inference Time: 0.9542 seconds\n",
            "Batch 32/237 - Batch Inference Time: 0.9381 seconds\n",
            "Batch 33/237 - Batch Inference Time: 0.9660 seconds\n",
            "Batch 34/237 - Batch Inference Time: 0.9446 seconds\n",
            "Batch 35/237 - Batch Inference Time: 0.9341 seconds\n",
            "Batch 36/237 - Batch Inference Time: 1.2199 seconds\n",
            "Batch 37/237 - Batch Inference Time: 0.9383 seconds\n",
            "Batch 38/237 - Batch Inference Time: 0.9326 seconds\n",
            "Batch 39/237 - Batch Inference Time: 0.9373 seconds\n",
            "Batch 40/237 - Batch Inference Time: 0.9406 seconds\n",
            "Batch 41/237 - Batch Inference Time: 0.9278 seconds\n",
            "Batch 42/237 - Batch Inference Time: 0.9467 seconds\n",
            "Batch 43/237 - Batch Inference Time: 0.9417 seconds\n",
            "Batch 44/237 - Batch Inference Time: 0.9395 seconds\n",
            "Batch 45/237 - Batch Inference Time: 0.9545 seconds\n",
            "Batch 46/237 - Batch Inference Time: 1.2647 seconds\n",
            "Batch 47/237 - Batch Inference Time: 0.9554 seconds\n",
            "Batch 48/237 - Batch Inference Time: 0.9453 seconds\n",
            "Batch 49/237 - Batch Inference Time: 0.9391 seconds\n",
            "Batch 50/237 - Batch Inference Time: 0.9529 seconds\n",
            "Batch 51/237 - Batch Inference Time: 0.9422 seconds\n",
            "Batch 52/237 - Batch Inference Time: 0.9329 seconds\n",
            "Batch 53/237 - Batch Inference Time: 0.9440 seconds\n",
            "Batch 54/237 - Batch Inference Time: 0.9381 seconds\n",
            "Batch 55/237 - Batch Inference Time: 0.9580 seconds\n",
            "Batch 56/237 - Batch Inference Time: 1.2512 seconds\n",
            "Batch 57/237 - Batch Inference Time: 0.9433 seconds\n",
            "Batch 58/237 - Batch Inference Time: 0.9617 seconds\n",
            "Batch 59/237 - Batch Inference Time: 0.9434 seconds\n",
            "Batch 60/237 - Batch Inference Time: 0.9378 seconds\n",
            "Batch 61/237 - Batch Inference Time: 0.9374 seconds\n",
            "Batch 62/237 - Batch Inference Time: 0.9516 seconds\n",
            "Batch 63/237 - Batch Inference Time: 0.9510 seconds\n",
            "Batch 64/237 - Batch Inference Time: 0.9127 seconds\n",
            "Batch 65/237 - Batch Inference Time: 0.9176 seconds\n",
            "Batch 66/237 - Batch Inference Time: 0.9551 seconds\n",
            "Batch 67/237 - Batch Inference Time: 1.2302 seconds\n",
            "Batch 68/237 - Batch Inference Time: 0.9435 seconds\n",
            "Batch 69/237 - Batch Inference Time: 0.9601 seconds\n",
            "Batch 70/237 - Batch Inference Time: 0.9632 seconds\n",
            "Batch 71/237 - Batch Inference Time: 0.9811 seconds\n",
            "Batch 72/237 - Batch Inference Time: 0.9470 seconds\n",
            "Batch 73/237 - Batch Inference Time: 0.9352 seconds\n",
            "Batch 74/237 - Batch Inference Time: 0.9227 seconds\n",
            "Batch 75/237 - Batch Inference Time: 0.9315 seconds\n",
            "Batch 76/237 - Batch Inference Time: 0.9357 seconds\n",
            "Batch 77/237 - Batch Inference Time: 1.2141 seconds\n",
            "Batch 78/237 - Batch Inference Time: 0.9346 seconds\n",
            "Batch 79/237 - Batch Inference Time: 0.9235 seconds\n",
            "Batch 80/237 - Batch Inference Time: 0.9162 seconds\n",
            "Batch 81/237 - Batch Inference Time: 0.9748 seconds\n",
            "Batch 82/237 - Batch Inference Time: 0.9591 seconds\n",
            "Batch 83/237 - Batch Inference Time: 0.9581 seconds\n",
            "Batch 84/237 - Batch Inference Time: 0.9457 seconds\n",
            "Batch 85/237 - Batch Inference Time: 0.9334 seconds\n",
            "Batch 86/237 - Batch Inference Time: 0.9542 seconds\n",
            "Batch 87/237 - Batch Inference Time: 1.2336 seconds\n",
            "Batch 88/237 - Batch Inference Time: 0.9502 seconds\n",
            "Batch 89/237 - Batch Inference Time: 0.9370 seconds\n",
            "Batch 90/237 - Batch Inference Time: 0.9291 seconds\n",
            "Batch 91/237 - Batch Inference Time: 0.9192 seconds\n",
            "Batch 92/237 - Batch Inference Time: 0.9520 seconds\n",
            "Batch 93/237 - Batch Inference Time: 0.9267 seconds\n",
            "Batch 94/237 - Batch Inference Time: 0.9606 seconds\n",
            "Batch 95/237 - Batch Inference Time: 0.9399 seconds\n",
            "Batch 96/237 - Batch Inference Time: 0.9407 seconds\n",
            "Batch 97/237 - Batch Inference Time: 1.2237 seconds\n",
            "Batch 98/237 - Batch Inference Time: 0.9312 seconds\n",
            "Batch 99/237 - Batch Inference Time: 0.9452 seconds\n",
            "Batch 100/237 - Batch Inference Time: 0.9660 seconds\n",
            "Batch 101/237 - Batch Inference Time: 0.9310 seconds\n",
            "Batch 102/237 - Batch Inference Time: 0.9358 seconds\n",
            "Batch 103/237 - Batch Inference Time: 0.9348 seconds\n",
            "Batch 104/237 - Batch Inference Time: 0.9449 seconds\n",
            "Batch 105/237 - Batch Inference Time: 0.9449 seconds\n",
            "Batch 106/237 - Batch Inference Time: 0.9127 seconds\n",
            "Batch 107/237 - Batch Inference Time: 0.9558 seconds\n",
            "Batch 108/237 - Batch Inference Time: 1.2463 seconds\n",
            "Batch 109/237 - Batch Inference Time: 0.9525 seconds\n",
            "Batch 110/237 - Batch Inference Time: 0.9463 seconds\n",
            "Batch 111/237 - Batch Inference Time: 0.9556 seconds\n",
            "Batch 112/237 - Batch Inference Time: 0.9734 seconds\n",
            "Batch 113/237 - Batch Inference Time: 0.9400 seconds\n",
            "Batch 114/237 - Batch Inference Time: 0.9327 seconds\n",
            "Batch 115/237 - Batch Inference Time: 0.9491 seconds\n",
            "Batch 116/237 - Batch Inference Time: 0.9287 seconds\n",
            "Batch 117/237 - Batch Inference Time: 0.9661 seconds\n",
            "Batch 118/237 - Batch Inference Time: 1.2393 seconds\n",
            "Batch 119/237 - Batch Inference Time: 0.9394 seconds\n",
            "Batch 120/237 - Batch Inference Time: 0.9570 seconds\n",
            "Batch 121/237 - Batch Inference Time: 0.9374 seconds\n",
            "Batch 122/237 - Batch Inference Time: 0.9402 seconds\n",
            "Batch 123/237 - Batch Inference Time: 0.9353 seconds\n",
            "Batch 124/237 - Batch Inference Time: 0.9414 seconds\n",
            "Batch 125/237 - Batch Inference Time: 0.9209 seconds\n",
            "Batch 126/237 - Batch Inference Time: 0.9425 seconds\n",
            "Batch 127/237 - Batch Inference Time: 0.9497 seconds\n",
            "Batch 128/237 - Batch Inference Time: 1.2179 seconds\n",
            "Batch 129/237 - Batch Inference Time: 0.9378 seconds\n",
            "Batch 130/237 - Batch Inference Time: 0.9430 seconds\n",
            "Batch 131/237 - Batch Inference Time: 0.9404 seconds\n",
            "Batch 132/237 - Batch Inference Time: 0.9563 seconds\n",
            "Batch 133/237 - Batch Inference Time: 0.9741 seconds\n",
            "Batch 134/237 - Batch Inference Time: 0.9327 seconds\n",
            "Batch 135/237 - Batch Inference Time: 0.9443 seconds\n",
            "Batch 136/237 - Batch Inference Time: 0.9333 seconds\n",
            "Batch 137/237 - Batch Inference Time: 0.9479 seconds\n",
            "Batch 138/237 - Batch Inference Time: 1.2112 seconds\n",
            "Batch 139/237 - Batch Inference Time: 0.9256 seconds\n",
            "Batch 140/237 - Batch Inference Time: 0.9570 seconds\n",
            "Batch 141/237 - Batch Inference Time: 0.9211 seconds\n",
            "Batch 142/237 - Batch Inference Time: 0.9806 seconds\n",
            "Batch 143/237 - Batch Inference Time: 0.9471 seconds\n",
            "Batch 144/237 - Batch Inference Time: 0.9745 seconds\n",
            "Batch 145/237 - Batch Inference Time: 0.9654 seconds\n",
            "Batch 146/237 - Batch Inference Time: 0.9383 seconds\n",
            "Batch 147/237 - Batch Inference Time: 0.9546 seconds\n",
            "Batch 148/237 - Batch Inference Time: 0.9393 seconds\n",
            "Batch 149/237 - Batch Inference Time: 1.2162 seconds\n",
            "Batch 150/237 - Batch Inference Time: 0.9373 seconds\n",
            "Batch 151/237 - Batch Inference Time: 0.9402 seconds\n",
            "Batch 152/237 - Batch Inference Time: 0.9450 seconds\n",
            "Batch 153/237 - Batch Inference Time: 0.9355 seconds\n",
            "Batch 154/237 - Batch Inference Time: 0.9600 seconds\n",
            "Batch 155/237 - Batch Inference Time: 0.9452 seconds\n",
            "Batch 156/237 - Batch Inference Time: 0.9487 seconds\n",
            "Batch 157/237 - Batch Inference Time: 0.9628 seconds\n",
            "Batch 158/237 - Batch Inference Time: 0.9392 seconds\n",
            "Batch 159/237 - Batch Inference Time: 1.2209 seconds\n",
            "Batch 160/237 - Batch Inference Time: 0.9512 seconds\n",
            "Batch 161/237 - Batch Inference Time: 0.9369 seconds\n",
            "Batch 162/237 - Batch Inference Time: 0.9486 seconds\n",
            "Batch 163/237 - Batch Inference Time: 0.9463 seconds\n",
            "Batch 164/237 - Batch Inference Time: 0.9517 seconds\n",
            "Batch 165/237 - Batch Inference Time: 0.9382 seconds\n",
            "Batch 166/237 - Batch Inference Time: 0.9413 seconds\n",
            "Batch 167/237 - Batch Inference Time: 0.9362 seconds\n",
            "Batch 168/237 - Batch Inference Time: 0.9522 seconds\n",
            "Batch 169/237 - Batch Inference Time: 1.2650 seconds\n",
            "Batch 170/237 - Batch Inference Time: 0.9190 seconds\n",
            "Batch 171/237 - Batch Inference Time: 0.9190 seconds\n",
            "Batch 172/237 - Batch Inference Time: 0.9270 seconds\n",
            "Batch 173/237 - Batch Inference Time: 0.9428 seconds\n",
            "Batch 174/237 - Batch Inference Time: 0.9387 seconds\n",
            "Batch 175/237 - Batch Inference Time: 0.9482 seconds\n",
            "Batch 176/237 - Batch Inference Time: 0.9540 seconds\n",
            "Batch 177/237 - Batch Inference Time: 0.9479 seconds\n",
            "Batch 178/237 - Batch Inference Time: 0.9347 seconds\n",
            "Batch 179/237 - Batch Inference Time: 1.2428 seconds\n",
            "Batch 180/237 - Batch Inference Time: 0.9443 seconds\n",
            "Batch 181/237 - Batch Inference Time: 0.9719 seconds\n",
            "Batch 182/237 - Batch Inference Time: 0.9591 seconds\n",
            "Batch 183/237 - Batch Inference Time: 0.9358 seconds\n",
            "Batch 184/237 - Batch Inference Time: 0.9368 seconds\n",
            "Batch 185/237 - Batch Inference Time: 0.9405 seconds\n",
            "Batch 186/237 - Batch Inference Time: 0.9279 seconds\n",
            "Batch 187/237 - Batch Inference Time: 0.9340 seconds\n",
            "Batch 188/237 - Batch Inference Time: 0.9526 seconds\n",
            "Batch 189/237 - Batch Inference Time: 0.9241 seconds\n",
            "Batch 190/237 - Batch Inference Time: 1.2386 seconds\n",
            "Batch 191/237 - Batch Inference Time: 0.9646 seconds\n",
            "Batch 192/237 - Batch Inference Time: 0.9448 seconds\n",
            "Batch 193/237 - Batch Inference Time: 0.9727 seconds\n",
            "Batch 194/237 - Batch Inference Time: 0.9841 seconds\n",
            "Batch 195/237 - Batch Inference Time: 0.9800 seconds\n",
            "Batch 196/237 - Batch Inference Time: 0.9329 seconds\n",
            "Batch 197/237 - Batch Inference Time: 0.9297 seconds\n",
            "Batch 198/237 - Batch Inference Time: 0.9516 seconds\n",
            "Batch 199/237 - Batch Inference Time: 0.9479 seconds\n",
            "Batch 200/237 - Batch Inference Time: 1.2509 seconds\n",
            "Batch 201/237 - Batch Inference Time: 0.9396 seconds\n",
            "Batch 202/237 - Batch Inference Time: 0.9480 seconds\n",
            "Batch 203/237 - Batch Inference Time: 0.9433 seconds\n",
            "Batch 204/237 - Batch Inference Time: 0.9769 seconds\n",
            "Batch 205/237 - Batch Inference Time: 0.9891 seconds\n",
            "Batch 206/237 - Batch Inference Time: 0.9450 seconds\n",
            "Batch 207/237 - Batch Inference Time: 0.9500 seconds\n",
            "Batch 208/237 - Batch Inference Time: 0.9568 seconds\n",
            "Batch 209/237 - Batch Inference Time: 0.9621 seconds\n",
            "Batch 210/237 - Batch Inference Time: 1.2321 seconds\n",
            "Batch 211/237 - Batch Inference Time: 0.9222 seconds\n",
            "Batch 212/237 - Batch Inference Time: 0.9564 seconds\n",
            "Batch 213/237 - Batch Inference Time: 0.9639 seconds\n",
            "Batch 214/237 - Batch Inference Time: 0.9349 seconds\n",
            "Batch 215/237 - Batch Inference Time: 0.9640 seconds\n",
            "Batch 216/237 - Batch Inference Time: 0.9429 seconds\n",
            "Batch 217/237 - Batch Inference Time: 0.9604 seconds\n",
            "Batch 218/237 - Batch Inference Time: 0.9694 seconds\n",
            "Batch 219/237 - Batch Inference Time: 0.9581 seconds\n",
            "Batch 220/237 - Batch Inference Time: 1.2261 seconds\n",
            "Batch 221/237 - Batch Inference Time: 0.9329 seconds\n",
            "Batch 222/237 - Batch Inference Time: 0.9378 seconds\n",
            "Batch 223/237 - Batch Inference Time: 0.9342 seconds\n",
            "Batch 224/237 - Batch Inference Time: 0.9258 seconds\n",
            "Batch 225/237 - Batch Inference Time: 0.9626 seconds\n",
            "Batch 226/237 - Batch Inference Time: 0.9472 seconds\n",
            "Batch 227/237 - Batch Inference Time: 0.9309 seconds\n",
            "Batch 228/237 - Batch Inference Time: 0.9227 seconds\n",
            "Batch 229/237 - Batch Inference Time: 0.9507 seconds\n",
            "Batch 230/237 - Batch Inference Time: 0.9468 seconds\n",
            "Batch 231/237 - Batch Inference Time: 1.2515 seconds\n",
            "Batch 232/237 - Batch Inference Time: 0.9411 seconds\n",
            "Batch 233/237 - Batch Inference Time: 0.9541 seconds\n",
            "Batch 234/237 - Batch Inference Time: 0.9470 seconds\n",
            "Batch 235/237 - Batch Inference Time: 0.9570 seconds\n",
            "Batch 236/237 - Batch Inference Time: 0.9372 seconds\n",
            "Batch 237/237 - Batch Inference Time: 1.5829 seconds\n",
            "\n",
            "Testing completed: Testing Accuracy = 0.8800\n",
            "Average Inference Time per Batch: 1.0078 seconds\n",
            "Total Inference Time: 238.84 seconds\n",
            "\n",
            "Client connection closed.\n"
          ]
        }
      ],
      "source": [
        "import socket\n",
        "import pickle\n",
        "import zlib\n",
        "import time\n",
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "from tensorflow.keras import Sequential\n",
        "from tensorflow.keras.layers import Conv1D, MaxPooling1D, BatchNormalization\n",
        "from sklearn.model_selection import train_test_split\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "\n",
        "# Client-side model\n",
        "def create_client_model():\n",
        "    model = Sequential([\n",
        "        Conv1D(16, kernel_size=3, activation='relu', input_shape=(40, 1),padding='same'),\n",
        "        BatchNormalization(),\n",
        "        Conv1D(32, kernel_size=3, activation='relu',padding='same'),\n",
        "        BatchNormalization(),\n",
        "        #MaxPooling1D(pool_size=2),\n",
        "        Conv1D(32, kernel_size=3, activation='relu',padding='same'),\n",
        "        BatchNormalization(),\n",
        "        #MaxPooling1D(pool_size=2),\n",
        "        Conv1D(64, kernel_size=3, activation='relu',padding='same'),\n",
        "        BatchNormalization(),\n",
        "        Conv1D(64, kernel_size=3, activation='relu',padding='same'),\n",
        "        BatchNormalization(),\n",
        "        MaxPooling1D(pool_size=2),\n",
        "\n",
        "    ])\n",
        "    return model\n",
        "\n",
        "# Serialize and compress data using pickle\n",
        "def serialize_data(data):\n",
        "    return zlib.compress(pickle.dumps(data))\n",
        "\n",
        "# Client function\n",
        "def start_client(host='127.0.0.1', port=65437):\n",
        "    client_model = create_client_model()\n",
        "    client_socket = socket.socket(socket.AF_INET, socket.SOCK_STREAM)\n",
        "    client_socket.connect((host, port))\n",
        "    print(\"Connected to server!\")\n",
        "\n",
        "    batch_size = 512\n",
        "    epochs =  10\n",
        "    total_batches = int(np.ceil(X_train_scaled.shape[0] / batch_size))\n",
        "\n",
        "    print(\"\\nStarting Training...\")\n",
        "    start_time = time.time()\n",
        "\n",
        "    for epoch in range(epochs):\n",
        "        print(f\"\\nEpoch {epoch + 1}/{epochs}\")\n",
        "        epoch_loss = 0\n",
        "        correct_predictions = 0\n",
        "        total_samples = 0\n",
        "\n",
        "        for batch_index, i in enumerate(range(0, X_train_scaled.shape[0], batch_size), start=1):\n",
        "            x_batch = X_train_scaled[i:min(i + batch_size, X_train_scaled.shape[0])]\n",
        "            y_batch = y_train[i:min(i + batch_size, y_train.shape[0])]\n",
        "\n",
        "            # Forward pass to get intermediate activations\n",
        "            intermediate_output = client_model(x_batch, training=True).numpy()\n",
        "\n",
        "            # Serialize and send data\n",
        "            data = serialize_data((intermediate_output.tolist(), y_batch.tolist()))\n",
        "            client_socket.sendall(f\"{len(data):08}\".encode('utf-8'))\n",
        "            client_socket.sendall(data)\n",
        "\n",
        "            # Receive server response\n",
        "            response_header = client_socket.recv(8)\n",
        "            response_size = int(response_header.decode('utf-8').strip())\n",
        "            response = client_socket.recv(response_size)\n",
        "            server_loss, batch_correct = map(float, response.decode('utf-8').split(','))\n",
        "\n",
        "            # Update statistics\n",
        "            epoch_loss += server_loss\n",
        "            correct_predictions += batch_correct\n",
        "            total_samples += x_batch.shape[0]\n",
        "\n",
        "            # Display batch progress\n",
        "            progress = (batch_index / total_batches) * 100\n",
        "            print(f\"\\rBatch {batch_index}/{total_batches} - Progress: {progress:.2f}% - Loss: {server_loss:.4f}\", end=\"\")\n",
        "\n",
        "        training_accuracy = correct_predictions / total_samples\n",
        "        print(f\"\\nEpoch {epoch + 1} completed: Avg Loss = {epoch_loss / total_batches:.4f}, \"\n",
        "              f\"Training Accuracy = {training_accuracy:.4f}\")\n",
        "\n",
        "    total_training_time = time.time() - start_time\n",
        "    print(f\"\\nTraining completed in {total_training_time:.2f} seconds.\")\n",
        "\n",
        "    # Signal the server to switch to evaluation mode\n",
        "    client_socket.sendall(f\"{-1:08}\".encode('utf-8'))\n",
        "    print(\"Training complete. Signaled server to start evaluation.\")\n",
        "\n",
        "        # Evaluate testing accuracy in batches\n",
        "    print(\"\\nEvaluating on test data...\")\n",
        "    test_batch_size = 512  # Larger batch size for efficient testing\n",
        "    total_test_batches = int(np.ceil(X_test_scaled.shape[0] / test_batch_size))\n",
        "    correct_predictions = 0\n",
        "    total_samples = 0\n",
        "    total_inference_time = 0\n",
        "\n",
        "    for batch_num, i in enumerate(range(0, X_test_scaled.shape[0], test_batch_size), start=1):\n",
        "        x_test_batch = X_test_scaled[i:min(i + test_batch_size, X_test_scaled.shape[0])]\n",
        "        y_test_batch = y_test[i:min(i + test_batch_size, y_test.shape[0])]\n",
        "\n",
        "        # Start timing the inference\n",
        "        start_infer_time = time.time()\n",
        "\n",
        "        test_intermediate = client_model.predict(x_test_batch, verbose=0)\n",
        "        test_data = serialize_data((test_intermediate.tolist(), y_test_batch.tolist()))\n",
        "        data_length = len(test_data)\n",
        "        client_socket.sendall(f\"{len(test_data):08}\".encode('utf-8'))\n",
        "        client_socket.sendall(test_data)\n",
        "        total_bytes_sent += 8 + data_length\n",
        "        test_accuracy_response = client_socket.recv(8)\n",
        "        test_accuracy_size = int(test_accuracy_response.decode('utf-8').strip())\n",
        "        test_accuracy_data = client_socket.recv(test_accuracy_size)\n",
        "        batch_correct = int(test_accuracy_data.decode('utf-8'))\n",
        "        total_bytes_received += 8 + test_accuracy_size  # 8 bytes for header + actual data\n",
        "\n",
        "        # Stop timing and accumulate\n",
        "        end_infer_time = time.time()\n",
        "        batch_inference_time = end_infer_time - start_infer_time\n",
        "        total_inference_time += batch_inference_time\n",
        "\n",
        "        print(f\"Batch {batch_num}/{total_test_batches} - Batch Inference Time: {batch_inference_time:.4f} seconds\")\n",
        "\n",
        "        correct_predictions += batch_correct\n",
        "        total_samples += x_test_batch.shape[0]\n",
        "\n",
        "    test_accuracy = correct_predictions / total_samples\n",
        "    avg_inference_time = total_inference_time / total_test_batches\n",
        "    print(f\"\\nTesting completed: Testing Accuracy = {test_accuracy:.4f}\")\n",
        "    print(f\"Average Inference Time per Batch: {avg_inference_time:.4f} seconds\")\n",
        "    print(f\"Total Inference Time: {total_inference_time:.2f} seconds\")\n",
        "    print(f\"Total Communication Overhead:\")\n",
        "    print(f\"  Bytes Sent: {total_bytes_sent} bytes\")\n",
        "    print(f\"  Bytes Received: {total_bytes_received} bytes\")\n",
        "    print(f\"  Total: {total_bytes_sent + total_bytes_received} bytes\")\n",
        "\n",
        "    client_socket.close()\n",
        "    print(\"\\nClient connection closed.\")\n",
        "\n",
        "# Start the client\n",
        "start_client()\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "QHSiXMHxJ43H"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "A2kIceCjYhyX",
        "outputId": "dd821ad0-84be-4679-a15e-9aa2da323d31"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/keras/src/layers/pooling/base_pooling.py:23: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(name=name, **kwargs)\n"
          ]
        }
      ],
      "source": [
        "import socket\n",
        "import pickle\n",
        "import zlib\n",
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "from tensorflow.keras import Sequential\n",
        "from tensorflow.keras.layers import MaxPooling1D, Flatten, Dense, BatchNormalization\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "import threading\n",
        "from sklearn.metrics import precision_score, recall_score, f1_score\n",
        "from tensorflow.keras.layers import Dropout\n",
        "\n",
        "# Server-side model\n",
        "def create_server_model():\n",
        "    model = Sequential([\n",
        "        MaxPooling1D(pool_size=2,input_shape=(20, 64)),\n",
        "        Conv1D(128, kernel_size=3, activation='relu',padding='same'),\n",
        "        BatchNormalization(),\n",
        "        Conv1D(128, kernel_size=3, activation='relu',padding='same'),\n",
        "        BatchNormalization(),\n",
        "        MaxPooling1D(pool_size=2),\n",
        "        Conv1D(256, kernel_size=3, activation='relu',padding='same'),\n",
        "        BatchNormalization(),\n",
        "        Conv1D(256, kernel_size=3, activation='relu',padding='same'),\n",
        "        BatchNormalization(),\n",
        "        MaxPooling1D(pool_size=2),\n",
        "        Flatten(),\n",
        "        Dense(256, activation='relu'),\n",
        "        Dropout(0.3),\n",
        "        Dense(128, activation='relu'),\n",
        "        Dropout(0.2),\n",
        "        Dense(11, activation='softmax')\n",
        "    ])\n",
        "    model.compile(optimizer=Adam(learning_rate=0.001),\n",
        "                  loss='categorical_crossentropy',\n",
        "                  metrics=['accuracy'])\n",
        "    return model\n",
        "\n",
        "# Deserialize and decompress data\n",
        "def deserialize_data(data):\n",
        "    return pickle.loads(zlib.decompress(data))\n",
        "\n",
        "# Server function\n",
        "def start_server(host='127.0.0.1', port=65439):\n",
        "    server_model = create_server_model()\n",
        "    server_socket = socket.socket(socket.AF_INET, socket.SOCK_STREAM)\n",
        "    server_socket.bind((host, port))\n",
        "    server_socket.listen(1)\n",
        "    print(\"Server waiting for connection...\")\n",
        "    conn, addr = server_socket.accept()\n",
        "    print(f\"Connected to client: {addr}\")\n",
        "    lr_schedule = tf.keras.optimizers.schedules.ExponentialDecay(\n",
        "    initial_learning_rate=0.001,\n",
        "    decay_steps=10000,\n",
        "    decay_rate=0.9\n",
        "    )\n",
        "    optimizer = tf.keras.optimizers.Adam(learning_rate=lr_schedule)\n",
        "\n",
        "    all_true_labels = []\n",
        "    all_pred_labels = []\n",
        "\n",
        "\n",
        "    while True:\n",
        "        try:\n",
        "            # Receive header indicating batch size\n",
        "            header = conn.recv(8)\n",
        "            if not header:\n",
        "                break\n",
        "            data_size = int(header.decode('utf-8').strip())\n",
        "\n",
        "\n",
        "            # If a special flag (e.g., -1) is sent, switch to evaluation\n",
        "            if data_size == -1:\n",
        "              print(\"Switching to evaluation phase...\")\n",
        "              break\n",
        "\n",
        "            # Receive the batch data\n",
        "            data = b\"\"\n",
        "            while len(data) < data_size:\n",
        "                packet = conn.recv(4096)\n",
        "                if not packet:\n",
        "                    break\n",
        "                data += packet\n",
        "\n",
        "            # Deserialize the data\n",
        "            intermediate_output, labels = deserialize_data(data)\n",
        "\n",
        "            # Perform forward pass and backpropagation on batch\n",
        "            with tf.GradientTape() as tape:\n",
        "                logits = server_model(np.array(intermediate_output), training=True)\n",
        "                loss = tf.reduce_mean(\n",
        "                    tf.keras.losses.categorical_crossentropy(np.array(labels), logits)\n",
        "                )\n",
        "            gradients = tape.gradient(loss, server_model.trainable_variables)\n",
        "            optimizer.apply_gradients(zip(gradients, server_model.trainable_variables))\n",
        "\n",
        "            pred_classes = np.argmax(logits.numpy(), axis=1)\n",
        "            true_classes = np.argmax(labels, axis=1)\n",
        "\n",
        "            all_pred_labels.extend(pred_classes)\n",
        "            all_true_labels.extend(true_classes)\n",
        "\n",
        "            correct_predictions = int(np.sum(\n",
        "                np.argmax(logits.numpy(), axis=1) == np.argmax(labels, axis=1)\n",
        "            ))\n",
        "            response = f\"{loss.numpy():.4f},{correct_predictions}\"\n",
        "            conn.sendall(f\"{len(response):08}\".encode('utf-8'))\n",
        "            conn.sendall(response.encode('utf-8'))\n",
        "\n",
        "        except Exception as e:\n",
        "            print(f\"Error: {e}\")\n",
        "            break\n",
        "\n",
        "    # At the end of training\n",
        "    precision = precision_score(all_true_labels, all_pred_labels, average='macro')\n",
        "    recall = recall_score(all_true_labels, all_pred_labels, average='macro')\n",
        "    f1 = f1_score(all_true_labels, all_pred_labels, average='macro')\n",
        "    print(f\"\\nTraining Metrics → Precision: {precision:.4f}, Recall: {recall:.4f}, F1 Score: {f1:.4f}\")\n",
        "\n",
        "    # Handle test evaluation\n",
        "    print(\"Evaluating test data...\")\n",
        "\n",
        "    all_test_true = []\n",
        "    all_test_pred = []\n",
        "\n",
        "    while True:\n",
        "        header = conn.recv(8)\n",
        "        if not header:\n",
        "            break\n",
        "        test_data_size = int(header.decode('utf-8').strip())\n",
        "        test_data = b\"\"\n",
        "        while len(test_data) < test_data_size:\n",
        "            packet = conn.recv(4096)\n",
        "            if not packet:\n",
        "                break\n",
        "            test_data += packet\n",
        "\n",
        "        test_intermediate, test_labels = deserialize_data(test_data)\n",
        "        logits = server_model(np.array(test_intermediate), training=False)\n",
        "\n",
        "        test_intermediate = np.array(test_intermediate)\n",
        "        test_labels = np.array(test_labels)\n",
        "\n",
        "        logits = server_model(test_intermediate, training=False)\n",
        "        pred_classes = np.argmax(logits.numpy(), axis=1)\n",
        "        true_classes = np.argmax(test_labels, axis=1)\n",
        "\n",
        "        all_test_pred.extend(pred_classes)\n",
        "        all_test_true.extend(true_classes)\n",
        "\n",
        "        correct_predictions = int(np.sum(\n",
        "            np.argmax(logits.numpy(), axis=1) == np.argmax(test_labels, axis=1)\n",
        "        ))\n",
        "        response = f\"{correct_predictions}\"\n",
        "        conn.sendall(f\"{len(response):08}\".encode('utf-8'))\n",
        "        conn.sendall(response.encode('utf-8'))\n",
        "\n",
        "    # Final test metrics\n",
        "    precision = precision_score(all_test_true, all_test_pred, average='macro')\n",
        "    recall = recall_score(all_test_true, all_test_pred, average='macro')\n",
        "    f1 = f1_score(all_test_true, all_test_pred, average='macro')\n",
        "    print(f\"\\nTesting Metrics → Precision: {precision:.4f}, Recall: {recall:.4f}, F1 Score: {f1:.4f}\")\n",
        "\n",
        "\n",
        "    conn.close()\n",
        "    server_socket.close()\n",
        "    print(\"Server connection closed.\")\n",
        "\n",
        "server_thread = threading.Thread(target=start_server)\n",
        "server_thread.start()\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#communication overhead"
      ],
      "metadata": {
        "id": "u47QMCXLYcZV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d5e33b9f-b9f1-47c2-e616-88e35838d587",
        "collapsed": true,
        "id": "jC8JF7BmYnCs"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/keras/src/layers/convolutional/base_conv.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Connected to server!Connected to client: ('127.0.0.1', 43948)\n",
            "\n",
            "\n",
            "Starting Training...\n",
            "\n",
            "Epoch 1/10\n",
            "Batch 553/553 - Progress: 100.00% - Loss: 0.1270\n",
            "Epoch 1 completed: Avg Loss = 0.2437, Training Accuracy = 0.8606\n",
            "\n",
            "Epoch 2/10\n",
            "Batch 553/553 - Progress: 100.00% - Loss: 0.1158\n",
            "Epoch 2 completed: Avg Loss = 0.1625, Training Accuracy = 0.8958\n",
            "\n",
            "Epoch 3/10\n",
            "Batch 553/553 - Progress: 100.00% - Loss: 0.1066\n",
            "Epoch 3 completed: Avg Loss = 0.1461, Training Accuracy = 0.9029\n",
            "\n",
            "Epoch 4/10\n",
            "Batch 553/553 - Progress: 100.00% - Loss: 0.1190\n",
            "Epoch 4 completed: Avg Loss = 0.1427, Training Accuracy = 0.9042\n",
            "\n",
            "Epoch 5/10\n",
            "Batch 553/553 - Progress: 100.00% - Loss: 0.1033\n",
            "Epoch 5 completed: Avg Loss = 0.1403, Training Accuracy = 0.9046\n",
            "\n",
            "Epoch 6/10\n",
            "Batch 553/553 - Progress: 100.00% - Loss: 0.1048\n",
            "Epoch 6 completed: Avg Loss = 0.1386, Training Accuracy = 0.9055\n",
            "\n",
            "Epoch 7/10\n",
            "Batch 553/553 - Progress: 100.00% - Loss: 0.1106\n",
            "Epoch 7 completed: Avg Loss = 0.1375, Training Accuracy = 0.9059\n",
            "\n",
            "Epoch 8/10\n",
            "Batch 553/553 - Progress: 100.00% - Loss: 0.1088\n",
            "Epoch 8 completed: Avg Loss = 0.1361, Training Accuracy = 0.9064\n",
            "\n",
            "Epoch 9/10\n",
            "Batch 553/553 - Progress: 100.00% - Loss: 0.1064\n",
            "Epoch 9 completed: Avg Loss = 0.1340, Training Accuracy = 0.9071\n",
            "\n",
            "Epoch 10/10\n",
            "Batch 553/553 - Progress: 100.00% - Loss: 0.1088\n",
            "Epoch 10 completed: Avg Loss = 0.1343, Training Accuracy = 0.9072\n",
            "\n",
            "Training completed in 9135.13 seconds.\n",
            "Training complete. Signaled server to start evaluation.\n",
            "\n",
            "Evaluating on test data...\n",
            "Switching to evaluation phase...\n",
            "\n",
            "Training Metrics → Precision: 0.8997, Recall: 0.8997, F1 Score: 0.8997\n",
            "Evaluating test data...\n",
            "Batch 1/237 - Batch Inference Time: 12.0030 seconds\n",
            "Batch 2/237 - Batch Inference Time: 1.7032 seconds\n",
            "Batch 3/237 - Batch Inference Time: 1.7155 seconds\n",
            "Batch 4/237 - Batch Inference Time: 1.4013 seconds\n",
            "Batch 5/237 - Batch Inference Time: 1.2284 seconds\n",
            "Batch 6/237 - Batch Inference Time: 1.2431 seconds\n",
            "Batch 7/237 - Batch Inference Time: 1.2586 seconds\n",
            "Batch 8/237 - Batch Inference Time: 1.5862 seconds\n",
            "Batch 9/237 - Batch Inference Time: 1.2357 seconds\n",
            "Batch 10/237 - Batch Inference Time: 1.3536 seconds\n",
            "Batch 11/237 - Batch Inference Time: 1.4249 seconds\n",
            "Batch 12/237 - Batch Inference Time: 1.6962 seconds\n",
            "Batch 13/237 - Batch Inference Time: 1.7290 seconds\n",
            "Batch 14/237 - Batch Inference Time: 1.2609 seconds\n",
            "Batch 15/237 - Batch Inference Time: 1.2587 seconds\n",
            "Batch 16/237 - Batch Inference Time: 1.5694 seconds\n",
            "Batch 17/237 - Batch Inference Time: 1.3037 seconds\n",
            "Batch 18/237 - Batch Inference Time: 1.2465 seconds\n",
            "Batch 19/237 - Batch Inference Time: 1.3326 seconds\n",
            "Batch 20/237 - Batch Inference Time: 1.2715 seconds\n",
            "Batch 21/237 - Batch Inference Time: 1.5476 seconds\n",
            "Batch 22/237 - Batch Inference Time: 1.7451 seconds\n",
            "Batch 23/237 - Batch Inference Time: 1.5475 seconds\n",
            "Batch 24/237 - Batch Inference Time: 1.2892 seconds\n",
            "Batch 25/237 - Batch Inference Time: 1.5745 seconds\n",
            "Batch 26/237 - Batch Inference Time: 1.2562 seconds\n",
            "Batch 27/237 - Batch Inference Time: 1.3189 seconds\n",
            "Batch 28/237 - Batch Inference Time: 1.3186 seconds\n",
            "Batch 29/237 - Batch Inference Time: 1.3103 seconds\n",
            "Batch 30/237 - Batch Inference Time: 1.4001 seconds\n",
            "Batch 31/237 - Batch Inference Time: 1.6290 seconds\n",
            "Batch 32/237 - Batch Inference Time: 1.6978 seconds\n",
            "Batch 33/237 - Batch Inference Time: 1.4840 seconds\n",
            "Batch 34/237 - Batch Inference Time: 1.6554 seconds\n",
            "Batch 35/237 - Batch Inference Time: 1.3016 seconds\n",
            "Batch 36/237 - Batch Inference Time: 1.2635 seconds\n",
            "Batch 37/237 - Batch Inference Time: 1.2654 seconds\n",
            "Batch 38/237 - Batch Inference Time: 1.3182 seconds\n",
            "Batch 39/237 - Batch Inference Time: 1.3094 seconds\n",
            "Batch 40/237 - Batch Inference Time: 1.4321 seconds\n",
            "Batch 41/237 - Batch Inference Time: 1.9085 seconds\n",
            "Batch 42/237 - Batch Inference Time: 1.6652 seconds\n",
            "Batch 43/237 - Batch Inference Time: 1.3243 seconds\n",
            "Batch 44/237 - Batch Inference Time: 1.3377 seconds\n",
            "Batch 45/237 - Batch Inference Time: 1.3048 seconds\n",
            "Batch 46/237 - Batch Inference Time: 1.6316 seconds\n",
            "Batch 47/237 - Batch Inference Time: 1.3132 seconds\n",
            "Batch 48/237 - Batch Inference Time: 1.3487 seconds\n",
            "Batch 49/237 - Batch Inference Time: 1.2877 seconds\n",
            "Batch 50/237 - Batch Inference Time: 1.6291 seconds\n",
            "Batch 51/237 - Batch Inference Time: 1.7114 seconds\n",
            "Batch 52/237 - Batch Inference Time: 1.4819 seconds\n",
            "Batch 53/237 - Batch Inference Time: 1.3324 seconds\n",
            "Batch 54/237 - Batch Inference Time: 1.3288 seconds\n",
            "Batch 55/237 - Batch Inference Time: 1.5877 seconds\n",
            "Batch 56/237 - Batch Inference Time: 1.3260 seconds\n",
            "Batch 57/237 - Batch Inference Time: 1.2715 seconds\n",
            "Batch 58/237 - Batch Inference Time: 1.2590 seconds\n",
            "Batch 59/237 - Batch Inference Time: 1.2966 seconds\n",
            "Batch 60/237 - Batch Inference Time: 1.7209 seconds\n",
            "Batch 61/237 - Batch Inference Time: 1.7395 seconds\n",
            "Batch 62/237 - Batch Inference Time: 1.3980 seconds\n",
            "Batch 63/237 - Batch Inference Time: 1.2438 seconds\n",
            "Batch 64/237 - Batch Inference Time: 1.6563 seconds\n",
            "Batch 65/237 - Batch Inference Time: 1.3153 seconds\n",
            "Batch 66/237 - Batch Inference Time: 1.2952 seconds\n",
            "Batch 67/237 - Batch Inference Time: 1.3674 seconds\n",
            "Batch 68/237 - Batch Inference Time: 1.3502 seconds\n",
            "Batch 69/237 - Batch Inference Time: 1.5436 seconds\n",
            "Batch 70/237 - Batch Inference Time: 1.7447 seconds\n",
            "Batch 71/237 - Batch Inference Time: 1.5586 seconds\n",
            "Batch 72/237 - Batch Inference Time: 1.2754 seconds\n",
            "Batch 73/237 - Batch Inference Time: 1.6331 seconds\n",
            "Batch 74/237 - Batch Inference Time: 1.3166 seconds\n",
            "Batch 75/237 - Batch Inference Time: 1.3417 seconds\n",
            "Batch 76/237 - Batch Inference Time: 1.2641 seconds\n",
            "Batch 77/237 - Batch Inference Time: 1.2453 seconds\n",
            "Batch 78/237 - Batch Inference Time: 1.2466 seconds\n",
            "Batch 79/237 - Batch Inference Time: 1.6873 seconds\n",
            "Batch 80/237 - Batch Inference Time: 1.6892 seconds\n",
            "Batch 81/237 - Batch Inference Time: 1.4569 seconds\n",
            "Batch 82/237 - Batch Inference Time: 1.5892 seconds\n",
            "Batch 83/237 - Batch Inference Time: 1.3439 seconds\n",
            "Batch 84/237 - Batch Inference Time: 1.2807 seconds\n",
            "Batch 85/237 - Batch Inference Time: 1.3299 seconds\n",
            "Batch 86/237 - Batch Inference Time: 1.2674 seconds\n",
            "Batch 87/237 - Batch Inference Time: 1.2871 seconds\n",
            "Batch 88/237 - Batch Inference Time: 1.2923 seconds\n",
            "Batch 89/237 - Batch Inference Time: 1.7069 seconds\n",
            "Batch 90/237 - Batch Inference Time: 1.9016 seconds\n",
            "Batch 91/237 - Batch Inference Time: 1.2717 seconds\n",
            "Batch 92/237 - Batch Inference Time: 1.3387 seconds\n",
            "Batch 93/237 - Batch Inference Time: 1.5883 seconds\n",
            "Batch 94/237 - Batch Inference Time: 1.2684 seconds\n",
            "Batch 95/237 - Batch Inference Time: 1.3386 seconds\n",
            "Batch 96/237 - Batch Inference Time: 1.2679 seconds\n",
            "Batch 97/237 - Batch Inference Time: 1.2655 seconds\n",
            "Batch 98/237 - Batch Inference Time: 1.5396 seconds\n",
            "Batch 99/237 - Batch Inference Time: 1.7039 seconds\n",
            "Batch 100/237 - Batch Inference Time: 1.5385 seconds\n",
            "Batch 101/237 - Batch Inference Time: 1.5657 seconds\n",
            "Batch 102/237 - Batch Inference Time: 1.2740 seconds\n",
            "Batch 103/237 - Batch Inference Time: 1.3586 seconds\n",
            "Batch 104/237 - Batch Inference Time: 1.2759 seconds\n",
            "Batch 105/237 - Batch Inference Time: 1.3018 seconds\n",
            "Batch 106/237 - Batch Inference Time: 1.3458 seconds\n",
            "Batch 107/237 - Batch Inference Time: 1.2507 seconds\n",
            "Batch 108/237 - Batch Inference Time: 1.6544 seconds\n",
            "Batch 109/237 - Batch Inference Time: 2.1397 seconds\n",
            "Batch 110/237 - Batch Inference Time: 1.3693 seconds\n",
            "Batch 111/237 - Batch Inference Time: 1.2693 seconds\n",
            "Batch 112/237 - Batch Inference Time: 1.3320 seconds\n",
            "Batch 113/237 - Batch Inference Time: 1.2432 seconds\n",
            "Batch 114/237 - Batch Inference Time: 1.2766 seconds\n",
            "Batch 115/237 - Batch Inference Time: 1.3291 seconds\n",
            "Batch 116/237 - Batch Inference Time: 1.2512 seconds\n",
            "Batch 117/237 - Batch Inference Time: 1.2985 seconds\n",
            "Batch 118/237 - Batch Inference Time: 1.7318 seconds\n",
            "Batch 119/237 - Batch Inference Time: 1.7243 seconds\n",
            "Batch 120/237 - Batch Inference Time: 1.7329 seconds\n",
            "Batch 121/237 - Batch Inference Time: 1.3484 seconds\n",
            "Batch 122/237 - Batch Inference Time: 1.3378 seconds\n",
            "Batch 123/237 - Batch Inference Time: 1.2612 seconds\n",
            "Batch 124/237 - Batch Inference Time: 1.3260 seconds\n",
            "Batch 125/237 - Batch Inference Time: 1.2541 seconds\n",
            "Batch 126/237 - Batch Inference Time: 1.3291 seconds\n",
            "Batch 127/237 - Batch Inference Time: 1.4929 seconds\n",
            "Batch 128/237 - Batch Inference Time: 1.6988 seconds\n",
            "Batch 129/237 - Batch Inference Time: 2.0231 seconds\n",
            "Batch 130/237 - Batch Inference Time: 1.2822 seconds\n",
            "Batch 131/237 - Batch Inference Time: 1.2694 seconds\n",
            "Batch 132/237 - Batch Inference Time: 1.2599 seconds\n",
            "Batch 133/237 - Batch Inference Time: 1.2562 seconds\n",
            "Batch 134/237 - Batch Inference Time: 1.3434 seconds\n",
            "Batch 135/237 - Batch Inference Time: 1.3402 seconds\n",
            "Batch 136/237 - Batch Inference Time: 1.3366 seconds\n",
            "Batch 137/237 - Batch Inference Time: 2.0450 seconds\n",
            "Batch 138/237 - Batch Inference Time: 1.7402 seconds\n",
            "Batch 139/237 - Batch Inference Time: 1.2810 seconds\n",
            "Batch 140/237 - Batch Inference Time: 1.3350 seconds\n",
            "Batch 141/237 - Batch Inference Time: 1.2929 seconds\n",
            "Batch 142/237 - Batch Inference Time: 1.3767 seconds\n",
            "Batch 143/237 - Batch Inference Time: 1.3137 seconds\n",
            "Batch 144/237 - Batch Inference Time: 1.3230 seconds\n",
            "Batch 145/237 - Batch Inference Time: 1.6814 seconds\n",
            "Batch 146/237 - Batch Inference Time: 1.5514 seconds\n",
            "Batch 147/237 - Batch Inference Time: 1.7083 seconds\n",
            "Batch 148/237 - Batch Inference Time: 1.5475 seconds\n",
            "Batch 149/237 - Batch Inference Time: 1.2789 seconds\n",
            "Batch 150/237 - Batch Inference Time: 1.3255 seconds\n",
            "Batch 151/237 - Batch Inference Time: 1.2286 seconds\n",
            "Batch 152/237 - Batch Inference Time: 1.2836 seconds\n",
            "Batch 153/237 - Batch Inference Time: 1.3134 seconds\n",
            "Batch 154/237 - Batch Inference Time: 1.6573 seconds\n",
            "Batch 155/237 - Batch Inference Time: 1.3546 seconds\n",
            "Batch 156/237 - Batch Inference Time: 1.7310 seconds\n",
            "Batch 157/237 - Batch Inference Time: 1.7410 seconds\n",
            "Batch 158/237 - Batch Inference Time: 1.4054 seconds\n",
            "Batch 159/237 - Batch Inference Time: 1.2750 seconds\n",
            "Batch 160/237 - Batch Inference Time: 1.2639 seconds\n",
            "Batch 161/237 - Batch Inference Time: 1.3472 seconds\n",
            "Batch 162/237 - Batch Inference Time: 1.2605 seconds\n",
            "Batch 163/237 - Batch Inference Time: 1.2502 seconds\n",
            "Batch 164/237 - Batch Inference Time: 1.2527 seconds\n",
            "Batch 165/237 - Batch Inference Time: 1.3307 seconds\n",
            "Batch 166/237 - Batch Inference Time: 2.1105 seconds\n",
            "Batch 167/237 - Batch Inference Time: 1.7388 seconds\n",
            "Batch 168/237 - Batch Inference Time: 1.2649 seconds\n",
            "Batch 169/237 - Batch Inference Time: 1.3464 seconds\n",
            "Batch 170/237 - Batch Inference Time: 1.3289 seconds\n",
            "Batch 171/237 - Batch Inference Time: 1.3327 seconds\n",
            "Batch 172/237 - Batch Inference Time: 1.2904 seconds\n",
            "Batch 173/237 - Batch Inference Time: 1.2621 seconds\n",
            "Batch 174/237 - Batch Inference Time: 1.3241 seconds\n",
            "Batch 175/237 - Batch Inference Time: 1.9339 seconds\n",
            "Batch 176/237 - Batch Inference Time: 1.7074 seconds\n",
            "Batch 177/237 - Batch Inference Time: 1.4878 seconds\n",
            "Batch 178/237 - Batch Inference Time: 1.2900 seconds\n",
            "Batch 179/237 - Batch Inference Time: 1.3384 seconds\n",
            "Batch 180/237 - Batch Inference Time: 1.3617 seconds\n",
            "Batch 181/237 - Batch Inference Time: 1.2464 seconds\n",
            "Batch 182/237 - Batch Inference Time: 1.2504 seconds\n",
            "Batch 183/237 - Batch Inference Time: 1.2703 seconds\n",
            "Batch 184/237 - Batch Inference Time: 1.6512 seconds\n",
            "Batch 185/237 - Batch Inference Time: 1.7114 seconds\n",
            "Batch 186/237 - Batch Inference Time: 1.7095 seconds\n",
            "Batch 187/237 - Batch Inference Time: 1.4319 seconds\n",
            "Batch 188/237 - Batch Inference Time: 1.3343 seconds\n",
            "Batch 189/237 - Batch Inference Time: 1.2731 seconds\n",
            "Batch 190/237 - Batch Inference Time: 1.3442 seconds\n",
            "Batch 191/237 - Batch Inference Time: 1.2922 seconds\n",
            "Batch 192/237 - Batch Inference Time: 1.3331 seconds\n",
            "Batch 193/237 - Batch Inference Time: 1.6554 seconds\n",
            "Batch 194/237 - Batch Inference Time: 1.5348 seconds\n",
            "Batch 195/237 - Batch Inference Time: 1.7307 seconds\n",
            "Batch 196/237 - Batch Inference Time: 1.6018 seconds\n",
            "Batch 197/237 - Batch Inference Time: 1.2806 seconds\n",
            "Batch 198/237 - Batch Inference Time: 1.3552 seconds\n",
            "Batch 199/237 - Batch Inference Time: 1.2815 seconds\n",
            "Batch 200/237 - Batch Inference Time: 1.2603 seconds\n",
            "Batch 201/237 - Batch Inference Time: 1.2683 seconds\n",
            "Batch 202/237 - Batch Inference Time: 1.5947 seconds\n",
            "Batch 203/237 - Batch Inference Time: 1.2805 seconds\n",
            "Batch 204/237 - Batch Inference Time: 1.5833 seconds\n",
            "Batch 205/237 - Batch Inference Time: 1.7452 seconds\n",
            "Batch 206/237 - Batch Inference Time: 1.6118 seconds\n",
            "Batch 207/237 - Batch Inference Time: 1.2627 seconds\n",
            "Batch 208/237 - Batch Inference Time: 1.3442 seconds\n",
            "Batch 209/237 - Batch Inference Time: 1.3198 seconds\n",
            "Batch 210/237 - Batch Inference Time: 1.3126 seconds\n",
            "Batch 211/237 - Batch Inference Time: 1.5707 seconds\n",
            "Batch 212/237 - Batch Inference Time: 1.3120 seconds\n",
            "Batch 213/237 - Batch Inference Time: 1.5237 seconds\n",
            "Batch 214/237 - Batch Inference Time: 1.6828 seconds\n",
            "Batch 215/237 - Batch Inference Time: 1.6972 seconds\n",
            "Batch 216/237 - Batch Inference Time: 1.2889 seconds\n",
            "Batch 217/237 - Batch Inference Time: 1.3674 seconds\n",
            "Batch 218/237 - Batch Inference Time: 1.2666 seconds\n",
            "Batch 219/237 - Batch Inference Time: 1.2710 seconds\n",
            "Batch 220/237 - Batch Inference Time: 1.6858 seconds\n",
            "Batch 221/237 - Batch Inference Time: 1.2616 seconds\n",
            "Batch 222/237 - Batch Inference Time: 1.3317 seconds\n",
            "Batch 223/237 - Batch Inference Time: 1.5737 seconds\n",
            "Batch 224/237 - Batch Inference Time: 1.6518 seconds\n",
            "Batch 225/237 - Batch Inference Time: 1.4803 seconds\n",
            "Batch 226/237 - Batch Inference Time: 1.2679 seconds\n",
            "Batch 227/237 - Batch Inference Time: 1.3090 seconds\n",
            "Batch 228/237 - Batch Inference Time: 1.2656 seconds\n",
            "Batch 229/237 - Batch Inference Time: 1.2513 seconds\n",
            "Batch 230/237 - Batch Inference Time: 1.2411 seconds\n",
            "Batch 231/237 - Batch Inference Time: 1.5878 seconds\n",
            "Batch 232/237 - Batch Inference Time: 1.3159 seconds\n",
            "Batch 233/237 - Batch Inference Time: 1.6899 seconds\n",
            "Batch 234/237 - Batch Inference Time: 1.8995 seconds\n",
            "Batch 235/237 - Batch Inference Time: 1.3979 seconds\n",
            "Batch 236/237 - Batch Inference Time: 1.2913 seconds\n",
            "Batch 237/237 - Batch Inference Time: 1.3299 seconds\n",
            "\n",
            "Testing completed: Testing Accuracy = 0.8529\n",
            "Average Inference Time per Batch: 1.4777 seconds\n",
            "Total Inference Time: 350.22 seconds\n",
            "Total Communication Overhead:\n",
            "  Bytes Sent: 571009359 bytes\n",
            "  Bytes Received: 2607 bytes\n",
            "  Total: 571011966 bytes\n",
            "\n",
            "Client connection closed.\n"
          ]
        }
      ],
      "source": [
        "import socket\n",
        "import pickle\n",
        "import zlib\n",
        "import time\n",
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "from tensorflow.keras import Sequential\n",
        "from tensorflow.keras.layers import Conv1D, MaxPooling1D, BatchNormalization\n",
        "from sklearn.model_selection import train_test_split\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "\n",
        "# Client-side model\n",
        "def create_client_model():\n",
        "    model = Sequential([\n",
        "        Conv1D(16, kernel_size=3, activation='relu', input_shape=(40, 1),padding='same'),\n",
        "        BatchNormalization(),\n",
        "        Conv1D(32, kernel_size=3, activation='relu',padding='same'),\n",
        "        BatchNormalization(),\n",
        "        #MaxPooling1D(pool_size=2),\n",
        "        Conv1D(32, kernel_size=3, activation='relu',padding='same'),\n",
        "        BatchNormalization(),\n",
        "        #MaxPooling1D(pool_size=2),\n",
        "        Conv1D(64, kernel_size=3, activation='relu',padding='same'),\n",
        "        BatchNormalization(),\n",
        "        Conv1D(64, kernel_size=3, activation='relu',padding='same'),\n",
        "        BatchNormalization(),\n",
        "        MaxPooling1D(pool_size=2),\n",
        "\n",
        "    ])\n",
        "    return model\n",
        "\n",
        "# Serialize and compress data using pickle\n",
        "def serialize_data(data):\n",
        "    return zlib.compress(pickle.dumps(data))\n",
        "\n",
        "# Client function\n",
        "def start_client(host='127.0.0.1', port=65439):\n",
        "    client_model = create_client_model()\n",
        "    client_socket = socket.socket(socket.AF_INET, socket.SOCK_STREAM)\n",
        "    client_socket.connect((host, port))\n",
        "    print(\"Connected to server!\")\n",
        "\n",
        "    batch_size = 512\n",
        "    epochs =  10\n",
        "    total_batches = int(np.ceil(X_train_scaled.shape[0] / batch_size))\n",
        "\n",
        "    print(\"\\nStarting Training...\")\n",
        "    start_time = time.time()\n",
        "\n",
        "    for epoch in range(epochs):\n",
        "        print(f\"\\nEpoch {epoch + 1}/{epochs}\")\n",
        "        epoch_loss = 0\n",
        "        correct_predictions = 0\n",
        "        total_samples = 0\n",
        "\n",
        "        for batch_index, i in enumerate(range(0, X_train_scaled.shape[0], batch_size), start=1):\n",
        "            x_batch = X_train_scaled[i:min(i + batch_size, X_train_scaled.shape[0])]\n",
        "            y_batch = y_train[i:min(i + batch_size, y_train.shape[0])]\n",
        "\n",
        "            # Forward pass to get intermediate activations\n",
        "            intermediate_output = client_model(x_batch, training=True).numpy()\n",
        "\n",
        "            # Serialize and send data\n",
        "            data = serialize_data((intermediate_output.tolist(), y_batch.tolist()))\n",
        "            client_socket.sendall(f\"{len(data):08}\".encode('utf-8'))\n",
        "            client_socket.sendall(data)\n",
        "\n",
        "            # Receive server response\n",
        "            response_header = client_socket.recv(8)\n",
        "            response_size = int(response_header.decode('utf-8').strip())\n",
        "            response = client_socket.recv(response_size)\n",
        "            server_loss, batch_correct = map(float, response.decode('utf-8').split(','))\n",
        "\n",
        "            # Update statistics\n",
        "            epoch_loss += server_loss\n",
        "            correct_predictions += batch_correct\n",
        "            total_samples += x_batch.shape[0]\n",
        "\n",
        "            # Display batch progress\n",
        "            progress = (batch_index / total_batches) * 100\n",
        "            print(f\"\\rBatch {batch_index}/{total_batches} - Progress: {progress:.2f}% - Loss: {server_loss:.4f}\", end=\"\")\n",
        "\n",
        "        training_accuracy = correct_predictions / total_samples\n",
        "        print(f\"\\nEpoch {epoch + 1} completed: Avg Loss = {epoch_loss / total_batches:.4f}, \"\n",
        "              f\"Training Accuracy = {training_accuracy:.4f}\")\n",
        "\n",
        "    total_training_time = time.time() - start_time\n",
        "    print(f\"\\nTraining completed in {total_training_time:.2f} seconds.\")\n",
        "\n",
        "    # Signal the server to switch to evaluation mode\n",
        "    client_socket.sendall(f\"{-1:08}\".encode('utf-8'))\n",
        "    print(\"Training complete. Signaled server to start evaluation.\")\n",
        "\n",
        "        # Evaluate testing accuracy in batches\n",
        "    print(\"\\nEvaluating on test data...\")\n",
        "    test_batch_size = 512  # Larger batch size for efficient testing\n",
        "    total_test_batches = int(np.ceil(X_test_scaled.shape[0] / test_batch_size))\n",
        "    correct_predictions = 0\n",
        "    total_samples = 0\n",
        "    total_inference_time = 0\n",
        "    total_bytes_sent = 0\n",
        "    total_bytes_received = 0\n",
        "\n",
        "    for batch_num, i in enumerate(range(0, X_test_scaled.shape[0], test_batch_size), start=1):\n",
        "        x_test_batch = X_test_scaled[i:min(i + test_batch_size, X_test_scaled.shape[0])]\n",
        "        y_test_batch = y_test[i:min(i + test_batch_size, y_test.shape[0])]\n",
        "\n",
        "        # Start timing the inference\n",
        "        start_infer_time = time.time()\n",
        "\n",
        "        test_intermediate = client_model.predict(x_test_batch, verbose=0)\n",
        "        test_data = serialize_data((test_intermediate.tolist(), y_test_batch.tolist()))\n",
        "        data_length = len(test_data)\n",
        "        client_socket.sendall(f\"{len(test_data):08}\".encode('utf-8'))\n",
        "        client_socket.sendall(test_data)\n",
        "        total_bytes_sent += 8 + data_length\n",
        "        test_accuracy_response = client_socket.recv(8)\n",
        "        test_accuracy_size = int(test_accuracy_response.decode('utf-8').strip())\n",
        "        test_accuracy_data = client_socket.recv(test_accuracy_size)\n",
        "        batch_correct = int(test_accuracy_data.decode('utf-8'))\n",
        "        total_bytes_received += 8 + test_accuracy_size  # 8 bytes for header + actual data\n",
        "\n",
        "        # Stop timing and accumulate\n",
        "        end_infer_time = time.time()\n",
        "        batch_inference_time = end_infer_time - start_infer_time\n",
        "        total_inference_time += batch_inference_time\n",
        "\n",
        "        print(f\"Batch {batch_num}/{total_test_batches} - Batch Inference Time: {batch_inference_time:.4f} seconds\")\n",
        "\n",
        "        correct_predictions += batch_correct\n",
        "        total_samples += x_test_batch.shape[0]\n",
        "\n",
        "    test_accuracy = correct_predictions / total_samples\n",
        "    avg_inference_time = total_inference_time / total_test_batches\n",
        "    print(f\"\\nTesting completed: Testing Accuracy = {test_accuracy:.4f}\")\n",
        "    print(f\"Average Inference Time per Batch: {avg_inference_time:.4f} seconds\")\n",
        "    print(f\"Total Inference Time: {total_inference_time:.2f} seconds\")\n",
        "    print(f\"Total Communication Overhead:\")\n",
        "    print(f\"  Bytes Sent: {total_bytes_sent} bytes\")\n",
        "    print(f\"  Bytes Received: {total_bytes_received} bytes\")\n",
        "    print(f\"  Total: {total_bytes_sent + total_bytes_received} bytes\")\n",
        "\n",
        "    client_socket.close()\n",
        "    print(\"\\nClient connection closed.\")\n",
        "\n",
        "# Start the client\n",
        "start_client()\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "n8wyUTuYYcdc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "UYCuB5WfYch3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "4wRdJEZRYclu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "pcXgC5jch-mC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "dbReDqARJ5EP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "d_k82M8fUSsi"
      },
      "outputs": [],
      "source": [
        "import socket\n",
        "import pickle\n",
        "import zlib\n",
        "import tensorflow as tf\n",
        "import tf_keras as keras\n",
        "import tensorflow_model_optimization as tfmot\n",
        "import numpy as np\n",
        "from tensorflow.keras import Sequential\n",
        "from tensorflow.keras.layers import MaxPooling1D, Flatten, Dense, BatchNormalization\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "import threading\n",
        "from sklearn.metrics import precision_score, recall_score, f1_score\n",
        "from tensorflow.keras.layers import Dropout\n",
        "# Apply pruning\n",
        "prune_low_magnitude = tfmot.sparsity.keras.prune_low_magnitude\n",
        "\n",
        "# Server-side model\n",
        "def create_server_model():\n",
        "    model = keras.Sequential([\n",
        "        keras.layers.MaxPooling1D(pool_size=2,input_shape=(20, 64)),\n",
        "        keras.layers.Conv1D(128, kernel_size=3, activation='relu',padding='same'),\n",
        "        keras.layers.BatchNormalization(),\n",
        "        keras.layers.Conv1D(128, kernel_size=3, activation='relu',padding='same'),\n",
        "        keras.layers.BatchNormalization(),\n",
        "        keras.layers.MaxPooling1D(pool_size=2),\n",
        "        keras.layers.Conv1D(256, kernel_size=3, activation='relu',padding='same'),\n",
        "        keras.layers.BatchNormalization(),\n",
        "        keras.layers.Conv1D(256, kernel_size=3, activation='relu',padding='same'),\n",
        "        keras.layers.BatchNormalization(),\n",
        "        keras.layers.MaxPooling1D(pool_size=2),\n",
        "        keras.layers.Flatten(),\n",
        "        keras.layers.Dense(256, activation='relu'),\n",
        "        keras.layers.Dropout(0.3),\n",
        "        keras.layers.Dense(128, activation='relu'),\n",
        "        keras.layers.Dropout(0.2),\n",
        "        keras.layers.Dense(11, activation='softmax')\n",
        "    ])\n",
        "    return model\n",
        "\n",
        "pruning_params = {\"pruning_schedule\": tfmot.sparsity.keras.PolynomialDecay(initial_sparsity=0.0, final_sparsity=0.5, begin_step=553, end_step=5530, power=3)}\n",
        "server_model = prune_low_magnitude(create_server_model(), **pruning_params)\n",
        "server_model.build(input_shape=(None, 20, 64))\n",
        "server_model.compile(optimizer='adam',loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "# Deserialize and decompress data\n",
        "def deserialize_data(data):\n",
        "    return pickle.loads(zlib.decompress(data))\n",
        "\n",
        "# Server function\n",
        "def start_server(host='127.0.0.1', port=65434):\n",
        "\n",
        "    pruned_server_model=server_model\n",
        "    pruning_callback = tfmot.sparsity.keras.UpdatePruningStep()\n",
        "    log_callback = tfmot.sparsity.keras.PruningSummaries(log_dir=\"logs\")\n",
        "\n",
        "\n",
        "    server_socket = socket.socket(socket.AF_INET, socket.SOCK_STREAM)\n",
        "    server_socket.bind((host, port))\n",
        "    server_socket.listen(1)\n",
        "    print(\"Server waiting for connection...\")\n",
        "    conn, addr = server_socket.accept()\n",
        "    print(f\"Connected to client: {addr}\")\n",
        "    lr_schedule = tf.keras.optimizers.schedules.ExponentialDecay(\n",
        "    initial_learning_rate=0.001,\n",
        "    decay_steps=20000,\n",
        "    decay_rate=0.95\n",
        "    )\n",
        "    optimizer = tf.keras.optimizers.Adam(learning_rate=lr_schedule)\n",
        "\n",
        "    total_comm_overhead = 0  # Track communication overhead\n",
        "    pruning_callback.set_model(pruned_server_model)\n",
        "    log_callback.set_model(pruned_server_model)\n",
        "    pruning_callback.on_train_begin()\n",
        "\n",
        "    all_true_labels = []\n",
        "    all_pred_labels = []\n",
        "\n",
        "    training_start_time = time.time()\n",
        "\n",
        "\n",
        "    while True:\n",
        "        try:\n",
        "            # Receive header indicating batch size\n",
        "            header = conn.recv(8)\n",
        "            if not header:\n",
        "                break\n",
        "            data_size = int(header.decode('utf-8').strip())\n",
        "\n",
        "\n",
        "            # If a special flag (e.g., -1) is sent, switch to evaluation\n",
        "            if data_size == -1:\n",
        "              print(\"Switching to evaluation phase...\")\n",
        "              break\n",
        "\n",
        "            # Receive the batch data\n",
        "            data = b\"\"\n",
        "            while len(data) < data_size:\n",
        "                packet = conn.recv(4096)\n",
        "                if not packet:\n",
        "                    break\n",
        "                data += packet\n",
        "            total_comm_overhead += len(data)  # Update comm overhead\n",
        "\n",
        "            # Deserialize the data\n",
        "            intermediate_output, labels = deserialize_data(data)\n",
        "            pruning_callback.on_train_batch_begin(batch=-1)\n",
        "\n",
        "            # Perform forward pass and backpropagation on batch\n",
        "            with tf.GradientTape() as tape:\n",
        "                logits = pruned_server_model(np.array(intermediate_output), training=True)\n",
        "                loss = tf.reduce_mean(\n",
        "                    tf.keras.losses.categorical_crossentropy(np.array(labels), logits)\n",
        "                )\n",
        "            gradients = tape.gradient(loss, pruned_server_model.trainable_variables)\n",
        "            optimizer.apply_gradients(zip(gradients, pruned_server_model.trainable_variables))\n",
        "            pruning_callback.on_epoch_end(batch=-1)\n",
        "\n",
        "            pred_classes = np.argmax(logits.numpy(), axis=1)\n",
        "            true_classes = np.argmax(labels, axis=1)\n",
        "\n",
        "            all_pred_labels.extend(pred_classes)\n",
        "            all_true_labels.extend(true_classes)\n",
        "\n",
        "            correct_predictions = int(np.sum(\n",
        "                np.argmax(logits.numpy(), axis=1) == np.argmax(labels, axis=1)\n",
        "            ))\n",
        "            response = f\"{loss.numpy():.4f},{correct_predictions}\"\n",
        "            conn.sendall(f\"{len(response):08}\".encode('utf-8'))\n",
        "            conn.sendall(response.encode('utf-8'))\n",
        "\n",
        "        except Exception as e:\n",
        "            print(f\"Error: {e}\")\n",
        "            break\n",
        "\n",
        "    training_end_time = time.time()\n",
        "    print(f\"Total Training Time: {training_end_time - training_start_time:.2f} sec\")\n",
        "    print(f\"Total Communication Overhead: {total_comm_overhead / 1024:.2f} KB\")\n",
        "\n",
        "\n",
        "    # At the end of training\n",
        "    precision = precision_score(all_true_labels, all_pred_labels, average='macro')\n",
        "    recall = recall_score(all_true_labels, all_pred_labels, average='macro')\n",
        "    f1 = f1_score(all_true_labels, all_pred_labels, average='macro')\n",
        "    print(f\"\\nTraining Metrics → Precision: {precision:.4f}, Recall: {recall:.4f}, F1 Score: {f1:.4f}\")\n",
        "\n",
        "    # Strip pruning and save the final model\n",
        "    #pruned_server_model = tfmot.sparsity.keras.strip_pruning(pruned_server_model)\n",
        "    #server_model.save(\"server_model_pruned.h5\")\n",
        "    model_for_export = tfmot.sparsity.keras.strip_pruning(pruned_server_model)\n",
        "\n",
        "    _, pruned_keras_file = tempfile.mkstemp('.h5')\n",
        "    keras.models.save_model(model_for_export, pruned_keras_file, include_optimizer=False)\n",
        "    print('Saved pruned Keras model to:', pruned_keras_file)\n",
        "\n",
        "\n",
        "    converter = tf.lite.TFLiteConverter.from_keras_model(pruned_server_model)\n",
        "    tflite_model = converter.convert()\n",
        "    with open(\"server_model_pruned.tflite\", \"wb\") as f:\n",
        "        f.write(tflite_model)\n",
        "\n",
        "    print(\"Model saved in .h5 and .tflite formats.\")\n",
        "\n",
        "    # Handle test evaluation\n",
        "    print(\"Evaluating test data...\")\n",
        "\n",
        "    all_test_true = []\n",
        "    all_test_pred = []\n",
        "\n",
        "    while True:\n",
        "        header = conn.recv(8)\n",
        "        if not header:\n",
        "            break\n",
        "        test_data_size = int(header.decode('utf-8').strip())\n",
        "        test_data = b\"\"\n",
        "        while len(test_data) < test_data_size:\n",
        "            packet = conn.recv(4096)\n",
        "            if not packet:\n",
        "                break\n",
        "            test_data += packet\n",
        "\n",
        "        test_intermediate, test_labels = deserialize_data(test_data)\n",
        "        #logits = pruned_server_model(np.array(test_intermediate), training=False)\n",
        "\n",
        "        test_intermediate = np.array(test_intermediate)\n",
        "        test_labels = np.array(test_labels)\n",
        "\n",
        "        logits = pruned_server_model(test_intermediate, training=False)\n",
        "        pred_classes = np.argmax(logits.numpy(), axis=1)\n",
        "        true_classes = np.argmax(test_labels, axis=1)\n",
        "\n",
        "        all_test_pred.extend(pred_classes)\n",
        "        all_test_true.extend(true_classes)\n",
        "\n",
        "        correct_predictions = int(np.sum(\n",
        "            np.argmax(logits.numpy(), axis=1) == np.argmax(test_labels, axis=1)\n",
        "        ))\n",
        "        response = f\"{correct_predictions}\"\n",
        "        conn.sendall(f\"{len(response):08}\".encode('utf-8'))\n",
        "        conn.sendall(response.encode('utf-8'))\n",
        "\n",
        "        # Final test metrics\n",
        "        precision = precision_score(all_test_true, all_test_pred, average='macro')\n",
        "        recall = recall_score(all_test_true, all_test_pred, average='macro')\n",
        "        f1 = f1_score(all_test_true, all_test_pred, average='macro')\n",
        "        #print(f\"\\nTesting Metrics → Precision: {precision:.4f}, Recall: {recall:.4f}, F1 Score: {f1:.4f}\")\n",
        "\n",
        "\n",
        "    conn.close()\n",
        "    server_socket.close()\n",
        "    print(\"Server connection closed.\")\n",
        "\n",
        "server_thread = threading.Thread(target=start_server)\n",
        "server_thread.start()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JaMyVRN7l_in"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 356
        },
        "outputId": "b87181ff-b837-43b5-8c21-be27f1024e54",
        "id": "Ck0hUD0mUXaf"
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-1-46900d3c8638>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mzlib\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mtensorflow\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mnumpy\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeras\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mSequential\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/tensorflow/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m    465\u001b[0m     \u001b[0mimportlib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimport_module\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"tf_keras.src.optimizers\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    466\u001b[0m   \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 467\u001b[0;31m     \u001b[0mimportlib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimport_module\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"keras.src.optimizers\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    468\u001b[0m \u001b[0;32mexcept\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mImportError\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mAttributeError\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    469\u001b[0m   \u001b[0;32mpass\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.11/importlib/__init__.py\u001b[0m in \u001b[0;36mimport_module\u001b[0;34m(name, package)\u001b[0m\n\u001b[1;32m    124\u001b[0m                 \u001b[0;32mbreak\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    125\u001b[0m             \u001b[0mlevel\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 126\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_bootstrap\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_gcd_import\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mlevel\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpackage\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlevel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    127\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    128\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/keras/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# DO NOT EDIT. Generated by api_gen.sh\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapi\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mDTypePolicy\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapi\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mFloatDTypePolicy\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapi\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mFunction\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapi\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mInitializer\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/keras/api/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapi\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mactivations\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapi\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mapplications\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapi\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mbackend\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/keras/api/activations/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      5\u001b[0m \"\"\"\n\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msrc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mactivations\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mdeserialize\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msrc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mactivations\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mget\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msrc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mactivations\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mserialize\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/keras/src/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msrc\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mactivations\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msrc\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mapplications\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msrc\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mbackend\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msrc\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mconstraints\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msrc\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mdatasets\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/keras/src/activations/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     31\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msrc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mactivations\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mactivations\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mthreshold\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     32\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msrc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapi_export\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mkeras_export\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 33\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msrc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msaving\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mobject_registration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     34\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msrc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msaving\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mserialization_lib\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     35\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/keras/src/saving/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msrc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msaving\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mobject_registration\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mget_registered_object\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msrc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msaving\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mobject_registration\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mregister_keras_serializable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msrc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msaving\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msaving_api\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mload_model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msrc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msaving\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mserialization_lib\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mdeserialize_keras_object\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msrc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msaving\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mserialization_lib\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mserialize_keras_object\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/keras/src/saving/saving_api.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msrc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapi_export\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mkeras_export\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msrc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlegacy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msaving\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mlegacy_h5_format\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msrc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msaving\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0msaving_lib\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msrc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutils\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mfile_utils\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/keras/src/legacy/saving/legacy_h5_format.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msrc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlegacy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msaving\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mjson_utils\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msrc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlegacy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msaving\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0msaving_options\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 13\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msrc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlegacy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msaving\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0msaving_utils\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     14\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msrc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msaving\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mobject_registration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msrc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutils\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mio_utils\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/keras/src/legacy/saving/saving_utils.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msrc\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mbackend\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msrc\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mlayers\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msrc\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mlosses\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msrc\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mmetrics\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mmetrics_module\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/keras/src/layers/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msrc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapi_export\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mkeras_export\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msrc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mactivations\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mactivation\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mActivation\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msrc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mactivations\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0melu\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mELU\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msrc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mactivations\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mleaky_relu\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mLeakyReLU\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msrc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mactivations\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprelu\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mPReLU\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/keras/src/layers/activations/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msrc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mactivations\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0melu\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mELU\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msrc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mactivations\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mleaky_relu\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mLeakyReLU\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msrc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mactivations\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprelu\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mPReLU\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msrc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mactivations\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrelu\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mReLU\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msrc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mactivations\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msoftmax\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mSoftmax\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/keras/src/layers/activations/elu.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msrc\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mactivations\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msrc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapi_export\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mkeras_export\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msrc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayer\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mLayer\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/keras/src/layers/layer.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     41\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msrc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msaving\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeras_saveable\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mKerasSaveable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     42\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msrc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutils\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mpython_utils\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 43\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msrc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutils\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0msummary_utils\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     44\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msrc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutils\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtraceback_utils\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     45\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msrc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutils\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtracking\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/keras/src/utils/summary_utils.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mrich\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mrich\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconsole\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mrich\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmarkup\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/rich/console.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     48\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0m_export_format\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mCONSOLE_HTML_FORMAT\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mCONSOLE_SVG_FORMAT\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     49\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0m_fileno\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mget_fileno\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 50\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0m_log_render\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mFormatTimeCallable\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mLogRender\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     51\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0malign\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mAlign\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mAlignMethod\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     52\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mcolor\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mColorSystem\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mblend_rgb\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/rich/_log_render.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mtext\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mText\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mTextType\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mTYPE_CHECKING\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/rich/text.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0m_pick\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mpick_bool\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0m_wrap\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mdivide_line\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 22\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0malign\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mAlignMethod\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     23\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mcells\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mcell_len\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mset_cell_size\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mcontainers\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mLines\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/rich/align.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      8\u001b[0m     \u001b[0;32mfrom\u001b[0m \u001b[0mtyping_extensions\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mLiteral\u001b[0m  \u001b[0;31m# pragma: no cover\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mconstrain\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mConstrain\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mjupyter\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mJupyterMixin\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mmeasure\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mMeasurement\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/rich/constrain.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mjupyter\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mJupyterMixin\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mmeasure\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mMeasurement\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mTYPE_CHECKING\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/rich/measure.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m    126\u001b[0m     \u001b[0mconsole\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m\"Console\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    127\u001b[0m     \u001b[0moptions\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m\"ConsoleOptions\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 128\u001b[0;31m     \u001b[0mrenderables\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mSequence\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"RenderableType\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    129\u001b[0m ) -> \"Measurement\":\n\u001b[1;32m    130\u001b[0m     \"\"\"Get a measurement that would fit a number of renderables.\n",
            "\u001b[0;32m/usr/lib/python3.11/typing.py\u001b[0m in \u001b[0;36minner\u001b[0;34m(*args, **kwds)\u001b[0m\n\u001b[1;32m    374\u001b[0m         \u001b[0;32mdef\u001b[0m \u001b[0minner\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    375\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 376\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mcached\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    377\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    378\u001b[0m                 \u001b[0;32mpass\u001b[0m  \u001b[0;31m# All real errors (not unhashable args) are raised below.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.11/typing.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, params)\u001b[0m\n\u001b[1;32m   1591\u001b[0m         \u001b[0mparams\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtuple\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_type_check\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmsg\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mp\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mparams\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1592\u001b[0m         \u001b[0m_check_generic\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparams\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_nparams\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1593\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcopy_with\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1594\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1595\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mcopy_with\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparams\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.11/typing.py\u001b[0m in \u001b[0;36mcopy_with\u001b[0;34m(self, params)\u001b[0m\n\u001b[1;32m   1594\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1595\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mcopy_with\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparams\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1596\u001b[0;31m         return _GenericAlias(self.__origin__, params,\n\u001b[0m\u001b[1;32m   1597\u001b[0m                              name=self._name, inst=self._inst)\n\u001b[1;32m   1598\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ],
      "source": [
        "import socket\n",
        "import pickle\n",
        "import zlib\n",
        "import time\n",
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "from tensorflow.keras import Sequential\n",
        "from tensorflow.keras.layers import Conv1D, MaxPooling1D, BatchNormalization\n",
        "from sklearn.model_selection import train_test_split\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "\n",
        "# Client-side model\n",
        "def create_client_model():\n",
        "    model =keras.Sequential([\n",
        "        keras.layers.InputLayer(input_shape=(40, 1)),\n",
        "        keras.layers.Conv1D(16, kernel_size=3, activation='relu',padding='same'),\n",
        "        keras.layers.BatchNormalization(),\n",
        "        keras.layers.Conv1D(32, kernel_size=3, activation='relu',padding='same'),\n",
        "        keras.layers.BatchNormalization(),\n",
        "        #MaxPooling1D(pool_size=2),\n",
        "        keras.layers.Conv1D(32, kernel_size=3, activation='relu',padding='same'),\n",
        "        keras.layers.BatchNormalization(),\n",
        "        #MaxPooling1D(pool_size=2),\n",
        "        keras.layers.Conv1D(64, kernel_size=3, activation='relu',padding='same'),\n",
        "        keras.layers.BatchNormalization(),\n",
        "        keras.layers.Conv1D(64, kernel_size=3, activation='relu',padding='same'),\n",
        "        keras.layers.BatchNormalization(),\n",
        "        keras.layers.MaxPooling1D(pool_size=2),\n",
        "\n",
        "    ])\n",
        "    return model\n",
        "\n",
        "    # Apply pruning\n",
        "pruning_params = {'pruning_schedule': tfmot.sparsity.keras.PolynomialDecay(initial_sparsity=0.0, final_sparsity=0.50, begin_step=553, end_step=5530,power=3)}\n",
        "pruned_client_model = prune_low_magnitude(create_client_model(), **pruning_params)\n",
        "pruned_client_model.build(input_shape=(None, 40, 1))\n",
        "#print(\"Size of gzipped baseline Keras model: %.2f bytes\" % (get_gzipped_model_size(pruned_client_model)))\n",
        "\n",
        "# Serialize and compress data using pickle\n",
        "def serialize_data(data):\n",
        "    return zlib.compress(pickle.dumps(data))\n",
        "\n",
        "# Client function\n",
        "def start_client(host='127.0.0.1', port=65434):\n",
        "    client_model = create_client_model()\n",
        "    client_socket = socket.socket(socket.AF_INET, socket.SOCK_STREAM)\n",
        "    client_socket.connect((host, port))\n",
        "    print(\"Connected to server!\")\n",
        "\n",
        "    pruning_callback = tfmot.sparsity.keras.UpdatePruningStep()\n",
        "    pruning_callback.set_model(pruned_client_model)\n",
        "    pruning_callback.on_train_begin()\n",
        "\n",
        "    batch_size = 512\n",
        "    epochs =  10\n",
        "    total_batches = int(np.ceil(X_train_scaled.shape[0] / batch_size))\n",
        "    total_comm_overhead = 0\n",
        "\n",
        "    print(\"\\nStarting Training...\")\n",
        "    start_time = time.time()\n",
        "\n",
        "    for epoch in range(epochs):\n",
        "        print(f\"\\nEpoch {epoch + 1}/{epochs}\")\n",
        "        epoch_loss = 0\n",
        "        correct_predictions = 0\n",
        "        total_samples = 0\n",
        "\n",
        "        for batch_index, i in enumerate(range(0, X_train_scaled.shape[0], batch_size), start=1):\n",
        "            x_batch = X_train_scaled[i:min(i + batch_size, X_train_scaled.shape[0])]\n",
        "            y_batch = y_train[i:min(i + batch_size, y_train.shape[0])]\n",
        "\n",
        "            pruning_callback.on_train_batch_begin(batch=-1)\n",
        "\n",
        "            # Forward pass to get intermediate activations\n",
        "            intermediate_output = pruned_client_model(x_batch, training=True).numpy()\n",
        "\n",
        "            # Serialize and send data\n",
        "            data = serialize_data((intermediate_output.tolist(), y_batch.tolist()))\n",
        "            data_size = len(data)\n",
        "\n",
        "            client_socket.sendall(f\"{len(data):08}\".encode('utf-8'))\n",
        "            client_socket.sendall(data)\n",
        "\n",
        "            total_comm_overhead += data_size\n",
        "\n",
        "            # Receive server response\n",
        "            response_header = client_socket.recv(8)\n",
        "            response_size = int(response_header.decode('utf-8').strip())\n",
        "            response = client_socket.recv(response_size)\n",
        "            server_loss, batch_correct = map(float, response.decode('utf-8').split(','))\n",
        "            pruning_callback.on_epoch_end(batch=-1)\n",
        "\n",
        "            # Update statistics\n",
        "            epoch_loss += server_loss\n",
        "            correct_predictions += batch_correct\n",
        "            total_samples += x_batch.shape[0]\n",
        "\n",
        "            # Display batch progress\n",
        "            progress = (batch_index / total_batches) * 100\n",
        "            print(f\"\\rBatch {batch_index}/{total_batches} - Progress: {progress:.2f}% - Loss: {server_loss:.4f}\", end=\"\")\n",
        "\n",
        "        training_accuracy = correct_predictions / total_samples\n",
        "        print(f\"\\nEpoch {epoch + 1} completed: Avg Loss = {epoch_loss / total_batches:.4f}, \"\n",
        "              f\"Training Accuracy = {training_accuracy:.4f}\")\n",
        "\n",
        "    total_training_time = time.time() - start_time\n",
        "    print(f\"\\nTraining completed in {total_training_time:.2f} seconds.\")\n",
        "    print(f\"Total Communication Overhead: {total_comm_overhead / 1024:.2f} KB\")\n",
        "\n",
        "    #client_model = tfmot.sparsity.keras.strip_pruning(pruned_client_model)\n",
        "    #client_model.save(\"client_model_pruned.h5\")\n",
        "    model_for_export = tfmot.sparsity.keras.strip_pruning(pruned_client_model)\n",
        "\n",
        "    _, pruned_keras_file = tempfile.mkstemp('.h5')\n",
        "    keras.models.save_model(model_for_export, pruned_keras_file, include_optimizer=False)\n",
        "    print('Saved pruned Keras model to:', pruned_keras_file)\n",
        "\n",
        "    print(\"Size of gzipped pruned Keras model: %.2f bytes\" % (get_gzipped_model_size(pruned_keras_file)))\n",
        "\n",
        "    #converter = tf.lite.TFLiteConverter.from_keras_model(pruned_client_model)\n",
        "    #tflite_model = converter.convert()\n",
        "    #with open(\"client_model_pruned.tflite\", \"wb\") as f:\n",
        "        #f.write(tflite_model)\n",
        "    converter = tf.lite.TFLiteConverter.from_keras_model(model_for_export)\n",
        "    pruned_tflite_model = converter.convert()\n",
        "\n",
        "    _, pruned_tflite_file = tempfile.mkstemp('.tflite')\n",
        "\n",
        "    with open(pruned_tflite_file, 'wb') as f:\n",
        "        f.write(pruned_tflite_model)\n",
        "\n",
        "    print('Saved pruned TFLite model to:', pruned_tflite_file)\n",
        "    print(\"Size of gzipped pruned TFlite model: %.2f bytes\" % (get_gzipped_model_size(pruned_tflite_file)))\n",
        "\n",
        "        #print(\"Client model saved in .h5 and .tflite formats.\")\n",
        "    # Signal the server to switch to evaluation mode\n",
        "    client_socket.sendall(f\"{-1:08}\".encode('utf-8'))\n",
        "    print(\"Training complete. Signaled server to start evaluation.\")\n",
        "    from sklearn.metrics import confusion_matrix, classification_report\n",
        "\n",
        "\n",
        "    # Evaluate testing accuracy in batches\n",
        "    print(\"\\nEvaluating on test data...\")\n",
        "    test_batch_size = 512  # Larger batch size for efficient testing\n",
        "    total_test_batches = int(np.ceil(X_test_scaled.shape[0] / test_batch_size))\n",
        "    correct_predictions = 0\n",
        "    total_samples = 0\n",
        "    total_inference_time = 0\n",
        "    total_bytes_sent = 0\n",
        "    total_bytes_received = 0\n",
        "\n",
        "\n",
        "\n",
        "    for batch_num, i in enumerate(range(0, X_test_scaled.shape[0], test_batch_size), start=1):\n",
        "        x_test_batch = X_test_scaled[i:min(i + test_batch_size, X_test_scaled.shape[0])]\n",
        "        y_test_batch = y_test[i:min(i + test_batch_size, y_test.shape[0])]\n",
        "\n",
        "        # Start timing the inference\n",
        "        start_infer_time = time.time()\n",
        "\n",
        "        test_intermediate = pruned_client_model.predict(x_test_batch, verbose=0)\n",
        "        test_data = serialize_data((test_intermediate.tolist(), y_test_batch.tolist()))\n",
        "\n",
        "        # Send data size and data to server\n",
        "        data_length = len(test_data)\n",
        "        client_socket.sendall(f\"{data_length:08}\".encode('utf-8'))\n",
        "        client_socket.sendall(test_data)\n",
        "        total_bytes_sent += 8 + data_length  # 8 bytes for header + actual data\n",
        "\n",
        "\n",
        "        # Receive accuracy result from server\n",
        "        test_accuracy_response = client_socket.recv(8)\n",
        "        test_accuracy_size = int(test_accuracy_response.decode('utf-8').strip())\n",
        "        test_accuracy_data = client_socket.recv(test_accuracy_size)\n",
        "        batch_correct = int(test_accuracy_data.decode('utf-8'))\n",
        "        total_bytes_received += 8 + test_accuracy_size  # 8 bytes for header + actual data\n",
        "\n",
        "        # Stop timing and accumulate\n",
        "        end_infer_time = time.time()\n",
        "        batch_inference_time = end_infer_time - start_infer_time\n",
        "        total_inference_time += batch_inference_time\n",
        "\n",
        "        print(f\"Batch {batch_num}/{total_test_batches} - Inference Time: {batch_inference_time:.4f}s - Sent: {data_length}B\")\n",
        "\n",
        "        correct_predictions += batch_correct\n",
        "        total_samples += x_test_batch.shape[0]\n",
        "\n",
        "        # Append for confusion matrix\n",
        "        #all_pred_labels.extend(batch_pred_labels)\n",
        "        #all_true_labels.extend(np.argmax(y_test_batch, axis=1))  # Assuming one-hot encoded labels\n",
        "\n",
        "    # Final results\n",
        "    test_accuracy = correct_predictions / total_samples\n",
        "    avg_inference_time = total_inference_time / total_test_batches\n",
        "\n",
        "    print(f\"\\nTesting completed: Testing Accuracy = {test_accuracy:.4f}\")\n",
        "    print(f\"Average Inference Time per Batch: {avg_inference_time:.4f} seconds\")\n",
        "    print(f\"Total Inference Time: {total_inference_time:.2f} seconds\")\n",
        "    print(f\"Total Communication Overhead:\")\n",
        "    print(f\"  Bytes Sent: {total_bytes_sent} bytes\")\n",
        "    print(f\"  Bytes Received: {total_bytes_received} bytes\")\n",
        "    print(f\"  Total: {total_bytes_sent + total_bytes_received} bytes\")\n",
        "\n",
        "    client_socket.close()\n",
        "    print(\"\\nClient connection closed.\")\n",
        "\n",
        "# Start the client\n",
        "start_client()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8pevU2Y6l_ld"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}